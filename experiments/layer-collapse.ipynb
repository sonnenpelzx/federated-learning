{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# Python version: 3.6\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "\n",
    "from utils.sampling import mnist_iid, mnist_noniid, cifar_iid\n",
    "from utils.options import args_parser\n",
    "from models.Update import LocalUpdate\n",
    "from models.Nets import MLP, CNNMnist, CNNCifar\n",
    "from models.Fed import FedAvg\n",
    "from models.test import test_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seed settings\n",
    "- If you want the seed to be set manually, uncomment and set the seed value in these files:\n",
    "- also change uncomment the lines with `torch.backends.cudnn.deterministic = True`\n",
    "1. utils/sampling.py\n",
    "2. main_fed.py\n",
    "3. models/Nets.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the layer-colapse.py\n",
    "- This command is equivalent to running it from the console\n",
    "- Results are saved in federated-learning/save/test.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "2420111.5\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   0, Average loss 2.297\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "2519974.2\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   1, Average loss 1.899\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "4509664.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   2, Average loss 0.588\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "8030828.5\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   3, Average loss 0.096\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "9187477.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   4, Average loss 0.001\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "9356810.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   5, Average loss 0.001\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "9447894.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   6, Average loss 0.000\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "9510566.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   7, Average loss 0.000\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "9558353.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   8, Average loss 0.000\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "9597088.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   9, Average loss 0.000\n",
      "Training accuracy: 28.64\n",
      "Testing accuracy: 28.01\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "2420111.5\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   0, Average loss 2.297\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "2519974.2\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   1, Average loss 1.899\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "4509664.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   2, Average loss 0.588\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "8030828.5\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   3, Average loss 0.096\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "9187477.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   4, Average loss 0.001\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "9356810.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   5, Average loss 0.001\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "9447894.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   6, Average loss 0.000\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "9510566.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   7, Average loss 0.000\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "9558353.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   8, Average loss 0.000\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "9597088.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   9, Average loss 0.000\n",
      "Training accuracy: 28.64\n",
      "Testing accuracy: 28.01\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "2420111.5\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   0, Average loss 2.297\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "2519974.2\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   1, Average loss 1.899\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "4509664.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   2, Average loss 0.588\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "8030828.5\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   3, Average loss 0.096\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "9187477.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   4, Average loss 0.001\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "9356810.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   5, Average loss 0.001\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "9447894.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   6, Average loss 0.000\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "9510566.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   7, Average loss 0.000\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "9558353.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   8, Average loss 0.000\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "9597088.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   9, Average loss 0.000\n",
      "Training accuracy: 28.64\n",
      "Testing accuracy: 28.01\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "149896.28\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   0, Average loss 2.302\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "150752.16\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   1, Average loss 2.302\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "152879.17\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   2, Average loss 2.300\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "157382.03\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   3, Average loss 2.281\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "180170.58\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   4, Average loss 1.819\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "336436.66\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   5, Average loss 1.002\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "602565.8\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   6, Average loss 0.595\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "944986.6\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   7, Average loss 0.321\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "1293024.1\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   8, Average loss 0.145\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "1553970.5\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   9, Average loss 0.005\n",
      "Training accuracy: 27.01\n",
      "Testing accuracy: 26.43\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "1948746.2\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   0, Average loss 2.298\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "2024928.2\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   1, Average loss 1.943\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "3379870.0\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   2, Average loss 0.800\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "5991449.0\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   3, Average loss 0.226\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "7617579.0\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   4, Average loss 0.006\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "8009531.5\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round   5, Average loss 0.001\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "8154034.5\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   6, Average loss 0.001\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "8238777.5\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   7, Average loss 0.000\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "8298459.0\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   8, Average loss 0.000\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "8344463.0\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   9, Average loss 0.000\n",
      "Training accuracy: 28.62\n",
      "Testing accuracy: 28.65\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "2027163.0\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   0, Average loss 2.297\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "2110189.8\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   1, Average loss 1.935\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "3525235.2\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   2, Average loss 0.732\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "6295091.5\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   3, Average loss 0.175\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "7798777.0\n",
      "849142.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   4, Average loss 0.003\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "8039928.5\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   5, Average loss 0.001\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "8149842.0\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   6, Average loss 0.000\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "8220465.0\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   7, Average loss 0.000\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "8272440.5\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   8, Average loss 0.000\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "8313535.0\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   9, Average loss 0.000\n",
      "Training accuracy: 29.17\n",
      "Testing accuracy: 29.05\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "8962.486\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   0, Average loss 2.303\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "8974.103\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   1, Average loss 2.302\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "8993.798\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   2, Average loss 2.302\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "9021.914\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   3, Average loss 2.302\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "9059.687\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   4, Average loss 2.302\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "9110.454\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   5, Average loss 2.302\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "9177.576\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   6, Average loss 2.302\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "9271.127\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   7, Average loss 2.302\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "9417.74\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   8, Average loss 2.300\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "9762.429\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   9, Average loss 2.250\n",
      "Training accuracy: 10.00\n",
      "Testing accuracy: 10.03\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "1255251.1\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   0, Average loss 2.299\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "1290896.5\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   1, Average loss 2.186\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "1722882.6\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   2, Average loss 1.148\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "3570772.2\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   3, Average loss 0.260\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "4998709.5\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   4, Average loss 0.006\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "5314379.0\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   5, Average loss 0.002\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "5463090.5\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   6, Average loss 0.001\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "5554181.5\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   7, Average loss 0.001\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "5618131.0\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   8, Average loss 0.001\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "5666919.0\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   9, Average loss 0.000\n",
      "Training accuracy: 28.77\n",
      "Testing accuracy: 28.61\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "1378031.5\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   0, Average loss 2.299\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "1421268.0\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   1, Average loss 2.180\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "1884614.2\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   2, Average loss 1.077\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "3893318.5\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   3, Average loss 0.296\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "5243663.0\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   4, Average loss 0.016\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "5627541.0\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   5, Average loss 0.002\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "5753847.0\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round   6, Average loss 0.001\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "5828608.5\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   7, Average loss 0.001\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "5880727.5\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   8, Average loss 0.000\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "5920438.0\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   9, Average loss 0.000\n",
      "Training accuracy: 29.24\n",
      "Testing accuracy: 28.90\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "589.4397\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   0, Average loss 2.303\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "589.5833\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   1, Average loss 2.303\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "589.7736\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   2, Average loss 2.303\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "590.0084\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   3, Average loss 2.303\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "590.2868\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   4, Average loss 2.303\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "590.6083\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   5, Average loss 2.303\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "590.97186\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   6, Average loss 2.303\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "591.3771\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   7, Average loss 2.303\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "591.8229\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   8, Average loss 2.303\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "592.3091\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   9, Average loss 2.303\n",
      "Training accuracy: 12.97\n",
      "Testing accuracy: 12.94\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "721483.5\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   0, Average loss 2.300\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "735929.1\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   1, Average loss 2.260\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "871832.6\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   2, Average loss 1.533\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "1670523.2\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   3, Average loss 0.630\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "2665078.8\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   4, Average loss 0.284\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "3467986.2\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   5, Average loss 0.129\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "4026201.0\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   6, Average loss 0.003\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "4154361.0\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   7, Average loss 0.001\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "4224863.0\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   8, Average loss 0.001\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "4271456.0\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   9, Average loss 0.001\n",
      "Training accuracy: 29.44\n",
      "Testing accuracy: 29.77\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "819641.2\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   0, Average loss 2.299\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "840834.44\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   1, Average loss 2.219\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "1048331.0\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   2, Average loss 1.353\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "2098099.2\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   3, Average loss 0.471\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "3191489.2\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   4, Average loss 0.120\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "3749482.5\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   5, Average loss 0.103\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "4076036.5\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   6, Average loss 0.002\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "4186675.2\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   7, Average loss 0.001\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "4248909.5\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   8, Average loss 0.001\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "4291066.5\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   9, Average loss 0.000\n",
      "Training accuracy: 29.49\n",
      "Testing accuracy: 28.97\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "36.876144\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   0, Average loss 2.303\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "36.87526\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   1, Average loss 2.303\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "36.874718\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   2, Average loss 2.303\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "36.874508\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   3, Average loss 2.303\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "36.87463\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   4, Average loss 2.303\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "36.875095\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   5, Average loss 2.303\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "36.875877\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   6, Average loss 2.303\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "36.876984\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   7, Average loss 2.303\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "36.878403\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round   8, Average loss 2.303\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "36.880135\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   9, Average loss 2.303\n",
      "Training accuracy: 9.82\n",
      "Testing accuracy: 10.09\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "371311.38\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   0, Average loss 2.300\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "378178.22\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   1, Average loss 2.276\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "423672.75\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   2, Average loss 1.721\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "730151.6\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   3, Average loss 1.009\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "1215573.4\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   4, Average loss 0.520\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "1831827.4\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   5, Average loss 0.252\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "2410844.0\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   6, Average loss 0.119\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "2703498.8\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   7, Average loss 0.083\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "2984234.0\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   8, Average loss 0.122\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "3372021.5\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   9, Average loss 0.004\n",
      "Training accuracy: 29.38\n",
      "Testing accuracy: 29.27\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "472993.62\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   0, Average loss 2.301\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "481262.28\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   1, Average loss 2.287\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "526932.75\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   2, Average loss 1.798\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "903582.0\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   3, Average loss 0.911\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "1586285.8\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   4, Average loss 0.445\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "2401960.0\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   5, Average loss 0.150\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "3016390.5\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   6, Average loss 0.076\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "3306391.5\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   7, Average loss 0.005\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "3411472.0\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\Documents\\GitHub\\federated-learning\\layer-collapse.py:116\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m idxs_users:\n\u001b[0;32m    115\u001b[0m     local \u001b[38;5;241m=\u001b[39m LocalUpdate(args\u001b[38;5;241m=\u001b[39margs, dataset\u001b[38;5;241m=\u001b[39mdataset_train, idxs\u001b[38;5;241m=\u001b[39mdict_users[idx])\n\u001b[1;32m--> 116\u001b[0m     w, loss, mask \u001b[38;5;241m=\u001b[39m local\u001b[38;5;241m.\u001b[39mtrain(net\u001b[38;5;241m=\u001b[39mcopy\u001b[38;5;241m.\u001b[39mdeepcopy(net_glob)\u001b[38;5;241m.\u001b[39mto(args\u001b[38;5;241m.\u001b[39mdevice), mask\u001b[38;5;241m=\u001b[39mmasks[idx])\n\u001b[0;32m    117\u001b[0m     masks[idx] \u001b[38;5;241m=\u001b[39m mask\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mall_clients:\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\federated-learning\\models\\Update.py:91\u001b[0m, in \u001b[0;36mLocalUpdate.train\u001b[1;34m(self, net, mask)\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;129;01mand\u001b[39;00m batch_idx \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     88\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUpdate Epoch: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m [\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{:.0f}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m)]\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mLoss: \u001b[39m\u001b[38;5;132;01m{:.6f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m     89\u001b[0m                 \u001b[38;5;28miter\u001b[39m, batch_idx \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(images), \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mldr_train\u001b[38;5;241m.\u001b[39mdataset),\n\u001b[0;32m     90\u001b[0m                        \u001b[38;5;241m100.\u001b[39m \u001b[38;5;241m*\u001b[39m batch_idx \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mldr_train), loss\u001b[38;5;241m.\u001b[39mitem()))\n\u001b[1;32m---> 91\u001b[0m         batch_loss\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m     92\u001b[0m     epoch_loss\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28msum\u001b[39m(batch_loss)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(batch_loss))\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m net\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;28msum\u001b[39m(epoch_loss) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(epoch_loss), mask\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "%run ../layer-collapse.py --iid --model mlp --dataset cifar --epochs 10 --local_ep 20 --gpu -0 --num_channels 1 --num_users 100 --frac 0.1 --compression 10 --prune_epochs 100 --pruner mag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Testing plots\n",
    "\n",
    "- The code below is for testing plots from the results printed by manually copying them.\n",
    "- To plot the results directly, uncomment the `plt.show()` line\n",
    "- To save the results, uncomment the `plt.savefig()` line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "y = {}\n",
    "iters = 30\n",
    "alphas = [i/5 for i in range(iters)]\n",
    "y['synflow'] = [torch.tensor(97.7400), torch.tensor(97.6300), torch.tensor(97.5300), torch.tensor(97.5300), torch.tensor(97.6400), torch.tensor(97.2400), torch.tensor(96.3500), torch.tensor(95.5000), torch.tensor(94.8100), torch.tensor(93.3100), torch.tensor(89.5500), torch.tensor(71.1400), torch.tensor(42.9200), torch.tensor(10.1600), torch.tensor(11.9300), torch.tensor(9.1900), torch.tensor(14.0700), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000)]\n",
    "y['mag'] = [torch.tensor(97.4500), torch.tensor(97.0300), torch.tensor(97.2700), torch.tensor(97.6600), torch.tensor(97.6800), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000)]\n",
    "x_vals = [10**alpha for alpha in alphas]\n",
    "plt.figure()\n",
    "plt.xscale('log')\n",
    "plt.plot(x_vals, y['synflow'], label='Synflow', linestyle='-', marker='o', color='r')\n",
    "plt.plot(x_vals, y['mag'], label='Mag', linestyle='-', marker='o', color='b')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Y-axis')\n",
    "plt.title('Synflow vs Mag')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Save plot\n",
    "plt.savefig('../save/tesasdt-plot.png'.format())\n",
    "\n",
    "# Show plot\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

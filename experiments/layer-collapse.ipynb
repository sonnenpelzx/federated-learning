{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seed settings\n",
    "- If you want the seed to be set manually, uncomment and set the seed value in these files:\n",
    "- also change uncomment the lines with `torch.backends.cudnn.deterministic = True`\n",
    "1. utils/sampling.py\n",
    "2. main_fed.py\n",
    "3. models/Nets.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the layer-colapse.py\n",
    "- This command is equivalent to running it from the console\n",
    "- Results are saved in federated-learning/save/test.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "mask 10 6 <class 'list'> torch.Size([400, 784])\n",
      "Aggregation over all clients\n",
      "RANDOM USER INDICES [2 8 4]\n",
      "fedspa\n",
      "layer collapse if = 0\n",
<<<<<<< HEAD
      "1223886.0\n",
      "430600.0 430600 0.0 0.0\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "1223886.0\n",
      "430600.0 430600 0.0 0.0\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "1223886.0\n",
      "430600.0 430600 0.0 0.0\n",
      "[8, 8, 2, 8, 4, 8, 8, 8, 8, 8]\n",
      "Round   0, Average loss 2.186\n",
      "RANDOM USER INDICES [3 5 1]\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "1241850.9\n",
      "430600.0 430600 0.0 0.0\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "1241850.9\n",
      "430600.0 430600 0.0 0.0\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "1241850.9\n",
      "430600.0 430600 0.0 0.0\n",
      "[5, 1, 5, 3, 5, 5, 5, 5, 3, 5]\n",
      "Round   1, Average loss 1.332\n",
      "RANDOM USER INDICES [2 3 8]\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "1312039.2\n",
      "430600.0 430600 0.0 0.0\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "1312039.2\n",
      "430600.0 430600 0.0 0.0\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "1312039.2\n",
      "430600.0 430600 0.0 0.0\n",
      "[2, 2, 2, 3, 2, 2, 2, 2, 8, 2]\n",
      "Round   2, Average loss 0.819\n",
      "RANDOM USER INDICES [6 1 9]\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "1355056.0\n",
      "430600.0 430600 0.0 0.0\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "1355056.0\n",
      "430600.0 430600 0.0 0.0\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "1355056.0\n",
      "430600.0 430600 0.0 0.0\n",
      "[1, 1, 1, 6, 9, 9, 6, 1, 6, 9]\n",
      "Round   3, Average loss 0.782\n",
      "RANDOM USER INDICES [5 2 7]\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "1392036.0\n",
      "430600.0 430600 0.0 0.0\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "1392036.0\n",
      "430600.0 430600 0.0 0.0\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "1392036.0\n",
      "430600.0 430600 0.0 0.0\n",
      "[5, 2, 2, 5, 5, 5, 5, 7, 5, 5]\n",
      "Round   4, Average loss 0.484\n",
      "RANDOM USER INDICES [1 8 9]\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "1440970.4\n",
      "430600.0 430600 0.0 0.0\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "1440970.4\n",
      "430600.0 430600 0.0 0.0\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "1440970.4\n",
      "430600.0 430600 0.0 0.0\n",
      "[1, 1, 1, 8, 9, 9, 8, 9, 8, 9]\n",
      "Round   5, Average loss 0.325\n",
      "RANDOM USER INDICES [3 2 1]\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "1484189.0\n",
      "430600.0 430600 0.0 0.0\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "1484189.0\n",
      "430600.0 430600 0.0 0.0\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "1484189.0\n",
      "430600.0 430600 0.0 0.0\n",
      "[1, 1, 2, 3, 2, 1, 3, 1, 3, 1]\n",
      "Round   6, Average loss 0.345\n",
      "RANDOM USER INDICES [0 9 2]\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "1512516.5\n",
      "430600.0 430600 0.0 0.0\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "1512516.5\n",
      "430600.0 430600 0.0 0.0\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "1512516.5\n",
      "430600.0 430600 0.0 0.0\n",
      "[0, 2, 2, 0, 9, 9, 9, 9, 0, 9]\n",
      "Round   7, Average loss 0.331\n",
      "RANDOM USER INDICES [7 8 9]\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "1525799.0\n",
      "430600.0 430600 0.0 0.0\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "1525799.0\n",
      "430600.0 430600 0.0 0.0\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "1525799.0\n",
      "430600.0 430600 0.0 0.0\n",
      "[8, 9, 9, 8, 9, 9, 8, 7, 8, 9]\n",
      "Round   8, Average loss 0.156\n",
      "RANDOM USER INDICES [1 2 5]\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "1548767.4\n",
      "430600.0 430600 0.0 0.0\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "1548767.4\n",
      "430600.0 430600 0.0 0.0\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "1548767.4\n",
      "430600.0 430600 0.0 0.0\n",
      "[2, 1, 2, 2, 5, 5, 5, 5, 5, 5]\n",
      "Round   9, Average loss 0.310\n",
      "Training accuracy: 14.68\n",
      "Testing accuracy: 14.98\n",
=======
      "2420111.5\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   0, Average loss 2.297\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "2519974.2\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   1, Average loss 1.899\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "4509664.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   2, Average loss 0.588\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "8030828.5\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   3, Average loss 0.096\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "9187477.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   4, Average loss 0.001\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "9356810.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   5, Average loss 0.001\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "9447894.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   6, Average loss 0.000\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "9510566.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   7, Average loss 0.000\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "9558353.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   8, Average loss 0.000\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "9597088.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   9, Average loss 0.000\n",
      "Training accuracy: 28.64\n",
      "Testing accuracy: 28.01\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
>>>>>>> cd74fe101214af3549e372085e1c9d4f3a0fafc0
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "mask 10 6 <class 'list'> torch.Size([400, 784])\n",
      "Aggregation over all clients\n",
      "RANDOM USER INDICES [2 8 4]\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
<<<<<<< HEAD
      "1223886.0\n",
      "430600.0 430600 0.0 0.0\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1223886.0\n",
      "430600.0 430600 0.0 0.0\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1223886.0\n",
      "430600.0 430600 0.0 0.0\n",
      "[8, 8, 2, 8, 4, 8, 8, 8, 8, 8]\n",
      "Round   0, Average loss 2.186\n",
      "RANDOM USER INDICES [3 5 1]\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1241850.9\n",
      "430600.0 430600 0.0 0.0\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1241850.9\n",
      "430600.0 430600 0.0 0.0\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1241850.9\n",
      "430600.0 430600 0.0 0.0\n",
      "[5, 1, 5, 3, 5, 5, 5, 5, 3, 5]\n",
      "Round   1, Average loss 1.332\n",
      "RANDOM USER INDICES [2 3 8]\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1312039.2\n",
      "430600.0 430600 0.0 0.0\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1312039.2\n",
      "430600.0 430600 0.0 0.0\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1312039.2\n",
      "430600.0 430600 0.0 0.0\n",
      "[2, 2, 2, 3, 2, 2, 2, 2, 8, 2]\n",
      "Round   2, Average loss 0.819\n",
      "RANDOM USER INDICES [6 1 9]\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1355056.0\n",
      "430600.0 430600 0.0 0.0\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1355056.0\n",
      "430600.0 430600 0.0 0.0\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1355056.0\n",
      "430600.0 430600 0.0 0.0\n",
      "[1, 1, 1, 6, 9, 9, 6, 1, 6, 9]\n",
      "Round   3, Average loss 0.782\n",
      "RANDOM USER INDICES [5 2 7]\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1392036.0\n",
      "430600.0 430600 0.0 0.0\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1392036.0\n",
      "430600.0 430600 0.0 0.0\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1392036.0\n",
      "430600.0 430600 0.0 0.0\n",
      "[5, 2, 2, 5, 5, 5, 5, 7, 5, 5]\n",
      "Round   4, Average loss 0.484\n",
      "RANDOM USER INDICES [1 8 9]\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1440970.4\n",
      "430600.0 430600 0.0 0.0\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1440970.4\n",
      "430600.0 430600 0.0 0.0\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1440970.4\n",
      "430600.0 430600 0.0 0.0\n",
      "[1, 1, 1, 8, 9, 9, 8, 9, 8, 9]\n",
      "Round   5, Average loss 0.325\n",
      "RANDOM USER INDICES [3 2 1]\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1484189.0\n",
      "430600.0 430600 0.0 0.0\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1484189.0\n",
      "430600.0 430600 0.0 0.0\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1484189.0\n",
      "430600.0 430600 0.0 0.0\n",
      "[1, 1, 2, 3, 2, 1, 3, 1, 3, 1]\n",
      "Round   6, Average loss 0.345\n",
      "RANDOM USER INDICES [0 9 2]\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1512516.5\n",
      "430600.0 430600 0.0 0.0\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1512516.5\n",
      "430600.0 430600 0.0 0.0\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1512516.5\n",
      "430600.0 430600 0.0 0.0\n",
      "[0, 2, 2, 0, 9, 9, 9, 9, 0, 9]\n",
      "Round   7, Average loss 0.331\n",
      "RANDOM USER INDICES [7 8 9]\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1525799.0\n",
      "430600.0 430600 0.0 0.0\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1525799.0\n",
      "430600.0 430600 0.0 0.0\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1525799.0\n",
      "430600.0 430600 0.0 0.0\n",
      "[8, 9, 9, 8, 9, 9, 8, 7, 8, 9]\n",
      "Round   8, Average loss 0.156\n",
      "RANDOM USER INDICES [1 2 5]\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1548767.4\n",
      "430600.0 430600 0.0 0.0\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1548767.4\n",
      "430600.0 430600 0.0 0.0\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1548767.4\n",
      "430600.0 430600 0.0 0.0\n",
      "[2, 1, 2, 2, 5, 5, 5, 5, 5, 5]\n",
      "Round   9, Average loss 0.310\n",
      "Training accuracy: 14.68\n",
      "Testing accuracy: 14.98\n",
=======
      "2420111.5\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   0, Average loss 2.297\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "2519974.2\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   1, Average loss 1.899\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "4509664.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   2, Average loss 0.588\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "8030828.5\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   3, Average loss 0.096\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "9187477.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   4, Average loss 0.001\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "9356810.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   5, Average loss 0.001\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "9447894.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   6, Average loss 0.000\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "9510566.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   7, Average loss 0.000\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "9558353.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   8, Average loss 0.000\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "9597088.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   9, Average loss 0.000\n",
      "Training accuracy: 28.64\n",
      "Testing accuracy: 28.01\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
>>>>>>> cd74fe101214af3549e372085e1c9d4f3a0fafc0
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "mask 10 6 <class 'list'> torch.Size([400, 784])\n",
      "Aggregation over all clients\n",
      "RANDOM USER INDICES [2 8 4]\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
<<<<<<< HEAD
      "1223886.0\n",
      "430600.0 430600 0.0 0.0\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1223886.0\n",
      "430600.0 430600 0.0 0.0\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1223886.0\n",
      "430600.0 430600 0.0 0.0\n",
      "[8, 8, 2, 8, 4, 8, 8, 8, 8, 8]\n",
      "Round   0, Average loss 2.186\n",
      "RANDOM USER INDICES [3 5 1]\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1241850.9\n",
      "430600.0 430600 0.0 0.0\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1241850.9\n",
      "430600.0 430600 0.0 0.0\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1241850.9\n",
      "430600.0 430600 0.0 0.0\n",
      "[5, 1, 5, 3, 5, 5, 5, 5, 3, 5]\n",
      "Round   1, Average loss 1.332\n",
      "RANDOM USER INDICES [2 3 8]\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1312039.2\n",
      "430600.0 430600 0.0 0.0\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1312039.2\n",
      "430600.0 430600 0.0 0.0\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1312039.2\n",
      "430600.0 430600 0.0 0.0\n",
      "[2, 2, 2, 3, 2, 2, 2, 2, 8, 2]\n",
      "Round   2, Average loss 0.819\n",
      "RANDOM USER INDICES [6 1 9]\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1355056.0\n",
      "430600.0 430600 0.0 0.0\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1355056.0\n",
      "430600.0 430600 0.0 0.0\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1355056.0\n",
      "430600.0 430600 0.0 0.0\n",
      "[1, 1, 1, 6, 9, 9, 6, 1, 6, 9]\n",
      "Round   3, Average loss 0.782\n",
      "RANDOM USER INDICES [5 2 7]\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1392036.0\n",
      "430600.0 430600 0.0 0.0\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1392036.0\n",
      "430600.0 430600 0.0 0.0\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1392036.0\n",
      "430600.0 430600 0.0 0.0\n",
      "[5, 2, 2, 5, 5, 5, 5, 7, 5, 5]\n",
      "Round   4, Average loss 0.484\n",
      "RANDOM USER INDICES [1 8 9]\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1440970.4\n",
      "430600.0 430600 0.0 0.0\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1440970.4\n",
      "430600.0 430600 0.0 0.0\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1440970.4\n",
      "430600.0 430600 0.0 0.0\n",
      "[1, 1, 1, 8, 9, 9, 8, 9, 8, 9]\n",
      "Round   5, Average loss 0.325\n",
      "RANDOM USER INDICES [3 2 1]\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1484189.0\n",
      "430600.0 430600 0.0 0.0\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1484189.0\n",
      "430600.0 430600 0.0 0.0\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1484189.0\n",
      "430600.0 430600 0.0 0.0\n",
      "[1, 1, 2, 3, 2, 1, 3, 1, 3, 1]\n",
      "Round   6, Average loss 0.345\n",
      "RANDOM USER INDICES [0 9 2]\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1512516.5\n",
      "430600.0 430600 0.0 0.0\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1512516.5\n",
      "430600.0 430600 0.0 0.0\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1512516.5\n",
      "430600.0 430600 0.0 0.0\n",
      "[0, 2, 2, 0, 9, 9, 9, 9, 0, 9]\n",
      "Round   7, Average loss 0.331\n",
      "RANDOM USER INDICES [7 8 9]\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1525799.0\n",
      "430600.0 430600 0.0 0.0\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1525799.0\n",
      "430600.0 430600 0.0 0.0\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1525799.0\n",
      "430600.0 430600 0.0 0.0\n",
      "[8, 9, 9, 8, 9, 9, 8, 7, 8, 9]\n",
      "Round   8, Average loss 0.156\n",
      "RANDOM USER INDICES [1 2 5]\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1548767.4\n",
      "430600.0 430600 0.0 0.0\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1548767.4\n",
      "430600.0 430600 0.0 0.0\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "1548767.4\n",
      "430600.0 430600 0.0 0.0\n",
      "[2, 1, 2, 2, 5, 5, 5, 5, 5, 5]\n",
      "Round   9, Average loss 0.310\n",
      "Training accuracy: 14.68\n",
      "Testing accuracy: 14.98\n",
=======
      "2420111.5\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   0, Average loss 2.297\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "2519974.2\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   1, Average loss 1.899\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "4509664.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   2, Average loss 0.588\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "8030828.5\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   3, Average loss 0.096\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "9187477.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   4, Average loss 0.001\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "9356810.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   5, Average loss 0.001\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "9447894.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   6, Average loss 0.000\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "9510566.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   7, Average loss 0.000\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "9558353.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   8, Average loss 0.000\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "9597088.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   9, Average loss 0.000\n",
      "Training accuracy: 28.64\n",
      "Testing accuracy: 28.01\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
>>>>>>> cd74fe101214af3549e372085e1c9d4f3a0fafc0
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "mask 10 6 <class 'list'> torch.Size([400, 784])\n",
      "Aggregation over all clients\n",
      "RANDOM USER INDICES [2 8 4]\n",
      "fedspa\n",
      "layer collapse if = 0\n",
<<<<<<< HEAD
      "76967.51\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "78963.69\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "76891.39\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "[8, 8, 2, 8, 4, 8, 8, 8, 8, 8]\n",
      "Round   0, Average loss 2.301\n",
      "RANDOM USER INDICES [3 5 1]\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "5106.781\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "4748.1367\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "4975.248\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "[3, 1, 5, 3, 3, 5, 3, 3, 3, 3]\n",
      "Round   1, Average loss 2.303\n",
      "RANDOM USER INDICES [2 3 8]\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "451.27753\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "2544.0767\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "3206.473\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "[8, 8, 2, 3, 8, 8, 8, 8, 8, 8]\n",
      "Round   2, Average loss 2.303\n",
      "RANDOM USER INDICES [6 1 9]\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "168.13048\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "244.2933\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "161.22795\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "[1, 1, 1, 1, 1, 1, 6, 1, 1, 9]\n",
      "Round   3, Average loss 2.303\n",
      "RANDOM USER INDICES [5 2 7]\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "26.190613\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "23.58947\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "14.282673\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "[5, 5, 2, 5, 5, 5, 5, 7, 5, 5]\n",
      "Round   4, Average loss 2.303\n",
      "RANDOM USER INDICES [1 8 9]\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "16.5285\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "22.527433\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "2.0384955\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "[8, 1, 8, 8, 8, 8, 8, 8, 8, 9]\n",
      "Round   5, Average loss 2.303\n",
      "RANDOM USER INDICES [3 2 1]\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "8.20689\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "2.4354653\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "12.491603\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "[1, 1, 2, 3, 1, 1, 3, 1, 1, 1]\n",
      "Round   6, Average loss 2.303\n",
      "RANDOM USER INDICES [0 9 2]\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "0.7103488\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "0.9570352\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "1.6370293\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "[0, 2, 2, 2, 2, 2, 2, 2, 2, 9]\n",
      "Round   7, Average loss 2.303\n",
      "RANDOM USER INDICES [7 8 9]\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "0.12751852\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "1.4131765\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "0.17928794\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "[8, 8, 8, 8, 8, 8, 8, 7, 8, 9]\n",
      "Round   8, Average loss 2.303\n",
      "RANDOM USER INDICES [1 2 5]\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "0.86542404\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "0.7149117\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "0.6341914\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "[1, 1, 2, 1, 1, 5, 1, 1, 1, 1]\n",
      "Round   9, Average loss 2.303\n",
      "Training accuracy: 7.60\n",
      "Testing accuracy: 7.23\n",
=======
      "149896.28\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   0, Average loss 2.302\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "150752.16\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   1, Average loss 2.302\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "152879.17\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   2, Average loss 2.300\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "157382.03\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   3, Average loss 2.281\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "180170.58\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   4, Average loss 1.819\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "336436.66\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   5, Average loss 1.002\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "602565.8\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   6, Average loss 0.595\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "944986.6\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   7, Average loss 0.321\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "1293024.1\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   8, Average loss 0.145\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "1553970.5\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   9, Average loss 0.005\n",
      "Training accuracy: 27.01\n",
      "Testing accuracy: 26.43\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
>>>>>>> cd74fe101214af3549e372085e1c9d4f3a0fafc0
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "mask 10 6 <class 'list'> torch.Size([400, 784])\n",
      "Aggregation over all clients\n",
      "RANDOM USER INDICES [2 8 4]\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
<<<<<<< HEAD
      "820557.5\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "820557.5\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "820557.5\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "[8, 8, 2, 8, 4, 8, 8, 8, 8, 8]\n",
      "Round   0, Average loss 2.201\n",
      "RANDOM USER INDICES [3 5 1]\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "833002.75\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "833002.75\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "833002.75\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "[5, 1, 5, 3, 5, 5, 5, 5, 3, 5]\n",
      "Round   1, Average loss 1.502\n",
      "RANDOM USER INDICES [2 3 8]\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "879718.3\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "879718.3\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "879718.3\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "[2, 2, 2, 3, 2, 2, 2, 2, 8, 2]\n",
      "Round   2, Average loss 0.878\n",
      "RANDOM USER INDICES [6 1 9]\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "917772.8\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "917772.8\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "917772.8\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "[1, 1, 1, 6, 9, 9, 6, 1, 6, 9]\n",
      "Round   3, Average loss 0.858\n",
      "RANDOM USER INDICES [5 2 7]\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "943334.9\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "943334.9\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "943334.9\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "[5, 5, 2, 5, 5, 5, 5, 7, 5, 5]\n",
      "Round   4, Average loss 0.562\n",
      "RANDOM USER INDICES [1 8 9]\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "963187.75\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "963187.75\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "963187.75\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "[1, 1, 1, 8, 9, 1, 8, 9, 8, 9]\n",
      "Round   5, Average loss 0.426\n",
      "RANDOM USER INDICES [3 2 1]\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "1001173.25\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "1001173.25\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "1001173.25\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "[1, 1, 2, 3, 2, 1, 3, 1, 3, 1]\n",
      "Round   6, Average loss 0.322\n",
      "RANDOM USER INDICES [0 9 2]\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "1030014.1\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "1030014.1\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "1030014.1\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "[0, 2, 2, 0, 9, 9, 9, 9, 0, 9]\n",
      "Round   7, Average loss 0.384\n",
      "RANDOM USER INDICES [7 8 9]\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "1044610.3\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "1044610.3\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "1044610.3\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "[8, 9, 9, 8, 9, 9, 8, 7, 8, 9]\n",
      "Round   8, Average loss 0.168\n",
      "RANDOM USER INDICES [1 2 5]\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "1060387.6\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "1060387.6\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "1060387.6\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "[2, 1, 2, 2, 5, 5, 5, 5, 5, 5]\n",
      "Round   9, Average loss 0.401\n",
      "Training accuracy: 12.31\n",
      "Testing accuracy: 12.53\n",
=======
      "1948746.2\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   0, Average loss 2.298\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "2024928.2\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   1, Average loss 1.943\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "3379870.0\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   2, Average loss 0.800\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "5991449.0\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   3, Average loss 0.226\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "7617579.0\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   4, Average loss 0.006\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "8009531.5\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round   5, Average loss 0.001\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "8154034.5\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   6, Average loss 0.001\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "8238777.5\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   7, Average loss 0.000\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "8298459.0\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   8, Average loss 0.000\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "8344463.0\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   9, Average loss 0.000\n",
      "Training accuracy: 28.62\n",
      "Testing accuracy: 28.65\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
>>>>>>> cd74fe101214af3549e372085e1c9d4f3a0fafc0
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "mask 10 6 <class 'list'> torch.Size([400, 784])\n",
      "Aggregation over all clients\n",
      "RANDOM USER INDICES [2 8 4]\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
<<<<<<< HEAD
      "936652.8\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "936652.8\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "936652.8\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "[8, 8, 2, 8, 4, 8, 8, 8, 8, 8]\n",
      "Round   0, Average loss 2.209\n",
      "RANDOM USER INDICES [3 5 1]\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "948691.25\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "948691.25\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "948691.25\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "[5, 1, 5, 3, 5, 5, 5, 5, 3, 5]\n",
      "Round   1, Average loss 1.501\n",
      "RANDOM USER INDICES [2 3 8]\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "1002803.2\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "1002803.2\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "1002803.2\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "[2, 2, 2, 3, 2, 2, 2, 2, 8, 2]\n",
      "Round   2, Average loss 0.893\n",
      "RANDOM USER INDICES [6 1 9]\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "1041439.25\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "1041439.25\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "1041439.25\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "[1, 1, 1, 6, 9, 9, 6, 1, 6, 9]\n",
      "Round   3, Average loss 0.871\n",
      "RANDOM USER INDICES [5 2 7]\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "1062826.2\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "1062826.2\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "1062826.2\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "[5, 5, 2, 5, 5, 5, 5, 7, 5, 5]\n",
      "Round   4, Average loss 0.565\n",
      "RANDOM USER INDICES [1 8 9]\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "1087950.6\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "1087950.6\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "1087950.6\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "[1, 1, 1, 8, 9, 1, 8, 9, 8, 9]\n",
      "Round   5, Average loss 0.429\n",
      "RANDOM USER INDICES [3 2 1]\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "1130176.9\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "1130176.9\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "1130176.9\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "[1, 1, 2, 3, 1, 1, 3, 1, 3, 1]\n",
      "Round   6, Average loss 0.323\n",
      "RANDOM USER INDICES [0 9 2]\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "1158991.6\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "1158991.6\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "1158991.6\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "[0, 2, 2, 0, 9, 9, 9, 9, 0, 9]\n",
      "Round   7, Average loss 0.401\n",
      "RANDOM USER INDICES [7 8 9]\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "1168267.9\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "1168267.9\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "1168267.9\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "[8, 9, 9, 8, 9, 9, 8, 7, 8, 9]\n",
      "Round   8, Average loss 0.166\n",
      "RANDOM USER INDICES [1 2 5]\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "1186624.2\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "1186624.2\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "1186624.2\n",
      "271691.0 430600 158909.76746682878 0.36904265551980675\n",
      "[2, 1, 2, 2, 5, 5, 5, 5, 2, 5]\n",
      "Round   9, Average loss 0.388\n",
      "Training accuracy: 13.58\n",
      "Testing accuracy: 14.14\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "mask 10 6 <class 'list'> torch.Size([400, 784])\n",
      "Aggregation over all clients\n",
      "RANDOM USER INDICES [2 8 4]\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "4871.8965\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "5077.8325\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "4885.0024\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "[4, 4, 2, 4, 4, 4, 4, 4, 8, 4]\n",
      "Round   0, Average loss 2.302\n",
      "RANDOM USER INDICES [3 5 1]\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "21.066187\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "18.984081\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "18.601324\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "[3, 1, 3, 3, 3, 5, 3, 3, 5, 3]\n",
      "Round   1, Average loss 2.303\n",
      "RANDOM USER INDICES [2 3 8]\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "0.19907176\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "6.4315042\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "0.20233677\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "[3, 2, 2, 3, 3, 8, 3, 3, 8, 3]\n",
      "Round   2, Average loss 2.303\n",
      "RANDOM USER INDICES [6 1 9]\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "0.0061958097\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "0.014658026\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "0.007015088\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "[1, 1, 1, 1, 1, 9, 6, 1, 1, 9]\n",
      "Round   3, Average loss 2.303\n",
      "RANDOM USER INDICES [5 2 7]\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "0.0001341991\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "0.0003128529\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "3.327901e-05\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "[2, 2, 2, 5, 2, 5, 2, 7, 5, 2]\n",
      "Round   4, Average loss 2.303\n",
      "RANDOM USER INDICES [1 8 9]\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "7.464235e-05\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "4.3210434e-06\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "3.261227e-06\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 8, 9]\n",
      "Round   5, Average loss 2.303\n",
      "RANDOM USER INDICES [3 2 1]\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "2.8259554e-05\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "1.5812224e-05\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "3.980178e-05\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "[1, 1, 2, 3, 1, 1, 3, 3, 3, 3]\n",
      "Round   6, Average loss 2.303\n",
      "RANDOM USER INDICES [0 9 2]\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "1.3429968e-07\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "3.8909377e-07\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "1.143366e-05\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "[0, 2, 2, 2, 2, 2, 2, 9, 2, 9]\n",
      "Round   7, Average loss 2.303\n",
      "RANDOM USER INDICES [7 8 9]\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "1.8506032e-08\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "9.7419296e-08\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "1.1680977e-07\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "[7, 8, 8, 8, 9, 8, 8, 7, 8, 9]\n",
      "Round   8, Average loss 2.303\n",
      "RANDOM USER INDICES [1 2 5]\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "7.589746e-08\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "7.128378e-08\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "2.9572462e-09\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "[1, 1, 2, 1, 1, 5, 1, 1, 1, 1]\n",
      "Round   9, Average loss 2.303\n",
      "Training accuracy: 7.91\n",
      "Testing accuracy: 8.12\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "mask 10 6 <class 'list'> torch.Size([400, 784])\n",
      "Aggregation over all clients\n",
      "RANDOM USER INDICES [2 8 4]\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "365652.06\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "365652.06\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "365652.06\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "[8, 8, 2, 8, 4, 8, 8, 8, 8, 8]\n",
      "Round   0, Average loss 2.255\n",
      "RANDOM USER INDICES [3 5 1]\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "369023.75\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "369023.75\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "369023.75\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "[1, 1, 1, 3, 1, 5, 1, 1, 1, 1]\n",
      "Round   1, Average loss 1.949\n",
      "RANDOM USER INDICES [2 3 8]\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "381715.1\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "381715.1\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "381715.1\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "[2, 2, 2, 3, 2, 2, 2, 2, 8, 2]\n",
      "Round   2, Average loss 1.192\n",
      "RANDOM USER INDICES [6 1 9]\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "403914.25\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "403914.25\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "403914.25\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "[1, 1, 1, 6, 9, 9, 6, 1, 6, 9]\n",
      "Round   3, Average loss 1.231\n",
      "RANDOM USER INDICES [5 2 7]\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "409369.62\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "409369.62\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "409369.62\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "[5, 2, 2, 2, 5, 5, 5, 7, 5, 5]\n",
      "Round   4, Average loss 0.870\n",
      "RANDOM USER INDICES [1 8 9]\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "419815.28\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "419815.28\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "419815.28\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "[9, 1, 1, 8, 9, 9, 8, 9, 8, 9]\n",
      "Round   5, Average loss 0.873\n",
      "RANDOM USER INDICES [3 2 1]\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "431130.4\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "431130.4\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "431130.4\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "[1, 1, 2, 3, 2, 2, 3, 2, 3, 2]\n",
      "Round   6, Average loss 0.610\n",
      "RANDOM USER INDICES [0 9 2]\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "450633.84\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "450633.84\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "450633.84\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "[0, 2, 2, 0, 0, 9, 0, 0, 0, 9]\n",
      "Round   7, Average loss 0.546\n",
      "RANDOM USER INDICES [7 8 9]\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "468186.28\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "468186.28\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "468186.28\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "[8, 8, 8, 8, 9, 9, 8, 7, 8, 9]\n",
      "Round   8, Average loss 0.314\n",
      "RANDOM USER INDICES [1 2 5]\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "487056.75\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "487056.75\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "487056.75\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "[5, 1, 2, 5, 5, 5, 5, 5, 5, 5]\n",
      "Round   9, Average loss 0.488\n",
      "Training accuracy: 10.90\n",
      "Testing accuracy: 11.12\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "mask 10 6 <class 'list'> torch.Size([400, 784])\n",
      "Aggregation over all clients\n",
      "RANDOM USER INDICES [2 8 4]\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "521812.94\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "521812.94\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "521812.94\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "[8, 8, 2, 8, 4, 8, 8, 8, 8, 8]\n",
      "Round   0, Average loss 2.236\n",
      "RANDOM USER INDICES [3 5 1]\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "527281.3\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "527281.3\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "527281.3\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "[1, 1, 1, 3, 5, 5, 1, 1, 3, 1]\n",
      "Round   1, Average loss 1.702\n",
      "RANDOM USER INDICES [2 3 8]\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "553106.75\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "553106.75\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "553106.75\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "[2, 2, 2, 3, 2, 2, 2, 2, 8, 2]\n",
      "Round   2, Average loss 0.958\n",
      "RANDOM USER INDICES [6 1 9]\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "576143.0\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "576143.0\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "576143.0\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "[1, 1, 1, 6, 9, 9, 6, 1, 6, 9]\n",
      "Round   3, Average loss 1.141\n",
      "RANDOM USER INDICES [5 2 7]\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "578059.06\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "578059.06\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "578059.06\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "[5, 2, 2, 2, 5, 5, 5, 7, 5, 5]\n",
      "Round   4, Average loss 0.857\n",
      "RANDOM USER INDICES [1 8 9]\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "591496.9\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "591496.9\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "591496.9\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "[1, 1, 1, 8, 9, 9, 8, 9, 8, 9]\n",
      "Round   5, Average loss 0.824\n",
      "RANDOM USER INDICES [3 2 1]\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "609606.06\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "609606.06\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "609606.06\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "[1, 1, 2, 3, 1, 1, 3, 1, 3, 2]\n",
      "Round   6, Average loss 0.434\n",
      "RANDOM USER INDICES [0 9 2]\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "638889.1\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "638889.1\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "638889.1\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "[0, 2, 2, 0, 0, 2, 0, 0, 0, 9]\n",
      "Round   7, Average loss 0.489\n",
      "RANDOM USER INDICES [7 8 9]\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "645335.25\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "645335.25\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "645335.25\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "[8, 8, 8, 8, 9, 9, 8, 7, 8, 9]\n",
      "Round   8, Average loss 0.280\n",
      "RANDOM USER INDICES [1 2 5]\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "665933.0\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "665933.0\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "665933.0\n",
      "171425.0 430600 259175.05235966406 0.6018928294465027\n",
      "[5, 1, 2, 2, 5, 5, 5, 5, 5, 5]\n",
      "Round   9, Average loss 0.456\n",
      "Training accuracy: 11.65\n",
      "Testing accuracy: 11.72\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "mask 10 6 <class 'list'> torch.Size([400, 784])\n",
      "Aggregation over all clients\n",
      "RANDOM USER INDICES [2 8 4]\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "285.42685\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "301.21057\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "303.151\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "[4, 4, 2, 4, 4, 4, 4, 4, 8, 4]\n",
      "Round   0, Average loss 2.303\n",
      "RANDOM USER INDICES [3 5 1]\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "0.08966519\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "0.073984854\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "0.07652991\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "[3, 1, 5, 3, 3, 5, 3, 3, 5, 3]\n",
      "Round   1, Average loss 2.303\n",
      "RANDOM USER INDICES [2 3 8]\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "0.00012137765\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "0.010798192\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "7.526604e-05\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "[3, 8, 2, 3, 3, 8, 3, 3, 8, 3]\n",
      "Round   2, Average loss 2.303\n",
      "RANDOM USER INDICES [6 1 9]\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "4.322932e-07\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "1.6803484e-06\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "4.7627114e-07\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "[1, 1, 6, 1, 1, 9, 6, 1, 9, 9]\n",
      "Round   3, Average loss 2.303\n",
      "RANDOM USER INDICES [5 2 7]\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "2.7570193e-09\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "3.9151504e-09\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "1.4476943e-10\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "[5, 5, 2, 5, 5, 5, 5, 7, 5, 5]\n",
      "Round   4, Average loss 2.303\n",
      "RANDOM USER INDICES [1 8 9]\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "3.268841e-10\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "2.661961e-11\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "1.3061262e-11\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "[1, 1, 1, 1, 1, 1, 8, 9, 8, 9]\n",
      "Round   5, Average loss 2.303\n",
      "RANDOM USER INDICES [3 2 1]\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "4.4329467e-11\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "4.996459e-13\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "6.486808e-11\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "[1, 1, 2, 3, 1, 3, 3, 2, 3, 3]\n",
      "Round   6, Average loss 2.303\n",
      "RANDOM USER INDICES [0 9 2]\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "1.5452895e-14\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "1.2529467e-13\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "1.3358557e-13\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "[0, 9, 2, 9, 2, 9, 2, 0, 9, 9]\n",
      "Round   7, Average loss 2.303\n",
      "RANDOM USER INDICES [7 8 9]\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "3.173293e-18\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "1.2560017e-15\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "2.1289738e-14\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "[7, 9, 8, 9, 9, 9, 9, 7, 8, 9]\n",
      "Round   8, Average loss 2.303\n",
      "RANDOM USER INDICES [1 2 5]\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "1.5286587e-15\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "4.990304e-17\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "2.2610242e-15\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "[1, 1, 2, 5, 5, 5, 5, 2, 5, 1]\n",
      "Round   9, Average loss 2.303\n",
      "Training accuracy: 5.81\n",
      "Testing accuracy: 5.65\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "mask 10 6 <class 'list'> torch.Size([400, 784])\n",
      "Aggregation over all clients\n",
      "RANDOM USER INDICES [2 8 4]\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "136374.4\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "136374.4\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "136374.4\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "[8, 8, 2, 8, 4, 8, 8, 8, 8, 8]\n",
      "Round   0, Average loss 2.287\n",
      "RANDOM USER INDICES [3 5 1]\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "136729.9\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "136729.9\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "136729.9\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "[1, 1, 1, 3, 5, 5, 1, 1, 1, 1]\n",
      "Round   1, Average loss 2.279\n",
      "RANDOM USER INDICES [2 3 8]\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "137392.14\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "137392.14\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "137392.14\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "[3, 3, 2, 3, 3, 3, 3, 3, 8, 3]\n",
      "Round   2, Average loss 2.146\n",
      "RANDOM USER INDICES [6 1 9]\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "140170.95\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "140170.95\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "140170.95\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "[9, 1, 1, 9, 9, 9, 6, 9, 9, 9]\n",
      "Round   3, Average loss 1.752\n",
      "RANDOM USER INDICES [5 2 7]\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "147399.28\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "147399.28\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "147399.28\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "[5, 2, 2, 2, 5, 5, 5, 7, 5, 5]\n",
      "Round   4, Average loss 1.103\n",
      "RANDOM USER INDICES [1 8 9]\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "154272.14\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "154272.14\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "154272.14\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "[9, 1, 1, 8, 9, 9, 8, 9, 8, 9]\n",
      "Round   5, Average loss 1.149\n",
      "RANDOM USER INDICES [3 2 1]\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "156351.61\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "156351.61\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "156351.61\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "[1, 1, 2, 3, 1, 2, 3, 2, 3, 2]\n",
      "Round   6, Average loss 0.950\n",
      "RANDOM USER INDICES [0 9 2]\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "159686.88\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "159686.88\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "159686.88\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "[0, 2, 2, 2, 2, 2, 0, 0, 0, 9]\n",
      "Round   7, Average loss 0.904\n",
      "RANDOM USER INDICES [7 8 9]\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "162317.69\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "162317.69\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "162317.69\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "[7, 9, 9, 8, 7, 7, 7, 7, 8, 9]\n",
      "Round   8, Average loss 0.879\n",
      "RANDOM USER INDICES [1 2 5]\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "165431.12\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "165431.12\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "165431.12\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "[2, 1, 2, 2, 5, 5, 5, 5, 2, 5]\n",
      "Round   9, Average loss 0.811\n",
      "Training accuracy: 9.93\n",
      "Testing accuracy: 10.32\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "mask 10 6 <class 'list'> torch.Size([400, 784])\n",
      "Aggregation over all clients\n",
      "RANDOM USER INDICES [2 8 4]\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "277410.84\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "277410.84\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "277410.84\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "[8, 8, 2, 8, 4, 8, 8, 8, 8, 8]\n",
      "Round   0, Average loss 2.281\n",
      "RANDOM USER INDICES [3 5 1]\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "278739.53\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "278739.53\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "278739.53\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "[1, 1, 1, 3, 1, 5, 1, 1, 1, 1]\n",
      "Round   1, Average loss 2.218\n",
      "RANDOM USER INDICES [2 3 8]\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "281625.78\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "281625.78\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "281625.78\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "[2, 2, 2, 3, 2, 2, 2, 2, 8, 2]\n",
      "Round   2, Average loss 1.642\n",
      "RANDOM USER INDICES [6 1 9]\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "301592.22\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "301592.22\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "301592.22\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "[1, 1, 1, 6, 9, 9, 6, 1, 6, 9]\n",
      "Round   3, Average loss 1.300\n",
      "RANDOM USER INDICES [5 2 7]\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "304895.2\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "304895.2\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "304895.2\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "[5, 2, 2, 2, 5, 5, 5, 7, 5, 5]\n",
      "Round   4, Average loss 0.890\n",
      "RANDOM USER INDICES [1 8 9]\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "312491.34\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "312491.34\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "312491.34\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "[1, 1, 1, 8, 9, 9, 8, 9, 8, 9]\n",
      "Round   5, Average loss 1.019\n",
      "RANDOM USER INDICES [3 2 1]\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "312805.56\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "312805.56\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "312805.56\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "[1, 1, 2, 3, 2, 2, 3, 2, 3, 2]\n",
      "Round   6, Average loss 0.773\n",
      "RANDOM USER INDICES [0 9 2]\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "324524.6\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "324524.6\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "324524.6\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "[0, 2, 2, 0, 9, 9, 0, 0, 0, 9]\n",
      "Round   7, Average loss 0.812\n",
      "RANDOM USER INDICES [7 8 9]\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "327843.97\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "327843.97\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "327843.97\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "[8, 9, 8, 8, 9, 9, 9, 7, 8, 9]\n",
      "Round   8, Average loss 0.570\n",
      "RANDOM USER INDICES [1 2 5]\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "339434.6\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "339434.6\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "339434.6\n",
      "108162.0 430600 322438.1702591975 0.748811356849042\n",
      "[5, 1, 2, 2, 5, 5, 5, 5, 5, 5]\n",
      "Round   9, Average loss 0.519\n",
      "Training accuracy: 10.76\n",
      "Testing accuracy: 11.12\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "mask 10 6 <class 'list'> torch.Size([400, 784])\n",
      "Aggregation over all clients\n",
      "RANDOM USER INDICES [2 8 4]\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "16.814198\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "19.48233\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "18.109743\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "[4, 4, 2, 4, 4, 4, 4, 4, 8, 4]\n",
      "Round   0, Average loss 2.303\n",
      "RANDOM USER INDICES [3 5 1]\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "0.00042695034\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "0.0003243005\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "0.0002554969\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "[3, 1, 5, 3, 3, 5, 3, 3, 5, 3]\n",
      "Round   1, Average loss 2.303\n",
      "RANDOM USER INDICES [2 3 8]\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "4.6436497e-08\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "3.522379e-05\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "9.0563645e-08\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "[3, 8, 2, 3, 3, 8, 3, 3, 8, 3]\n",
      "Round   2, Average loss 2.303\n",
      "RANDOM USER INDICES [6 1 9]\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "1.693996e-10\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "7.085832e-11\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "1.03126875e-10\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "[1, 1, 9, 1, 1, 6, 6, 1, 1, 9]\n",
      "Round   3, Average loss 2.303\n",
      "RANDOM USER INDICES [5 2 7]\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "2.6348366e-14\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "7.872159e-15\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "4.0514235e-18\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "[5, 5, 2, 5, 5, 5, 5, 7, 5, 2]\n",
      "Round   4, Average loss 2.303\n",
      "RANDOM USER INDICES [1 8 9]\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "5.0359433e-16\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "2.5958747e-17\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "3.1394066e-18\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "[1, 1, 1, 1, 1, 1, 8, 8, 8, 9]\n",
      "Round   5, Average loss 2.303\n",
      "RANDOM USER INDICES [3 2 1]\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "8.784269e-19\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "4.278948e-18\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "1.2646992e-16\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "[1, 1, 2, 3, 1, 3, 3, 3, 3, 2]\n",
      "Round   6, Average loss 2.303\n",
      "RANDOM USER INDICES [0 9 2]\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "6.456068e-28\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "2.7318894e-23\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "8.73758e-19\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "[0, 2, 2, 2, 2, 9, 9, 9, 9, 9]\n",
      "Round   7, Average loss 2.303\n",
      "RANDOM USER INDICES [7 8 9]\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "1.7040536e-32\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "4.813291e-22\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "3.1151247e-24\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "[7, 9, 8, 9, 9, 9, 8, 7, 8, 9]\n",
      "Round   8, Average loss 2.303\n",
      "RANDOM USER INDICES [1 2 5]\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "1.3085222e-24\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "2.4210196e-24\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "3.375328e-26\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "[2, 1, 2, 1, 1, 5, 5, 1, 5, 1]\n",
      "Round   9, Average loss 2.303\n",
      "Training accuracy: 13.02\n",
      "Testing accuracy: 13.89\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "mask 10 6 <class 'list'> torch.Size([400, 784])\n",
      "Aggregation over all clients\n",
      "RANDOM USER INDICES [2 8 4]\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "38470.734\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "38470.734\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "38470.734\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "[8, 8, 2, 8, 4, 8, 8, 8, 8, 8]\n",
      "Round   0, Average loss 2.297\n",
      "RANDOM USER INDICES [3 5 1]\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "38495.5\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "38495.5\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "38495.5\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "[3, 1, 1, 3, 5, 5, 3, 3, 3, 3]\n",
      "Round   1, Average loss 2.297\n",
      "RANDOM USER INDICES [2 3 8]\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "38554.133\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "38554.133\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "38554.133\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "[3, 2, 2, 3, 2, 2, 3, 3, 8, 3]\n",
      "Round   2, Average loss 2.295\n",
      "RANDOM USER INDICES [6 1 9]\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "38661.53\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "38661.53\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "38661.53\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "[1, 1, 1, 6, 1, 1, 6, 1, 6, 9]\n",
      "Round   3, Average loss 2.291\n",
      "RANDOM USER INDICES [5 2 7]\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "38815.652\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "38815.652\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "38815.652\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "[7, 7, 2, 7, 7, 5, 7, 7, 7, 7]\n",
      "Round   4, Average loss 2.264\n",
      "RANDOM USER INDICES [1 8 9]\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "39101.207\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "39101.207\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "39101.207\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "[8, 1, 1, 8, 8, 1, 8, 8, 8, 9]\n",
      "Round   5, Average loss 2.264\n",
      "RANDOM USER INDICES [3 2 1]\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "39440.977\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "39440.977\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "39440.977\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "[1, 1, 2, 3, 1, 1, 3, 1, 3, 1]\n",
      "Round   6, Average loss 2.090\n",
      "RANDOM USER INDICES [0 9 2]\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "40842.027\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "40842.027\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "40842.027\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "[0, 2, 2, 0, 9, 9, 0, 9, 0, 9]\n",
      "Round   7, Average loss 1.504\n",
      "RANDOM USER INDICES [7 8 9]\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "42865.74\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "42865.74\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "42865.74\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "[8, 7, 7, 8, 7, 7, 7, 7, 8, 9]\n",
      "Round   8, Average loss 1.128\n",
      "RANDOM USER INDICES [1 2 5]\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "44951.273\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "44951.273\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "44951.273\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "[1, 1, 2, 2, 5, 5, 5, 5, 5, 5]\n",
      "Round   9, Average loss 1.168\n",
      "Training accuracy: 9.93\n",
      "Testing accuracy: 10.32\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
=======
      "2027163.0\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   0, Average loss 2.297\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "2110189.8\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   1, Average loss 1.935\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "3525235.2\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   2, Average loss 0.732\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "6295091.5\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   3, Average loss 0.175\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "7798777.0\n",
      "849142.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   4, Average loss 0.003\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "8039928.5\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   5, Average loss 0.001\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "8149842.0\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   6, Average loss 0.000\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "8220465.0\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   7, Average loss 0.000\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "8272440.5\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   8, Average loss 0.000\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "8313535.0\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   9, Average loss 0.000\n",
      "Training accuracy: 29.17\n",
      "Testing accuracy: 29.05\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "8962.486\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   0, Average loss 2.303\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "8974.103\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   1, Average loss 2.302\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "8993.798\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   2, Average loss 2.302\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "9021.914\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   3, Average loss 2.302\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "9059.687\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   4, Average loss 2.302\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "9110.454\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   5, Average loss 2.302\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "9177.576\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   6, Average loss 2.302\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "9271.127\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   7, Average loss 2.302\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "9417.74\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   8, Average loss 2.300\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "9762.429\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   9, Average loss 2.250\n",
      "Training accuracy: 10.00\n",
      "Testing accuracy: 10.03\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "1255251.1\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   0, Average loss 2.299\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "1290896.5\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   1, Average loss 2.186\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "1722882.6\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   2, Average loss 1.148\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "3570772.2\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   3, Average loss 0.260\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "4998709.5\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   4, Average loss 0.006\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "5314379.0\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   5, Average loss 0.002\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "5463090.5\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   6, Average loss 0.001\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "5554181.5\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   7, Average loss 0.001\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "5618131.0\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   8, Average loss 0.001\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "5666919.0\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   9, Average loss 0.000\n",
      "Training accuracy: 28.77\n",
      "Testing accuracy: 28.61\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "1378031.5\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   0, Average loss 2.299\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "1421268.0\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   1, Average loss 2.180\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "1884614.2\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   2, Average loss 1.077\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "3893318.5\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   3, Average loss 0.296\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "5243663.0\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   4, Average loss 0.016\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "5627541.0\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   5, Average loss 0.002\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "5753847.0\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round   6, Average loss 0.001\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "5828608.5\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   7, Average loss 0.001\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "5880727.5\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   8, Average loss 0.000\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "5920438.0\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   9, Average loss 0.000\n",
      "Training accuracy: 29.24\n",
      "Testing accuracy: 28.90\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "589.4397\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   0, Average loss 2.303\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "589.5833\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   1, Average loss 2.303\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "589.7736\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   2, Average loss 2.303\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "590.0084\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   3, Average loss 2.303\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "590.2868\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   4, Average loss 2.303\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "590.6083\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   5, Average loss 2.303\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "590.97186\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   6, Average loss 2.303\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "591.3771\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   7, Average loss 2.303\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "591.8229\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   8, Average loss 2.303\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "592.3091\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   9, Average loss 2.303\n",
      "Training accuracy: 12.97\n",
      "Testing accuracy: 12.94\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "721483.5\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   0, Average loss 2.300\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "735929.1\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   1, Average loss 2.260\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "871832.6\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   2, Average loss 1.533\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "1670523.2\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   3, Average loss 0.630\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "2665078.8\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   4, Average loss 0.284\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "3467986.2\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   5, Average loss 0.129\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "4026201.0\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   6, Average loss 0.003\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "4154361.0\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   7, Average loss 0.001\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "4224863.0\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   8, Average loss 0.001\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "4271456.0\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   9, Average loss 0.001\n",
      "Training accuracy: 29.44\n",
      "Testing accuracy: 29.77\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "819641.2\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   0, Average loss 2.299\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "840834.44\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   1, Average loss 2.219\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "1048331.0\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   2, Average loss 1.353\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "2098099.2\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   3, Average loss 0.471\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "3191489.2\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   4, Average loss 0.120\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "3749482.5\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   5, Average loss 0.103\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "4076036.5\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   6, Average loss 0.002\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "4186675.2\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   7, Average loss 0.001\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "4248909.5\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   8, Average loss 0.001\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "4291066.5\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   9, Average loss 0.000\n",
      "Training accuracy: 29.49\n",
      "Testing accuracy: 28.97\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "36.876144\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   0, Average loss 2.303\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "36.87526\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   1, Average loss 2.303\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "36.874718\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   2, Average loss 2.303\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "36.874508\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   3, Average loss 2.303\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "36.87463\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   4, Average loss 2.303\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "36.875095\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   5, Average loss 2.303\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "36.875877\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   6, Average loss 2.303\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "36.876984\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   7, Average loss 2.303\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "36.878403\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round   8, Average loss 2.303\n",
      "fedspa\n",
      "layer collapse if = 0\n",
      "36.880135\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   9, Average loss 2.303\n",
      "Training accuracy: 9.82\n",
      "Testing accuracy: 10.09\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "371311.38\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   0, Average loss 2.300\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "378178.22\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   1, Average loss 2.276\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "423672.75\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   2, Average loss 1.721\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "730151.6\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   3, Average loss 1.009\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "1215573.4\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   4, Average loss 0.520\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "1831827.4\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   5, Average loss 0.252\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "2410844.0\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   6, Average loss 0.119\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "2703498.8\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   7, Average loss 0.083\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "2984234.0\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   8, Average loss 0.122\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "3372021.5\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   9, Average loss 0.004\n",
      "Training accuracy: 29.38\n",
      "Testing accuracy: 29.27\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
>>>>>>> cd74fe101214af3549e372085e1c9d4f3a0fafc0
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
<<<<<<< HEAD
      "mask 10 6 <class 'list'> torch.Size([400, 784])\n",
      "Aggregation over all clients\n",
      "RANDOM USER INDICES [2 8 4]\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "131035.06\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "131035.06\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "131035.06\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "[8, 8, 2, 8, 4, 8, 8, 8, 8, 8]\n",
      "Round   0, Average loss 2.295\n",
      "RANDOM USER INDICES [3 5 1]\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "131300.52\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "131300.52\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "131300.52\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "[1, 1, 1, 3, 5, 5, 1, 1, 1, 1]\n",
      "Round   1, Average loss 2.292\n",
      "RANDOM USER INDICES [2 3 8]\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "131569.23\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "131569.23\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "131569.23\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "[3, 3, 2, 3, 3, 3, 3, 3, 8, 3]\n",
      "Round   2, Average loss 2.269\n",
      "RANDOM USER INDICES [6 1 9]\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "132389.25\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "132389.25\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "132389.25\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "[9, 1, 1, 9, 9, 9, 6, 9, 9, 9]\n",
      "Round   3, Average loss 2.144\n",
      "RANDOM USER INDICES [5 2 7]\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "134940.69\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "134940.69\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "134940.69\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "[5, 2, 2, 5, 5, 5, 5, 7, 5, 5]\n",
      "Round   4, Average loss 1.519\n",
      "RANDOM USER INDICES [1 8 9]\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "143463.22\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "143463.22\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "143463.22\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "[9, 1, 1, 8, 9, 9, 8, 9, 8, 9]\n",
      "Round   5, Average loss 1.178\n",
      "RANDOM USER INDICES [3 2 1]\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "146304.33\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "146304.33\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "146304.33\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "[1, 1, 2, 3, 1, 2, 3, 1, 3, 2]\n",
      "Round   6, Average loss 0.971\n",
      "RANDOM USER INDICES [0 9 2]\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "148378.52\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "148378.52\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "148378.52\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "[0, 2, 2, 2, 9, 2, 0, 0, 0, 9]\n",
      "Round   7, Average loss 0.925\n",
      "RANDOM USER INDICES [7 8 9]\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "149277.14\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "149277.14\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "149277.14\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "[8, 7, 8, 8, 7, 7, 8, 7, 8, 9]\n",
      "Round   8, Average loss 0.867\n",
      "RANDOM USER INDICES [1 2 5]\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "151278.98\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "151278.98\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "151278.98\n",
      "68246.0 430600 362354.4991326245 0.8415106807538887\n",
      "[2, 1, 2, 2, 5, 5, 5, 5, 2, 5]\n",
      "Round   9, Average loss 0.906\n",
      "Training accuracy: 9.93\n",
      "Testing accuracy: 10.32\n",
      "synflow test accuracy:  [tensor(14.9800), tensor(14.1400), tensor(11.7200), tensor(11.1200), tensor(10.3200)]\n",
      "mag test accuracy:  [tensor(14.9800), tensor(12.5300), tensor(11.1200), tensor(10.3200), tensor(10.3200)]\n"
=======
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "472993.62\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   0, Average loss 2.301\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "481262.28\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   1, Average loss 2.287\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "526932.75\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   2, Average loss 1.798\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "903582.0\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   3, Average loss 0.911\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "1586285.8\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   4, Average loss 0.445\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "2401960.0\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   5, Average loss 0.150\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "3016390.5\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   6, Average loss 0.076\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "3306391.5\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   7, Average loss 0.005\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "3411472.0\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\Documents\\GitHub\\federated-learning\\layer-collapse.py:116\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m idxs_users:\n\u001b[0;32m    115\u001b[0m     local \u001b[38;5;241m=\u001b[39m LocalUpdate(args\u001b[38;5;241m=\u001b[39margs, dataset\u001b[38;5;241m=\u001b[39mdataset_train, idxs\u001b[38;5;241m=\u001b[39mdict_users[idx])\n\u001b[1;32m--> 116\u001b[0m     w, loss, mask \u001b[38;5;241m=\u001b[39m local\u001b[38;5;241m.\u001b[39mtrain(net\u001b[38;5;241m=\u001b[39mcopy\u001b[38;5;241m.\u001b[39mdeepcopy(net_glob)\u001b[38;5;241m.\u001b[39mto(args\u001b[38;5;241m.\u001b[39mdevice), mask\u001b[38;5;241m=\u001b[39mmasks[idx])\n\u001b[0;32m    117\u001b[0m     masks[idx] \u001b[38;5;241m=\u001b[39m mask\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mall_clients:\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\federated-learning\\models\\Update.py:91\u001b[0m, in \u001b[0;36mLocalUpdate.train\u001b[1;34m(self, net, mask)\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;129;01mand\u001b[39;00m batch_idx \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     88\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUpdate Epoch: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m [\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{:.0f}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m)]\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mLoss: \u001b[39m\u001b[38;5;132;01m{:.6f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m     89\u001b[0m                 \u001b[38;5;28miter\u001b[39m, batch_idx \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(images), \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mldr_train\u001b[38;5;241m.\u001b[39mdataset),\n\u001b[0;32m     90\u001b[0m                        \u001b[38;5;241m100.\u001b[39m \u001b[38;5;241m*\u001b[39m batch_idx \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mldr_train), loss\u001b[38;5;241m.\u001b[39mitem()))\n\u001b[1;32m---> 91\u001b[0m         batch_loss\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m     92\u001b[0m     epoch_loss\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28msum\u001b[39m(batch_loss)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(batch_loss))\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m net\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;28msum\u001b[39m(epoch_loss) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(epoch_loss), mask\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
>>>>>>> cd74fe101214af3549e372085e1c9d4f3a0fafc0
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
<<<<<<< HEAD
    "%run ../layer-collapse-similarity.py --model mlp --dataset mnist --epochs 10 --local_ep 1 --gpu -1 --num_channels 1 --num_users 10 --frac 0.3 --compression 10 --prune_epochs 100 --pruner mag --all_clients"
=======
    "%run ../layer-collapse.py --iid --model mlp --dataset cifar --epochs 10 --local_ep 20 --gpu -0 --num_channels 1 --num_users 100 --frac 0.1 --compression 10 --prune_epochs 100 --pruner mag"
>>>>>>> cd74fe101214af3549e372085e1c9d4f3a0fafc0
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Testing plots\n",
    "\n",
    "- The code below is for testing plots from the results printed by manually copying them.\n",
    "- To plot the results directly, uncomment the `plt.show()` line\n",
    "- To save the results, uncomment the `plt.savefig()` line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "y = {}\n",
    "iters = 30\n",
    "alphas = [i/5 for i in range(iters)]\n",
    "y['synflow'] = [torch.tensor(97.7400), torch.tensor(97.6300), torch.tensor(97.5300), torch.tensor(97.5300), torch.tensor(97.6400), torch.tensor(97.2400), torch.tensor(96.3500), torch.tensor(95.5000), torch.tensor(94.8100), torch.tensor(93.3100), torch.tensor(89.5500), torch.tensor(71.1400), torch.tensor(42.9200), torch.tensor(10.1600), torch.tensor(11.9300), torch.tensor(9.1900), torch.tensor(14.0700), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000)]\n",
    "y['mag'] = [torch.tensor(97.4500), torch.tensor(97.0300), torch.tensor(97.2700), torch.tensor(97.6600), torch.tensor(97.6800), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000)]\n",
    "x_vals = [10**alpha for alpha in alphas]\n",
    "plt.figure()\n",
    "plt.xscale('log')\n",
    "plt.plot(x_vals, y['synflow'], label='Synflow', linestyle='-', marker='o', color='r')\n",
    "plt.plot(x_vals, y['mag'], label='Mag', linestyle='-', marker='o', color='b')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Y-axis')\n",
    "plt.title('Synflow vs Mag')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Save plot\n",
    "plt.savefig('../save/tesasdt-plot.png'.format())\n",
    "\n",
    "# Show plot\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "example",
   "language": "python",
   "name": "example"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

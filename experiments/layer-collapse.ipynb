{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# Python version: 3.6\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "\n",
    "from utils.sampling import mnist_iid, mnist_noniid, cifar_iid\n",
    "from utils.options import args_parser\n",
    "from models.Update import LocalUpdate\n",
    "from models.Nets import MLP, CNNMnist, CNNCifar\n",
    "from models.Fed import FedAvg\n",
    "from models.test import test_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seed settings\n",
    "- If you want the seed to be set manually, uncomment and set the seed value in these files:\n",
    "- also change uncomment the lines with `torch.backends.cudnn.deterministic = True`\n",
    "1. utils/sampling.py\n",
    "2. main_fed.py\n",
    "3. models/Nets.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the layer-colapse.py\n",
    "- This command is equivalent to running it from the console\n",
    "- Results are saved in federated-learning/save/test.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 20\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: fedspa\n",
      "sparsity:  0.2056717652757185\n",
      "Round   0, Average loss 1.049\n",
      "Round   1, Average loss 0.229\n",
      "Round   2, Average loss 0.126\n",
      "Round   3, Average loss 0.072\n",
      "Round   4, Average loss 0.089\n",
      "Round   5, Average loss 0.053\n",
      "Round   6, Average loss 0.061\n",
      "Round   7, Average loss 0.075\n",
      "Round   8, Average loss 0.055\n",
      "Round   9, Average loss 0.060\n",
      "Round  10, Average loss 0.055\n",
      "Round  11, Average loss 0.062\n",
      "Round  12, Average loss 0.043\n",
      "Round  13, Average loss 0.044\n",
      "Round  14, Average loss 0.067\n",
      "Round  15, Average loss 0.029\n",
      "Round  16, Average loss 0.030\n",
      "Round  17, Average loss 0.033\n",
      "Round  18, Average loss 0.041\n",
      "Round  19, Average loss 0.046\n",
      "Training accuracy: 41.17\n",
      "Testing accuracy: 42.50\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: mag\n",
      "sparsity:  0.2056717652757185\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "Round   0, Average loss 0.746\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "Round   1, Average loss 0.178\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "Round   2, Average loss 0.106\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "Round   3, Average loss 0.062\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "Round   4, Average loss 0.079\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "Round   5, Average loss 0.054\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "Round   6, Average loss 0.056\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "Round   7, Average loss 0.065\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "Round   8, Average loss 0.047\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "Round   9, Average loss 0.060\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "Round  10, Average loss 0.051\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "Round  11, Average loss 0.057\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "Round  12, Average loss 0.040\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "Round  13, Average loss 0.046\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "Round  14, Average loss 0.053\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "Round  15, Average loss 0.027\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "Round  16, Average loss 0.028\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "Round  17, Average loss 0.026\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "Round  18, Average loss 0.030\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "Round  19, Average loss 0.041\n",
      "Training accuracy: 50.92\n",
      "Testing accuracy: 52.22\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: synflow\n",
      "sparsity:  0.2056717652757185\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "Round   0, Average loss 0.750\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "Round   1, Average loss 0.176\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "Round   2, Average loss 0.105\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "Round   3, Average loss 0.061\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "Round   4, Average loss 0.078\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "Round   5, Average loss 0.051\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "Round   6, Average loss 0.056\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "Round   7, Average loss 0.063\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "Round   8, Average loss 0.046\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "Round   9, Average loss 0.061\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "Round  10, Average loss 0.050\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "Round  11, Average loss 0.057\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "Round  12, Average loss 0.039\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "Round  13, Average loss 0.046\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "Round  14, Average loss 0.052\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "Round  15, Average loss 0.028\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "Round  16, Average loss 0.028\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "Round  17, Average loss 0.026\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "Round  18, Average loss 0.030\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "1.2589254117941673\n",
      "Round  19, Average loss 0.041\n",
      "Training accuracy: 50.93\n",
      "Testing accuracy: 52.06\n",
      "1 / 20\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: fedspa\n",
      "sparsity:  0.36904265551980675\n",
      "Round   0, Average loss 1.518\n",
      "Round   1, Average loss 0.550\n",
      "Round   2, Average loss 0.224\n",
      "Round   3, Average loss 0.137\n",
      "Round   4, Average loss 0.123\n",
      "Round   5, Average loss 0.063\n",
      "Round   6, Average loss 0.078\n",
      "Round   7, Average loss 0.076\n",
      "Round   8, Average loss 0.065\n",
      "Round   9, Average loss 0.066\n",
      "Round  10, Average loss 0.067\n",
      "Round  11, Average loss 0.066\n",
      "Round  12, Average loss 0.044\n",
      "Round  13, Average loss 0.051\n",
      "Round  14, Average loss 0.071\n",
      "Round  15, Average loss 0.031\n",
      "Round  16, Average loss 0.039\n",
      "Round  17, Average loss 0.037\n",
      "Round  18, Average loss 0.042\n",
      "Round  19, Average loss 0.048\n",
      "Training accuracy: 34.51\n",
      "Testing accuracy: 35.50\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: mag\n",
      "sparsity:  0.36904265551980675\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "Round   0, Average loss 0.768\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "Round   1, Average loss 0.196\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "Round   2, Average loss 0.112\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "Round   3, Average loss 0.064\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "Round   4, Average loss 0.083\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "Round   5, Average loss 0.056\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "Round   6, Average loss 0.061\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "Round   7, Average loss 0.064\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "Round   8, Average loss 0.057\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "Round   9, Average loss 0.062\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "Round  10, Average loss 0.053\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "Round  11, Average loss 0.062\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "Round  12, Average loss 0.041\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "Round  13, Average loss 0.051\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "Round  14, Average loss 0.058\n",
      "1.5848931924611136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "Round  15, Average loss 0.030\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "Round  16, Average loss 0.032\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "Round  17, Average loss 0.028\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "Round  18, Average loss 0.032\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "Round  19, Average loss 0.045\n",
      "Training accuracy: 47.28\n",
      "Testing accuracy: 48.27\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: synflow\n",
      "sparsity:  0.36904265551980675\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "Round   0, Average loss 0.772\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "Round   1, Average loss 0.188\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "Round   2, Average loss 0.104\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "Round   3, Average loss 0.063\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "Round   4, Average loss 0.087\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "Round   5, Average loss 0.054\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "Round   6, Average loss 0.061\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "Round   7, Average loss 0.063\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "Round   8, Average loss 0.054\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "Round   9, Average loss 0.061\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "Round  10, Average loss 0.054\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "Round  11, Average loss 0.060\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "Round  12, Average loss 0.042\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "Round  13, Average loss 0.049\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "Round  14, Average loss 0.056\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "Round  15, Average loss 0.032\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "Round  16, Average loss 0.030\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "Round  17, Average loss 0.030\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "Round  18, Average loss 0.031\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "1.5848931924611136\n",
      "Round  19, Average loss 0.043\n",
      "Training accuracy: 48.67\n",
      "Testing accuracy: 49.92\n",
      "2 / 20\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: fedspa\n",
      "sparsity:  0.49881276637272765\n",
      "Round   0, Average loss 2.171\n",
      "Round   1, Average loss 1.063\n",
      "Round   2, Average loss 0.589\n",
      "Round   3, Average loss 0.225\n",
      "Round   4, Average loss 0.173\n",
      "Round   5, Average loss 0.078\n",
      "Round   6, Average loss 0.111\n",
      "Round   7, Average loss 0.094\n",
      "Round   8, Average loss 0.078\n",
      "Round   9, Average loss 0.099\n",
      "Round  10, Average loss 0.086\n",
      "Round  11, Average loss 0.098\n",
      "Round  12, Average loss 0.065\n",
      "Round  13, Average loss 0.078\n",
      "Round  14, Average loss 0.113\n",
      "Round  15, Average loss 0.041\n",
      "Round  16, Average loss 0.044\n",
      "Round  17, Average loss 0.052\n",
      "Round  18, Average loss 0.051\n",
      "Round  19, Average loss 0.072\n",
      "Training accuracy: 24.63\n",
      "Testing accuracy: 25.70\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: mag\n",
      "sparsity:  0.49881276637272765\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "Round   0, Average loss 0.828\n",
      "1.9952623149688795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "Round   1, Average loss 0.230\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "Round   2, Average loss 0.132\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "Round   3, Average loss 0.071\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "Round   4, Average loss 0.083\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "Round   5, Average loss 0.057\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "Round   6, Average loss 0.062\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "Round   7, Average loss 0.065\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "Round   8, Average loss 0.051\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "Round   9, Average loss 0.064\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "Round  10, Average loss 0.057\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "Round  11, Average loss 0.066\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "Round  12, Average loss 0.042\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "Round  13, Average loss 0.050\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "Round  14, Average loss 0.064\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "Round  15, Average loss 0.032\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "Round  16, Average loss 0.030\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "Round  17, Average loss 0.032\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "Round  18, Average loss 0.033\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "Round  19, Average loss 0.047\n",
      "Training accuracy: 51.33\n",
      "Testing accuracy: 52.92\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: synflow\n",
      "sparsity:  0.49881276637272765\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "Round   0, Average loss 0.777\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "Round   1, Average loss 0.203\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "Round   2, Average loss 0.115\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "Round   3, Average loss 0.062\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "Round   4, Average loss 0.088\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "Round   5, Average loss 0.055\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "Round   6, Average loss 0.059\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "Round   7, Average loss 0.065\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "Round   8, Average loss 0.059\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "Round   9, Average loss 0.063\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "Round  10, Average loss 0.057\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "Round  11, Average loss 0.070\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "Round  12, Average loss 0.045\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "Round  13, Average loss 0.050\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "Round  14, Average loss 0.065\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "Round  15, Average loss 0.033\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "Round  16, Average loss 0.032\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "Round  17, Average loss 0.030\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "Round  18, Average loss 0.032\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "1.9952623149688795\n",
      "Round  19, Average loss 0.045\n",
      "Training accuracy: 49.62\n",
      "Testing accuracy: 51.04\n",
      "3 / 20\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: fedspa\n",
      "sparsity:  0.6018928294465027\n",
      "Round   0, Average loss 2.299\n",
      "Round   1, Average loss 2.057\n",
      "Round   2, Average loss 0.963\n",
      "Round   3, Average loss 0.647\n",
      "Round   4, Average loss 0.695\n",
      "Round   5, Average loss 0.538\n",
      "Round   6, Average loss 0.547\n",
      "Round   7, Average loss 0.296\n",
      "Round   8, Average loss 0.196\n",
      "Round   9, Average loss 0.127\n",
      "Round  10, Average loss 0.132\n",
      "Round  11, Average loss 0.102\n",
      "Round  12, Average loss 0.069\n",
      "Round  13, Average loss 0.083\n",
      "Round  14, Average loss 0.096\n",
      "Round  15, Average loss 0.038\n",
      "Round  16, Average loss 0.048\n",
      "Round  17, Average loss 0.048\n",
      "Round  18, Average loss 0.060\n",
      "Round  19, Average loss 0.068\n",
      "Training accuracy: 31.53\n",
      "Testing accuracy: 31.75\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: mag\n",
      "sparsity:  0.6018928294465027\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "Round   0, Average loss 0.849\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "Round   1, Average loss 0.260\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "Round   2, Average loss 0.150\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "Round   3, Average loss 0.076\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "Round   4, Average loss 0.089\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "Round   5, Average loss 0.060\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "Round   6, Average loss 0.066\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "Round   7, Average loss 0.073\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "Round   8, Average loss 0.058\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "Round   9, Average loss 0.068\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "Round  10, Average loss 0.061\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "Round  11, Average loss 0.071\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "Round  12, Average loss 0.048\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "Round  13, Average loss 0.055\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "Round  14, Average loss 0.070\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "Round  15, Average loss 0.037\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "Round  16, Average loss 0.035\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "Round  17, Average loss 0.035\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "Round  18, Average loss 0.035\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "Round  19, Average loss 0.052\n",
      "Training accuracy: 43.87\n",
      "Testing accuracy: 44.94\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: synflow\n",
      "sparsity:  0.6018928294465027\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "Round   0, Average loss 0.833\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "Round   1, Average loss 0.215\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "Round   2, Average loss 0.117\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.51188643150958\n",
      "2.51188643150958\n",
      "Round   3, Average loss 0.067\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "Round   4, Average loss 0.080\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "Round   5, Average loss 0.055\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "Round   6, Average loss 0.060\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "Round   7, Average loss 0.064\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "Round   8, Average loss 0.057\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "Round   9, Average loss 0.060\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "Round  10, Average loss 0.058\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "Round  11, Average loss 0.064\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "Round  12, Average loss 0.047\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "Round  13, Average loss 0.050\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "Round  14, Average loss 0.064\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "Round  15, Average loss 0.035\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "Round  16, Average loss 0.037\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "Round  17, Average loss 0.036\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "Round  18, Average loss 0.035\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "2.51188643150958\n",
      "Round  19, Average loss 0.047\n",
      "Training accuracy: 45.90\n",
      "Testing accuracy: 46.22\n",
      "4 / 20\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: fedspa\n",
      "sparsity:  0.683772233983162\n",
      "Round   0, Average loss 2.302\n",
      "Round   1, Average loss 2.300\n",
      "Round   2, Average loss 2.301\n",
      "Round   3, Average loss 2.209\n",
      "Round   4, Average loss 1.817\n",
      "Round   5, Average loss 0.744\n",
      "Round   6, Average loss 0.822\n",
      "Round   7, Average loss 0.687\n",
      "Round   8, Average loss 0.694\n",
      "Round   9, Average loss 0.400\n",
      "Round  10, Average loss 0.324\n",
      "Round  11, Average loss 0.207\n",
      "Round  12, Average loss 0.106\n",
      "Round  13, Average loss 0.094\n",
      "Round  14, Average loss 0.132\n",
      "Round  15, Average loss 0.056\n",
      "Round  16, Average loss 0.053\n",
      "Round  17, Average loss 0.064\n",
      "Round  18, Average loss 0.059\n",
      "Round  19, Average loss 0.100\n",
      "Training accuracy: 19.44\n",
      "Testing accuracy: 20.21\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: mag\n",
      "sparsity:  0.683772233983162\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "Round   0, Average loss 0.908\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "Round   1, Average loss 0.298\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "Round   2, Average loss 0.154\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "Round   3, Average loss 0.085\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "Round   4, Average loss 0.086\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "Round   5, Average loss 0.061\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "Round   6, Average loss 0.068\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "Round   7, Average loss 0.081\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "Round   8, Average loss 0.059\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "Round   9, Average loss 0.064\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "Round  10, Average loss 0.068\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "Round  11, Average loss 0.064\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "Round  12, Average loss 0.046\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "Round  13, Average loss 0.052\n",
      "3.1622776601683795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "Round  14, Average loss 0.073\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "Round  15, Average loss 0.037\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "Round  16, Average loss 0.039\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "Round  17, Average loss 0.038\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "Round  18, Average loss 0.039\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "Round  19, Average loss 0.054\n",
      "Training accuracy: 47.55\n",
      "Testing accuracy: 48.41\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: synflow\n",
      "sparsity:  0.683772233983162\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "Round   0, Average loss 0.904\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "Round   1, Average loss 0.235\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "Round   2, Average loss 0.132\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "Round   3, Average loss 0.074\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "Round   4, Average loss 0.076\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "Round   5, Average loss 0.060\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "Round   6, Average loss 0.063\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "Round   7, Average loss 0.072\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "Round   8, Average loss 0.059\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "Round   9, Average loss 0.067\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "Round  10, Average loss 0.064\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "Round  11, Average loss 0.065\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "Round  12, Average loss 0.045\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "Round  13, Average loss 0.051\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "Round  14, Average loss 0.069\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "Round  15, Average loss 0.034\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "Round  16, Average loss 0.034\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "Round  17, Average loss 0.033\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "Round  18, Average loss 0.040\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "3.1622776601683795\n",
      "Round  19, Average loss 0.045\n",
      "Training accuracy: 43.89\n",
      "Testing accuracy: 44.80\n",
      "5 / 20\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: fedspa\n",
      "sparsity:  0.748811356849042\n",
      "Round   0, Average loss 2.302\n",
      "Round   1, Average loss 2.302\n",
      "Round   2, Average loss 2.302\n",
      "Round   3, Average loss 2.302\n",
      "Round   4, Average loss 2.302\n",
      "Round   5, Average loss 2.295\n",
      "Round   6, Average loss 2.300\n",
      "Round   7, Average loss 2.244\n",
      "Round   8, Average loss 1.864\n",
      "Round   9, Average loss 0.808\n",
      "Round  10, Average loss 0.763\n",
      "Round  11, Average loss 0.766\n",
      "Round  12, Average loss 0.677\n",
      "Round  13, Average loss 0.712\n",
      "Round  14, Average loss 0.670\n",
      "Round  15, Average loss 0.540\n",
      "Round  16, Average loss 0.215\n",
      "Round  17, Average loss 0.134\n",
      "Round  18, Average loss 0.100\n",
      "Round  19, Average loss 0.167\n",
      "Training accuracy: 18.59\n",
      "Testing accuracy: 18.86\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: mag\n",
      "sparsity:  0.748811356849042\n",
      "3.9810717055349722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "Round   0, Average loss 1.013\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "Round   1, Average loss 0.339\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "Round   2, Average loss 0.176\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "Round   3, Average loss 0.094\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "Round   4, Average loss 0.094\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "Round   5, Average loss 0.065\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "Round   6, Average loss 0.073\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "Round   7, Average loss 0.080\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "Round   8, Average loss 0.061\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "Round   9, Average loss 0.065\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "Round  10, Average loss 0.065\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "Round  11, Average loss 0.066\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "Round  12, Average loss 0.051\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "Round  13, Average loss 0.052\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "Round  14, Average loss 0.077\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "Round  15, Average loss 0.040\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "Round  16, Average loss 0.044\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "Round  17, Average loss 0.042\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "Round  18, Average loss 0.041\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "Round  19, Average loss 0.057\n",
      "Training accuracy: 41.27\n",
      "Testing accuracy: 41.71\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: synflow\n",
      "sparsity:  0.748811356849042\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "Round   0, Average loss 1.023\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "Round   1, Average loss 0.265\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "Round   2, Average loss 0.148\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "Round   3, Average loss 0.085\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "Round   4, Average loss 0.089\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "Round   5, Average loss 0.063\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "Round   6, Average loss 0.062\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "Round   7, Average loss 0.079\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "Round   8, Average loss 0.059\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "Round   9, Average loss 0.071\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "Round  10, Average loss 0.064\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "Round  11, Average loss 0.075\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "Round  12, Average loss 0.050\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "Round  13, Average loss 0.051\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "Round  14, Average loss 0.076\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "Round  15, Average loss 0.038\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "Round  16, Average loss 0.036\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "Round  17, Average loss 0.036\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "Round  18, Average loss 0.047\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "3.9810717055349722\n",
      "Round  19, Average loss 0.047\n",
      "Training accuracy: 44.62\n",
      "Testing accuracy: 45.54\n",
      "6 / 20\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: fedspa\n",
      "sparsity:  0.800473768503112\n",
      "Round   0, Average loss 2.303\n",
      "Round   1, Average loss 2.303\n",
      "Round   2, Average loss 2.303\n",
      "Round   3, Average loss 2.303\n",
      "Round   4, Average loss 2.302\n",
      "Round   5, Average loss 2.303\n",
      "Round   6, Average loss 2.303\n",
      "Round   7, Average loss 2.303\n",
      "Round   8, Average loss 2.302\n",
      "Round   9, Average loss 2.302\n",
      "Round  10, Average loss 2.302\n",
      "Round  11, Average loss 2.303\n",
      "Round  12, Average loss 2.302\n",
      "Round  13, Average loss 2.302\n",
      "Round  14, Average loss 2.302\n",
      "Round  15, Average loss 2.302\n",
      "Round  16, Average loss 2.302\n",
      "Round  17, Average loss 2.302\n",
      "Round  18, Average loss 2.302\n",
      "Round  19, Average loss 2.302\n",
      "Training accuracy: 17.76\n",
      "Testing accuracy: 18.06\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: mag\n",
      "sparsity:  0.800473768503112\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "Round   0, Average loss 1.187\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "Round   1, Average loss 0.432\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "Round   2, Average loss 0.213\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "Round   3, Average loss 0.113\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "Round   4, Average loss 0.116\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "Round   5, Average loss 0.077\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "Round   6, Average loss 0.087\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "Round   7, Average loss 0.080\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "Round   8, Average loss 0.068\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "Round   9, Average loss 0.080\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "Round  10, Average loss 0.076\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "Round  11, Average loss 0.073\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "Round  12, Average loss 0.063\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "Round  13, Average loss 0.057\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "Round  14, Average loss 0.093\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "Round  15, Average loss 0.062\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "Round  16, Average loss 0.052\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "Round  17, Average loss 0.044\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "Round  18, Average loss 0.050\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "Round  19, Average loss 0.061\n",
      "Training accuracy: 33.60\n",
      "Testing accuracy: 34.21\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: synflow\n",
      "sparsity:  0.800473768503112\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "Round   0, Average loss 1.105\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "Round   1, Average loss 0.272\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "Round   2, Average loss 0.155\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "Round   3, Average loss 0.078\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "Round   4, Average loss 0.080\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "Round   5, Average loss 0.054\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "Round   6, Average loss 0.064\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "Round   7, Average loss 0.076\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "Round   8, Average loss 0.058\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "Round   9, Average loss 0.066\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "Round  10, Average loss 0.064\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "Round  11, Average loss 0.062\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "Round  12, Average loss 0.049\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "Round  13, Average loss 0.050\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "Round  14, Average loss 0.071\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "Round  15, Average loss 0.034\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "Round  16, Average loss 0.037\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "Round  17, Average loss 0.037\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "Round  18, Average loss 0.048\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "5.011872336272722\n",
      "Round  19, Average loss 0.053\n",
      "Training accuracy: 39.89\n",
      "Testing accuracy: 41.01\n",
      "7 / 20\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: fedspa\n",
      "sparsity:  0.8415106807538887\n",
      "Round   0, Average loss 2.303\n",
      "Round   1, Average loss 2.303\n",
      "Round   2, Average loss 2.303\n",
      "Round   3, Average loss 2.303\n",
      "Round   4, Average loss 2.303\n",
      "Round   5, Average loss 2.303\n",
      "Round   6, Average loss 2.303\n",
      "Round   7, Average loss 2.303\n",
      "Round   8, Average loss 2.303\n",
      "Round   9, Average loss 2.303\n",
      "Round  10, Average loss 2.303\n",
      "Round  11, Average loss 2.303\n",
      "Round  12, Average loss 2.303\n",
      "Round  13, Average loss 2.303\n",
      "Round  14, Average loss 2.303\n",
      "Round  15, Average loss 2.303\n",
      "Round  16, Average loss 2.303\n",
      "Round  17, Average loss 2.303\n",
      "Round  18, Average loss 2.303\n",
      "Round  19, Average loss 2.303\n",
      "Training accuracy: 16.34\n",
      "Testing accuracy: 16.65\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: mag\n",
      "sparsity:  0.8415106807538887\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "Round   0, Average loss 1.259\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "Round   1, Average loss 0.527\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "Round   2, Average loss 0.270\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "Round   3, Average loss 0.151\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "Round   4, Average loss 0.145\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "Round   5, Average loss 0.093\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "Round   6, Average loss 0.089\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "Round   7, Average loss 0.088\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "Round   8, Average loss 0.074\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "Round   9, Average loss 0.069\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "Round  10, Average loss 0.093\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.309573444801933\n",
      "Round  11, Average loss 0.069\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "Round  12, Average loss 0.053\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "Round  13, Average loss 0.059\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "Round  14, Average loss 0.081\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "Round  15, Average loss 0.040\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "Round  16, Average loss 0.043\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "Round  17, Average loss 0.061\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "Round  18, Average loss 0.048\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "Round  19, Average loss 0.068\n",
      "Training accuracy: 23.45\n",
      "Testing accuracy: 23.66\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: synflow\n",
      "sparsity:  0.8415106807538887\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "Round   0, Average loss 1.243\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "Round   1, Average loss 0.311\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "Round   2, Average loss 0.160\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "Round   3, Average loss 0.084\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "Round   4, Average loss 0.086\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "Round   5, Average loss 0.056\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "Round   6, Average loss 0.065\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "Round   7, Average loss 0.072\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "Round   8, Average loss 0.056\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "Round   9, Average loss 0.070\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "Round  10, Average loss 0.061\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "Round  11, Average loss 0.069\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "Round  12, Average loss 0.051\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "Round  13, Average loss 0.059\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "Round  14, Average loss 0.076\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "Round  15, Average loss 0.039\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "Round  16, Average loss 0.037\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "Round  17, Average loss 0.038\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "Round  18, Average loss 0.049\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "6.309573444801933\n",
      "Round  19, Average loss 0.060\n",
      "Training accuracy: 31.42\n",
      "Testing accuracy: 32.35\n",
      "8 / 20\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: fedspa\n",
      "sparsity:  0.8741074588205833\n",
      "Round   0, Average loss 2.303\n",
      "Round   1, Average loss 2.303\n",
      "Round   2, Average loss 2.303\n",
      "Round   3, Average loss 2.303\n",
      "Round   4, Average loss 2.303\n",
      "Round   5, Average loss 2.303\n",
      "Round   6, Average loss 2.303\n",
      "Round   7, Average loss 2.303\n",
      "Round   8, Average loss 2.303\n",
      "Round   9, Average loss 2.303\n",
      "Round  10, Average loss 2.303\n",
      "Round  11, Average loss 2.303\n",
      "Round  12, Average loss 2.303\n",
      "Round  13, Average loss 2.303\n",
      "Round  14, Average loss 2.303\n",
      "Round  15, Average loss 2.303\n",
      "Round  16, Average loss 2.303\n",
      "Round  17, Average loss 2.303\n",
      "Round  18, Average loss 2.303\n",
      "Round  19, Average loss 2.303\n",
      "Training accuracy: 11.03\n",
      "Testing accuracy: 10.56\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: mag\n",
      "sparsity:  0.8741074588205833\n",
      "7.943282347242816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "Round   0, Average loss 1.253\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "Round   1, Average loss 0.601\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "Round   2, Average loss 0.326\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "Round   3, Average loss 0.172\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "Round   4, Average loss 0.169\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "Round   5, Average loss 0.110\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "Round   6, Average loss 0.103\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "Round   7, Average loss 0.097\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "Round   8, Average loss 0.090\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "Round   9, Average loss 0.078\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "Round  10, Average loss 0.097\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "Round  11, Average loss 0.076\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "Round  12, Average loss 0.061\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "Round  13, Average loss 0.067\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "Round  14, Average loss 0.093\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "Round  15, Average loss 0.049\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "Round  16, Average loss 0.056\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "Round  17, Average loss 0.056\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "Round  18, Average loss 0.057\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "Round  19, Average loss 0.065\n",
      "Training accuracy: 23.59\n",
      "Testing accuracy: 24.12\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: synflow\n",
      "sparsity:  0.8741074588205833\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "Round   0, Average loss 1.366\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "Round   1, Average loss 0.359\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "Round   2, Average loss 0.170\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "Round   3, Average loss 0.084\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "Round   4, Average loss 0.094\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "Round   5, Average loss 0.061\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "Round   6, Average loss 0.069\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "Round   7, Average loss 0.086\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "Round   8, Average loss 0.065\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "Round   9, Average loss 0.084\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "Round  10, Average loss 0.078\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "Round  11, Average loss 0.070\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "Round  12, Average loss 0.051\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "Round  13, Average loss 0.059\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "Round  14, Average loss 0.076\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "Round  15, Average loss 0.036\n",
      "7.943282347242816\n",
      "7.943282347242816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "Round  16, Average loss 0.038\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "Round  17, Average loss 0.037\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "Round  18, Average loss 0.052\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "7.943282347242816\n",
      "Round  19, Average loss 0.057\n",
      "Training accuracy: 42.02\n",
      "Testing accuracy: 42.24\n",
      "9 / 20\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: fedspa\n",
      "sparsity:  0.9\n",
      "Round   0, Average loss 2.303\n",
      "Round   1, Average loss 2.303\n",
      "Round   2, Average loss 2.303\n",
      "Round   3, Average loss 2.303\n",
      "Round   4, Average loss 2.303\n",
      "Round   5, Average loss 2.303\n",
      "Round   6, Average loss 2.303\n",
      "Round   7, Average loss 2.303\n",
      "Round   8, Average loss 2.303\n",
      "Round   9, Average loss 2.303\n",
      "Round  10, Average loss 2.303\n",
      "Round  11, Average loss 2.303\n",
      "Round  12, Average loss 2.303\n",
      "Round  13, Average loss 2.303\n",
      "Round  14, Average loss 2.303\n",
      "Round  15, Average loss 2.303\n",
      "Round  16, Average loss 2.303\n",
      "Round  17, Average loss 2.303\n",
      "Round  18, Average loss 2.303\n",
      "Round  19, Average loss 2.303\n",
      "Training accuracy: 9.54\n",
      "Testing accuracy: 9.41\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: mag\n",
      "sparsity:  0.9\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "Round   0, Average loss 2.303\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "Round   1, Average loss 2.303\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "Round   2, Average loss 2.303\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "Round   3, Average loss 2.303\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "Round   4, Average loss 2.303\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "Round   5, Average loss 2.303\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "Round   6, Average loss 2.303\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "Round   7, Average loss 2.303\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "Round   8, Average loss 2.303\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "Round   9, Average loss 2.303\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "Round  10, Average loss 2.303\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "Round  11, Average loss 2.303\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "Round  12, Average loss 2.303\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "Round  13, Average loss 2.303\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "Round  14, Average loss 2.303\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "Round  15, Average loss 2.303\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "Round  16, Average loss 2.303\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "Round  17, Average loss 2.303\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "Round  18, Average loss 2.303\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "10.0\n",
      "layer collapse\n",
      "Round  19, Average loss 2.303\n",
      "Training accuracy: 9.87\n",
      "Testing accuracy: 9.80\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: synflow\n",
      "sparsity:  0.9\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "Round   0, Average loss 1.476\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "Round   1, Average loss 0.430\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "Round   2, Average loss 0.164\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "Round   3, Average loss 0.100\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n",
      "10.0\n",
      "Round   4, Average loss 0.119\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "Round   5, Average loss 0.066\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "Round   6, Average loss 0.083\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "Round   7, Average loss 0.106\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "Round   8, Average loss 0.085\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "Round   9, Average loss 0.100\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "Round  10, Average loss 0.083\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "Round  11, Average loss 0.079\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "Round  12, Average loss 0.081\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "Round  13, Average loss 0.110\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "Round  14, Average loss 0.099\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "Round  15, Average loss 0.042\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "Round  16, Average loss 0.045\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "Round  17, Average loss 0.049\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "Round  18, Average loss 0.053\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "10.0\n",
      "Round  19, Average loss 0.110\n",
      "Training accuracy: 26.91\n",
      "Testing accuracy: 28.30\n",
      "10 / 20\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: fedspa\n",
      "sparsity:  0.9205671765275718\n",
      "Round   0, Average loss 2.303\n",
      "Round   1, Average loss 2.303\n",
      "Round   2, Average loss 2.303\n",
      "Round   3, Average loss 2.303\n",
      "Round   4, Average loss 2.303\n",
      "Round   5, Average loss 2.303\n",
      "Round   6, Average loss 2.303\n",
      "Round   7, Average loss 2.303\n",
      "Round   8, Average loss 2.303\n",
      "Round   9, Average loss 2.303\n",
      "Round  10, Average loss 2.303\n",
      "Round  11, Average loss 2.303\n",
      "Round  12, Average loss 2.303\n",
      "Round  13, Average loss 2.303\n",
      "Round  14, Average loss 2.303\n",
      "Round  15, Average loss 2.303\n",
      "Round  16, Average loss 2.303\n",
      "Round  17, Average loss 2.303\n",
      "Round  18, Average loss 2.303\n",
      "Round  19, Average loss 2.303\n",
      "Training accuracy: 9.81\n",
      "Testing accuracy: 9.26\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: mag\n",
      "sparsity:  0.9205671765275718\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "Round   0, Average loss 2.303\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "Round   1, Average loss 2.303\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "Round   2, Average loss 2.303\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "Round   3, Average loss 2.303\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "Round   4, Average loss 2.303\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "Round   5, Average loss 2.303\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "Round   6, Average loss 2.303\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "Round   7, Average loss 2.303\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "Round   8, Average loss 2.303\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "Round   9, Average loss 2.303\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "Round  10, Average loss 2.303\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "Round  11, Average loss 2.303\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "Round  12, Average loss 2.303\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "Round  13, Average loss 2.303\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "Round  14, Average loss 2.303\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "Round  15, Average loss 2.303\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "Round  16, Average loss 2.303\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "Round  17, Average loss 2.303\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "Round  18, Average loss 2.303\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "12.589254117941675\n",
      "layer collapse\n",
      "Round  19, Average loss 2.303\n",
      "Training accuracy: 9.87\n",
      "Testing accuracy: 9.80\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: synflow\n",
      "sparsity:  0.9205671765275718\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "Round   0, Average loss 1.598\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "Round   1, Average loss 0.532\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "Round   2, Average loss 0.207\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "Round   3, Average loss 0.094\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "Round   4, Average loss 0.112\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "Round   5, Average loss 0.066\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "Round   6, Average loss 0.088\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "Round   7, Average loss 0.106\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "Round   8, Average loss 0.075\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "Round   9, Average loss 0.109\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "Round  10, Average loss 0.083\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "Round  11, Average loss 0.091\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "Round  12, Average loss 0.072\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "Round  13, Average loss 0.090\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "Round  14, Average loss 0.109\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "Round  15, Average loss 0.044\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "Round  16, Average loss 0.047\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "Round  17, Average loss 0.044\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "Round  18, Average loss 0.056\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "12.589254117941675\n",
      "Round  19, Average loss 0.105\n",
      "Training accuracy: 27.55\n",
      "Testing accuracy: 28.02\n",
      "11 / 20\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: fedspa\n",
      "sparsity:  0.9369042655519807\n",
      "Round   0, Average loss 2.303\n",
      "Round   1, Average loss 2.303\n",
      "Round   2, Average loss 2.303\n",
      "Round   3, Average loss 2.303\n",
      "Round   4, Average loss 2.303\n",
      "Round   5, Average loss 2.303\n",
      "Round   6, Average loss 2.303\n",
      "Round   7, Average loss 2.303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round   8, Average loss 2.303\n",
      "Round   9, Average loss 2.303\n",
      "Round  10, Average loss 2.303\n",
      "Round  11, Average loss 2.303\n",
      "Round  12, Average loss 2.303\n",
      "Round  13, Average loss 2.303\n",
      "Round  14, Average loss 2.303\n",
      "Round  15, Average loss 2.303\n",
      "Round  16, Average loss 2.303\n",
      "Round  17, Average loss 2.303\n",
      "Round  18, Average loss 2.303\n",
      "Round  19, Average loss 2.303\n",
      "Training accuracy: 8.47\n",
      "Testing accuracy: 8.37\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: mag\n",
      "sparsity:  0.9369042655519807\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "Round   0, Average loss 2.303\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "Round   1, Average loss 2.303\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "Round   2, Average loss 2.303\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "Round   3, Average loss 2.303\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "Round   4, Average loss 2.303\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "Round   5, Average loss 2.303\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "Round   6, Average loss 2.303\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "Round   7, Average loss 2.303\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "Round   8, Average loss 2.303\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "Round   9, Average loss 2.303\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "Round  10, Average loss 2.303\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "Round  11, Average loss 2.303\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "Round  12, Average loss 2.303\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "Round  13, Average loss 2.303\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "Round  14, Average loss 2.303\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "Round  15, Average loss 2.303\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "Round  16, Average loss 2.303\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "Round  17, Average loss 2.303\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "Round  18, Average loss 2.303\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "15.848931924611133\n",
      "layer collapse\n",
      "Round  19, Average loss 2.303\n",
      "Training accuracy: 9.87\n",
      "Testing accuracy: 9.80\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: synflow\n",
      "sparsity:  0.9369042655519807\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "Round   0, Average loss 1.892\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "Round   1, Average loss 0.643\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "Round   2, Average loss 0.232\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "Round   3, Average loss 0.102\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "Round   4, Average loss 0.139\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "Round   5, Average loss 0.090\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "Round   6, Average loss 0.079\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "Round   7, Average loss 0.092\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "Round   8, Average loss 0.095\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "Round   9, Average loss 0.090\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "Round  10, Average loss 0.094\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "Round  11, Average loss 0.109\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "Round  12, Average loss 0.060\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "Round  13, Average loss 0.070\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "Round  14, Average loss 0.104\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "Round  15, Average loss 0.045\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "Round  16, Average loss 0.045\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "Round  17, Average loss 0.058\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "Round  18, Average loss 0.054\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "15.848931924611133\n",
      "Round  19, Average loss 0.064\n",
      "Training accuracy: 26.20\n",
      "Testing accuracy: 26.89\n",
      "12 / 20\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: fedspa\n",
      "sparsity:  0.9498812766372727\n",
      "Round   0, Average loss 2.303\n",
      "Round   1, Average loss 2.303\n",
      "Round   2, Average loss 2.303\n",
      "Round   3, Average loss 2.303\n",
      "Round   4, Average loss 2.303\n",
      "Round   5, Average loss 2.303\n",
      "Round   6, Average loss 2.303\n",
      "Round   7, Average loss 2.303\n",
      "Round   8, Average loss 2.303\n",
      "Round   9, Average loss 2.303\n",
      "Round  10, Average loss 2.303\n",
      "Round  11, Average loss 2.303\n",
      "Round  12, Average loss 2.303\n",
      "Round  13, Average loss 2.303\n",
      "Round  14, Average loss 2.303\n",
      "Round  15, Average loss 2.303\n",
      "Round  16, Average loss 2.303\n",
      "Round  17, Average loss 2.303\n",
      "Round  18, Average loss 2.303\n",
      "Round  19, Average loss 2.303\n",
      "Training accuracy: 13.65\n",
      "Testing accuracy: 14.11\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: mag\n",
      "sparsity:  0.9498812766372727\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "Round   0, Average loss 2.303\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "Round   1, Average loss 2.303\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "Round   2, Average loss 2.303\n",
      "19.952623149688797\n",
      "layer collapse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "Round   3, Average loss 2.303\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "Round   4, Average loss 2.303\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "Round   5, Average loss 2.303\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "Round   6, Average loss 2.303\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "Round   7, Average loss 2.303\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "Round   8, Average loss 2.303\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "Round   9, Average loss 2.303\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "Round  10, Average loss 2.303\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "Round  11, Average loss 2.303\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "Round  12, Average loss 2.303\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "Round  13, Average loss 2.303\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "Round  14, Average loss 2.303\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "Round  15, Average loss 2.303\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "Round  16, Average loss 2.303\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "Round  17, Average loss 2.303\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "Round  18, Average loss 2.303\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "19.952623149688797\n",
      "layer collapse\n",
      "Round  19, Average loss 2.303\n",
      "Training accuracy: 9.87\n",
      "Testing accuracy: 9.80\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: synflow\n",
      "sparsity:  0.9498812766372727\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "Round   0, Average loss 2.062\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "Round   1, Average loss 0.884\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "Round   2, Average loss 0.680\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "Round   3, Average loss 0.293\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "Round   4, Average loss 0.183\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "Round   5, Average loss 0.094\n",
      "19.952623149688797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "Round   6, Average loss 0.096\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "Round   7, Average loss 0.089\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "Round   8, Average loss 0.090\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "Round   9, Average loss 0.085\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "Round  10, Average loss 0.107\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "Round  11, Average loss 0.112\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "Round  12, Average loss 0.114\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "Round  13, Average loss 0.073\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "Round  14, Average loss 0.116\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "Round  15, Average loss 0.057\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "Round  16, Average loss 0.064\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "Round  17, Average loss 0.086\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "Round  18, Average loss 0.060\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "19.952623149688797\n",
      "Round  19, Average loss 0.070\n",
      "Training accuracy: 25.00\n",
      "Testing accuracy: 25.64\n",
      "13 / 20\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: fedspa\n",
      "sparsity:  0.9601892829446502\n",
      "Round   0, Average loss 2.303\n",
      "Round   1, Average loss 2.303\n",
      "Round   2, Average loss 2.303\n",
      "Round   3, Average loss 2.303\n",
      "Round   4, Average loss 2.303\n",
      "Round   5, Average loss 2.303\n",
      "Round   6, Average loss 2.303\n",
      "Round   7, Average loss 2.303\n",
      "Round   8, Average loss 2.303\n",
      "Round   9, Average loss 2.303\n",
      "Round  10, Average loss 2.303\n",
      "Round  11, Average loss 2.303\n",
      "Round  12, Average loss 2.303\n",
      "Round  13, Average loss 2.303\n",
      "Round  14, Average loss 2.303\n",
      "Round  15, Average loss 2.303\n",
      "Round  16, Average loss 2.303\n",
      "Round  17, Average loss 2.303\n",
      "Round  18, Average loss 2.303\n",
      "Round  19, Average loss 2.303\n",
      "Training accuracy: 6.70\n",
      "Testing accuracy: 6.99\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: mag\n",
      "sparsity:  0.9601892829446502\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "Round   0, Average loss 2.303\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "Round   1, Average loss 2.303\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "Round   2, Average loss 2.303\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "Round   3, Average loss 2.303\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "Round   4, Average loss 2.303\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "Round   5, Average loss 2.303\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "Round   6, Average loss 2.303\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "Round   7, Average loss 2.303\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer collapse\n",
      "Round   8, Average loss 2.303\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "Round   9, Average loss 2.303\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "Round  10, Average loss 2.303\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "Round  11, Average loss 2.303\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "Round  12, Average loss 2.303\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "Round  13, Average loss 2.303\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "Round  14, Average loss 2.303\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "Round  15, Average loss 2.303\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "Round  16, Average loss 2.303\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "Round  17, Average loss 2.303\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "Round  18, Average loss 2.303\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "25.118864315095795\n",
      "layer collapse\n",
      "Round  19, Average loss 2.303\n",
      "Training accuracy: 9.87\n",
      "Testing accuracy: 9.80\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: synflow\n",
      "sparsity:  0.9601892829446502\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "Round   0, Average loss 2.274\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "Round   1, Average loss 1.561\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "Round   2, Average loss 0.801\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "Round   3, Average loss 0.560\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "Round   4, Average loss 0.553\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "Round   5, Average loss 0.258\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "Round   6, Average loss 0.164\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "Round   7, Average loss 0.097\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "Round   8, Average loss 0.096\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "Round   9, Average loss 0.089\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "Round  10, Average loss 0.161\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "Round  11, Average loss 0.087\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "Round  12, Average loss 0.095\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "Round  13, Average loss 0.082\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "Round  14, Average loss 0.111\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.118864315095795\n",
      "Round  15, Average loss 0.063\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "Round  16, Average loss 0.059\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "Round  17, Average loss 0.073\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "Round  18, Average loss 0.058\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "25.118864315095795\n",
      "Round  19, Average loss 0.083\n",
      "Training accuracy: 24.43\n",
      "Testing accuracy: 24.23\n",
      "14 / 20\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: fedspa\n",
      "sparsity:  0.9683772233983162\n",
      "Round   0, Average loss 2.303\n",
      "Round   1, Average loss 2.303\n",
      "Round   2, Average loss 2.303\n",
      "Round   3, Average loss 2.303\n",
      "Round   4, Average loss 2.303\n",
      "Round   5, Average loss 2.303\n",
      "Round   6, Average loss 2.303\n",
      "Round   7, Average loss 2.303\n",
      "Round   8, Average loss 2.303\n",
      "Round   9, Average loss 2.303\n",
      "Round  10, Average loss 2.303\n",
      "Round  11, Average loss 2.303\n",
      "Round  12, Average loss 2.303\n",
      "Round  13, Average loss 2.303\n",
      "Round  14, Average loss 2.303\n",
      "Round  15, Average loss 2.303\n",
      "Round  16, Average loss 2.303\n",
      "Round  17, Average loss 2.303\n",
      "Round  18, Average loss 2.303\n",
      "Round  19, Average loss 2.303\n",
      "Training accuracy: 2.56\n",
      "Testing accuracy: 2.44\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: mag\n",
      "sparsity:  0.9683772233983162\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "Round   0, Average loss 2.303\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "Round   1, Average loss 2.303\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "Round   2, Average loss 2.303\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "Round   3, Average loss 2.303\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "Round   4, Average loss 2.303\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "Round   5, Average loss 2.303\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "Round   6, Average loss 2.303\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "Round   7, Average loss 2.303\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "Round   8, Average loss 2.303\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "Round   9, Average loss 2.303\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "Round  10, Average loss 2.303\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "Round  11, Average loss 2.303\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "Round  12, Average loss 2.303\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "Round  13, Average loss 2.303\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "Round  14, Average loss 2.303\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "Round  15, Average loss 2.303\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "Round  16, Average loss 2.303\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "Round  17, Average loss 2.303\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "Round  18, Average loss 2.303\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "31.622776601683793\n",
      "layer collapse\n",
      "Round  19, Average loss 2.303\n",
      "Training accuracy: 9.87\n",
      "Testing accuracy: 9.80\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: synflow\n",
      "sparsity:  0.9683772233983162\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "Round   0, Average loss 2.302\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "Round   1, Average loss 2.218\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "Round   2, Average loss 1.612\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "Round   3, Average loss 0.654\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "Round   4, Average loss 0.696\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "Round   5, Average loss 0.578\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "Round   6, Average loss 0.713\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "Round   7, Average loss 0.630\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "Round   8, Average loss 0.646\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "Round   9, Average loss 0.393\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "Round  10, Average loss 0.180\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "Round  11, Average loss 0.157\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "Round  12, Average loss 0.099\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "Round  13, Average loss 0.137\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "Round  14, Average loss 0.146\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "Round  15, Average loss 0.056\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "Round  16, Average loss 0.051\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "Round  17, Average loss 0.062\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "Round  18, Average loss 0.067\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "31.622776601683793\n",
      "Round  19, Average loss 0.085\n",
      "Training accuracy: 22.50\n",
      "Testing accuracy: 22.83\n",
      "15 / 20\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: fedspa\n",
      "sparsity:  0.9748811356849042\n",
      "Round   0, Average loss 2.303\n",
      "Round   1, Average loss 2.303\n",
      "Round   2, Average loss 2.303\n",
      "Round   3, Average loss 2.303\n",
      "Round   4, Average loss 2.303\n",
      "Round   5, Average loss 2.303\n",
      "Round   6, Average loss 2.303\n",
      "Round   7, Average loss 2.303\n",
      "Round   8, Average loss 2.303\n",
      "Round   9, Average loss 2.303\n",
      "Round  10, Average loss 2.303\n",
      "Round  11, Average loss 2.303\n",
      "Round  12, Average loss 2.303\n",
      "Round  13, Average loss 2.303\n",
      "Round  14, Average loss 2.303\n",
      "Round  15, Average loss 2.303\n",
      "Round  16, Average loss 2.303\n",
      "Round  17, Average loss 2.303\n",
      "Round  18, Average loss 2.303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round  19, Average loss 2.303\n",
      "Training accuracy: 4.29\n",
      "Testing accuracy: 4.04\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: mag\n",
      "sparsity:  0.9748811356849042\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "Round   0, Average loss 2.303\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "Round   1, Average loss 2.303\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "Round   2, Average loss 2.303\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "Round   3, Average loss 2.303\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "Round   4, Average loss 2.303\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "Round   5, Average loss 2.303\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "Round   6, Average loss 2.303\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "Round   7, Average loss 2.303\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "Round   8, Average loss 2.303\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "Round   9, Average loss 2.303\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "Round  10, Average loss 2.303\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "Round  11, Average loss 2.303\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "Round  12, Average loss 2.303\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "Round  13, Average loss 2.303\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "Round  14, Average loss 2.303\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "Round  15, Average loss 2.303\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "Round  16, Average loss 2.303\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "Round  17, Average loss 2.303\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "Round  18, Average loss 2.303\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "39.810717055349734\n",
      "layer collapse\n",
      "Round  19, Average loss 2.303\n",
      "Training accuracy: 9.87\n",
      "Testing accuracy: 9.80\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: synflow\n",
      "sparsity:  0.9748811356849042\n",
      "39.810717055349734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "Round   0, Average loss 2.302\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "Round   1, Average loss 2.255\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "Round   2, Average loss 1.925\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "Round   3, Average loss 0.738\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "Round   4, Average loss 0.703\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "Round   5, Average loss 0.581\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "Round   6, Average loss 0.719\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "Round   7, Average loss 0.638\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "Round   8, Average loss 0.694\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "Round   9, Average loss 0.552\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "Round  10, Average loss 0.536\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "Round  11, Average loss 0.424\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "Round  12, Average loss 0.115\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "Round  13, Average loss 0.132\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "Round  14, Average loss 0.145\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "Round  15, Average loss 0.063\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "Round  16, Average loss 0.057\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "Round  17, Average loss 0.058\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "Round  18, Average loss 0.091\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "39.810717055349734\n",
      "Round  19, Average loss 0.095\n",
      "Training accuracy: 20.52\n",
      "Testing accuracy: 20.62\n",
      "16 / 20\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: fedspa\n",
      "sparsity:  0.9800473768503112\n",
      "Round   0, Average loss 2.303\n",
      "Round   1, Average loss 2.303\n",
      "Round   2, Average loss 2.303\n",
      "Round   3, Average loss 2.303\n",
      "Round   4, Average loss 2.303\n",
      "Round   5, Average loss 2.303\n",
      "Round   6, Average loss 2.303\n",
      "Round   7, Average loss 2.303\n",
      "Round   8, Average loss 2.303\n",
      "Round   9, Average loss 2.303\n",
      "Round  10, Average loss 2.303\n",
      "Round  11, Average loss 2.303\n",
      "Round  12, Average loss 2.303\n",
      "Round  13, Average loss 2.303\n",
      "Round  14, Average loss 2.303\n",
      "Round  15, Average loss 2.303\n",
      "Round  16, Average loss 2.303\n",
      "Round  17, Average loss 2.303\n",
      "Round  18, Average loss 2.303\n",
      "Round  19, Average loss 2.303\n",
      "Training accuracy: 5.79\n",
      "Testing accuracy: 5.31\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: mag\n",
      "sparsity:  0.9800473768503112\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "Round   0, Average loss 2.303\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "Round   1, Average loss 2.303\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "Round   2, Average loss 2.303\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "Round   3, Average loss 2.303\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "Round   4, Average loss 2.303\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "Round   5, Average loss 2.303\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "Round   6, Average loss 2.303\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "Round   7, Average loss 2.303\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "Round   8, Average loss 2.303\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "Round   9, Average loss 2.303\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "Round  10, Average loss 2.303\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "Round  11, Average loss 2.303\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "Round  12, Average loss 2.303\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "Round  13, Average loss 2.303\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "Round  14, Average loss 2.303\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "Round  15, Average loss 2.303\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "Round  16, Average loss 2.303\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "Round  17, Average loss 2.303\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "Round  18, Average loss 2.303\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "50.11872336272722\n",
      "layer collapse\n",
      "Round  19, Average loss 2.303\n",
      "Training accuracy: 9.87\n",
      "Testing accuracy: 9.80\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: synflow\n",
      "sparsity:  0.9800473768503112\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "Round   0, Average loss 2.302\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "Round   1, Average loss 2.302\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "Round   2, Average loss 2.296\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "Round   3, Average loss 1.836\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "Round   4, Average loss 0.880\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "Round   5, Average loss 0.617\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "Round   6, Average loss 0.730\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "Round   7, Average loss 0.641\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "Round   8, Average loss 0.738\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "Round   9, Average loss 0.416\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "Round  10, Average loss 0.194\n",
      "50.11872336272722\n",
      "50.11872336272722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "Round  11, Average loss 0.317\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "Round  12, Average loss 0.173\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "Round  13, Average loss 0.127\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "Round  14, Average loss 0.140\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "Round  15, Average loss 0.074\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "Round  16, Average loss 0.075\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "Round  17, Average loss 0.052\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "Round  18, Average loss 0.128\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "50.11872336272722\n",
      "Round  19, Average loss 0.094\n",
      "Training accuracy: 24.73\n",
      "Testing accuracy: 25.41\n",
      "17 / 20\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: fedspa\n",
      "sparsity:  0.9841510680753889\n",
      "Round   0, Average loss 2.303\n",
      "Round   1, Average loss 2.303\n",
      "Round   2, Average loss 2.303\n",
      "Round   3, Average loss 2.303\n",
      "Round   4, Average loss 2.303\n",
      "Round   5, Average loss 2.303\n",
      "Round   6, Average loss 2.303\n",
      "Round   7, Average loss 2.303\n",
      "Round   8, Average loss 2.303\n",
      "Round   9, Average loss 2.303\n",
      "Round  10, Average loss 2.303\n",
      "Round  11, Average loss 2.303\n",
      "Round  12, Average loss 2.303\n",
      "Round  13, Average loss 2.303\n",
      "Round  14, Average loss 2.303\n",
      "Round  15, Average loss 2.303\n",
      "Round  16, Average loss 2.303\n",
      "Round  17, Average loss 2.303\n",
      "Round  18, Average loss 2.303\n",
      "Round  19, Average loss 2.303\n",
      "Training accuracy: 7.08\n",
      "Testing accuracy: 6.73\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: mag\n",
      "sparsity:  0.9841510680753889\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "Round   0, Average loss 2.303\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "Round   1, Average loss 2.303\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "Round   2, Average loss 2.303\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "Round   3, Average loss 2.303\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "Round   4, Average loss 2.303\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "Round   5, Average loss 2.303\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "Round   6, Average loss 2.303\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "Round   7, Average loss 2.303\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "Round   8, Average loss 2.303\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "Round   9, Average loss 2.303\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "Round  10, Average loss 2.303\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "Round  11, Average loss 2.303\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "Round  12, Average loss 2.303\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "Round  13, Average loss 2.303\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "Round  14, Average loss 2.303\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "Round  15, Average loss 2.303\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "Round  16, Average loss 2.303\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "Round  17, Average loss 2.303\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "Round  18, Average loss 2.303\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "63.09573444801933\n",
      "layer collapse\n",
      "Round  19, Average loss 2.303\n",
      "Training accuracy: 9.87\n",
      "Testing accuracy: 9.80\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: synflow\n",
      "sparsity:  0.9841510680753889\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "Round   0, Average loss 2.302\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "Round   1, Average loss 2.302\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "Round   2, Average loss 2.302\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "Round   3, Average loss 2.302\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "Round   4, Average loss 2.300\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "Round   5, Average loss 2.061\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "Round   6, Average loss 1.164\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "Round   7, Average loss 0.682\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "Round   8, Average loss 0.718\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "Round   9, Average loss 0.586\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "Round  10, Average loss 0.655\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "Round  11, Average loss 0.809\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "Round  12, Average loss 0.680\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "Round  13, Average loss 0.710\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "Round  14, Average loss 0.651\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "Round  15, Average loss 0.418\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "Round  16, Average loss 0.127\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "Round  17, Average loss 0.086\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "Round  18, Average loss 0.072\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "63.09573444801933\n",
      "Round  19, Average loss 0.105\n",
      "Training accuracy: 20.39\n",
      "Testing accuracy: 20.44\n",
      "18 / 20\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: fedspa\n",
      "sparsity:  0.9874107458820583\n",
      "Round   0, Average loss 2.303\n",
      "Round   1, Average loss 2.303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round   2, Average loss 2.303\n",
      "Round   3, Average loss 2.303\n",
      "Round   4, Average loss 2.303\n",
      "Round   5, Average loss 2.303\n",
      "Round   6, Average loss 2.303\n",
      "Round   7, Average loss 2.303\n",
      "Round   8, Average loss 2.303\n",
      "Round   9, Average loss 2.303\n",
      "Round  10, Average loss 2.303\n",
      "Round  11, Average loss 2.303\n",
      "Round  12, Average loss 2.303\n",
      "Round  13, Average loss 2.303\n",
      "Round  14, Average loss 2.303\n",
      "Round  15, Average loss 2.303\n",
      "Round  16, Average loss 2.303\n",
      "Round  17, Average loss 2.303\n",
      "Round  18, Average loss 2.303\n",
      "Round  19, Average loss 2.303\n",
      "Training accuracy: 10.47\n",
      "Testing accuracy: 10.05\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: mag\n",
      "sparsity:  0.9874107458820583\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "Round   0, Average loss 2.303\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "Round   1, Average loss 2.303\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "Round   2, Average loss 2.303\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "Round   3, Average loss 2.303\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "Round   4, Average loss 2.303\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "Round   5, Average loss 2.303\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "Round   6, Average loss 2.303\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "Round   7, Average loss 2.303\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "Round   8, Average loss 2.303\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "Round   9, Average loss 2.303\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "Round  10, Average loss 2.303\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "Round  11, Average loss 2.303\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "Round  12, Average loss 2.303\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "Round  13, Average loss 2.303\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "Round  14, Average loss 2.303\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "Round  15, Average loss 2.303\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "Round  16, Average loss 2.303\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "Round  17, Average loss 2.303\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "Round  18, Average loss 2.303\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "79.43282347242814\n",
      "layer collapse\n",
      "Round  19, Average loss 2.303\n",
      "Training accuracy: 9.87\n",
      "Testing accuracy: 9.80\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "pruner: synflow\n",
      "sparsity:  0.9874107458820583\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "Round   0, Average loss 2.302\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "Round   1, Average loss 2.302\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "Round   2, Average loss 2.303\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "Round   3, Average loss 2.303\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "Round   4, Average loss 2.303\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "Round   5, Average loss 2.302\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "Round   6, Average loss 2.303\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "Round   7, Average loss 2.303\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "Round   8, Average loss 2.302\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "Round   9, Average loss 2.302\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "Round  10, Average loss 2.302\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "Round  11, Average loss 2.302\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "Round  12, Average loss 2.302\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "Round  13, Average loss 2.301\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "Round  14, Average loss 2.301\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "Round  15, Average loss 2.224\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "Round  16, Average loss 1.155\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "Round  17, Average loss 0.676\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "Round  18, Average loss 0.665\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "79.43282347242814\n",
      "Round  19, Average loss 0.660\n",
      "Training accuracy: 9.74\n",
      "Testing accuracy: 9.82\n",
      "synflow test accuracy:  [tensor(52.0600), tensor(49.9200), tensor(51.0400), tensor(46.2200), tensor(44.8000), tensor(45.5400), tensor(41.0100), tensor(32.3500), tensor(42.2400), tensor(28.3000), tensor(28.0200), tensor(26.8900), tensor(25.6400), tensor(24.2300), tensor(22.8300), tensor(20.6200), tensor(25.4100), tensor(20.4400), tensor(9.8200)]\n",
      "mag test accuracy:  [tensor(52.2200), tensor(48.2700), tensor(52.9200), tensor(44.9400), tensor(48.4100), tensor(41.7100), tensor(34.2100), tensor(23.6600), tensor(24.1200), tensor(9.8000), tensor(9.8000), tensor(9.8000), tensor(9.8000), tensor(9.8000), tensor(9.8000), tensor(9.8000), tensor(9.8000), tensor(9.8000), tensor(9.8000)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "%run ../layer-collapse.py --model mlp --dataset mnist --epochs 20 --local_ep 5 --gpu -0 --num_channels 1 --num_users 100 --frac 0.1 --compression 10 --prune_epochs 100 --pruner mag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Testing plots\n",
    "\n",
    "- The code below is for testing plots from the results printed by manually copying them.\n",
    "- To plot the results directly, uncomment the `plt.show()` line\n",
    "- To save the results, uncomment the `plt.savefig()` line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "y = {}\n",
    "iters = 30\n",
    "alphas = [i/5 for i in range(iters)]\n",
    "y['synflow'] = [torch.tensor(97.7400), torch.tensor(97.6300), torch.tensor(97.5300), torch.tensor(97.5300), torch.tensor(97.6400), torch.tensor(97.2400), torch.tensor(96.3500), torch.tensor(95.5000), torch.tensor(94.8100), torch.tensor(93.3100), torch.tensor(89.5500), torch.tensor(71.1400), torch.tensor(42.9200), torch.tensor(10.1600), torch.tensor(11.9300), torch.tensor(9.1900), torch.tensor(14.0700), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000)]\n",
    "y['mag'] = [torch.tensor(97.4500), torch.tensor(97.0300), torch.tensor(97.2700), torch.tensor(97.6600), torch.tensor(97.6800), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000)]\n",
    "x_vals = [10**alpha for alpha in alphas]\n",
    "plt.figure()\n",
    "plt.xscale('log')\n",
    "plt.plot(x_vals, y['synflow'], label='Synflow', linestyle='-', marker='o', color='r')\n",
    "plt.plot(x_vals, y['mag'], label='Mag', linestyle='-', marker='o', color='b')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Y-axis')\n",
    "plt.title('Synflow vs Mag')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Save plot\n",
    "plt.savefig('../save/tesasdt-plot.png'.format())\n",
    "\n",
    "# Show plot\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

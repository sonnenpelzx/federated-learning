{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# Python version: 3.6\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "\n",
    "from utils.sampling import mnist_iid, mnist_noniid, cifar_iid\n",
    "from utils.options import args_parser\n",
    "from models.Update import LocalUpdate\n",
    "from models.Nets import MLP, CNNMnist, CNNCifar\n",
    "from models.Fed import FedAvg\n",
    "from models.test import test_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seed settings\n",
    "- If you want the seed to be set manually, uncomment and set the seed value in these files:\n",
    "- also change uncomment the lines with `torch.backends.cudnn.deterministic = True`\n",
    "1. utils/sampling.py\n",
    "2. main_fed.py\n",
    "3. models/Nets.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the layer-colapse.py\n",
    "- This command is equivalent to running it from the console\n",
    "- Results are saved in federated-learning/save/test.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "fedspa\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   0, Average loss 2.300\n",
      "fedspa\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   1, Average loss 2.226\n",
      "fedspa\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   2, Average loss 1.469\n",
      "fedspa\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   3, Average loss 0.478\n",
      "fedspa\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   4, Average loss 0.098\n",
      "fedspa\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   5, Average loss 0.106\n",
      "fedspa\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   6, Average loss 0.036\n",
      "fedspa\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   7, Average loss 0.048\n",
      "fedspa\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   8, Average loss 0.029\n",
      "fedspa\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   9, Average loss 0.004\n",
      "Training accuracy: 29.50\n",
      "Testing accuracy: 29.24\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "2420111.5\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   0, Average loss 2.300\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "2465894.5\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   1, Average loss 2.221\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "3019787.8\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   2, Average loss 1.417\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "5519791.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   3, Average loss 0.461\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "7895840.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   4, Average loss 0.169\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "9219939.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   5, Average loss 0.003\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "9495955.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   6, Average loss 0.001\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "9604475.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   7, Average loss 0.001\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "9673476.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   8, Average loss 0.000\n",
      "mag\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "9724114.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   9, Average loss 0.000\n",
      "Training accuracy: 28.63\n",
      "Testing accuracy: 28.04\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "2420111.5\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   0, Average loss 2.300\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "2465894.5\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   1, Average loss 2.221\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "3019787.8\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   2, Average loss 1.417\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "5519791.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   3, Average loss 0.461\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "7895840.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   4, Average loss 0.169\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "9219939.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   5, Average loss 0.003\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "9495955.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   6, Average loss 0.001\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "9604475.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   7, Average loss 0.001\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "9673476.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   8, Average loss 0.000\n",
      "synflow\n",
      "1.0\n",
      "Layer Collapse if = 0\n",
      "9724114.0\n",
      "1345800.0 1345800 0.0 0.0\n",
      "Round   9, Average loss 0.000\n",
      "Training accuracy: 28.63\n",
      "Testing accuracy: 28.04\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "fedspa\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   0, Average loss 2.302\n",
      "fedspa\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   1, Average loss 2.302\n",
      "fedspa\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   2, Average loss 2.301\n",
      "fedspa\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   3, Average loss 2.300\n",
      "fedspa\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   4, Average loss 2.297\n",
      "fedspa\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   5, Average loss 2.229\n",
      "fedspa\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   6, Average loss 1.687\n",
      "fedspa\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   7, Average loss 1.080\n",
      "fedspa\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   8, Average loss 0.752\n",
      "fedspa\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   9, Average loss 0.480\n",
      "Training accuracy: 25.12\n",
      "Testing accuracy: 24.31\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "1948746.2\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   0, Average loss 2.300\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "1981941.0\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   1, Average loss 2.241\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "2354046.5\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   2, Average loss 1.554\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "3921942.2\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   3, Average loss 0.716\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "5815302.5\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   4, Average loss 0.258\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "7162219.5\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   5, Average loss 0.103\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "7802837.5\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   6, Average loss 0.002\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "7972709.5\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   7, Average loss 0.001\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "8065975.0\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   8, Average loss 0.001\n",
      "mag\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "8129949.5\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   9, Average loss 0.000\n",
      "Training accuracy: 29.08\n",
      "Testing accuracy: 29.21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "2027163.0\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   0, Average loss 2.300\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "2064235.2\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   1, Average loss 2.232\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "2473613.2\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   2, Average loss 1.536\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "4139621.0\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   3, Average loss 0.648\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "6132070.5\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   4, Average loss 0.233\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "7604765.5\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   5, Average loss 0.077\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "8248672.5\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   6, Average loss 0.002\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "8416962.0\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   7, Average loss 0.001\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "8506518.0\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   8, Average loss 0.001\n",
      "synflow\n",
      "1.5848931924611136\n",
      "Layer Collapse if = 0\n",
      "8566657.0\n",
      "849143.0 1345800 496657.60579855595 0.36904265551980675\n",
      "Round   9, Average loss 0.000\n",
      "Training accuracy: 28.73\n",
      "Testing accuracy: 28.62\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "fedspa\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   0, Average loss 2.303\n",
      "fedspa\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   1, Average loss 2.303\n",
      "fedspa\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   2, Average loss 2.302\n",
      "fedspa\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   3, Average loss 2.302\n",
      "fedspa\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   4, Average loss 2.302\n",
      "fedspa\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   5, Average loss 2.302\n",
      "fedspa\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   6, Average loss 2.302\n",
      "fedspa\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   7, Average loss 2.302\n",
      "fedspa\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   8, Average loss 2.302\n",
      "fedspa\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   9, Average loss 2.302\n",
      "Training accuracy: 10.21\n",
      "Testing accuracy: 10.22\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "1255251.1\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   0, Average loss 2.300\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "1272707.2\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   1, Average loss 2.288\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "1360729.0\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   2, Average loss 2.033\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "1947369.5\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   3, Average loss 1.115\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "3369894.5\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   4, Average loss 0.428\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "4680719.0\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   5, Average loss 0.174\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "5574434.0\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   6, Average loss 0.005\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "5781132.0\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   7, Average loss 0.002\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "5884404.0\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   8, Average loss 0.001\n",
      "mag\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "5950140.0\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   9, Average loss 0.001\n",
      "Training accuracy: 29.54\n",
      "Testing accuracy: 28.81\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "1378031.5\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   0, Average loss 2.300\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "1399597.2\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   1, Average loss 2.280\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "1522794.4\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   2, Average loss 2.021\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "2160124.0\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   3, Average loss 1.048\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "3707177.5\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   4, Average loss 0.357\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "4953426.0\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   5, Average loss 0.010\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "5284543.0\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   6, Average loss 0.003\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "5431153.0\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   7, Average loss 0.001\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "5520098.0\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   8, Average loss 0.001\n",
      "synflow\n",
      "2.51188643150958\n",
      "Layer Collapse if = 0\n",
      "5582669.5\n",
      "535773.0 1345800 810027.3698691033 0.6018928294465027\n",
      "Round   9, Average loss 0.001\n",
      "Training accuracy: 28.89\n",
      "Testing accuracy: 28.20\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fedspa\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   0, Average loss 2.303\n",
      "fedspa\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   1, Average loss 2.303\n",
      "fedspa\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   2, Average loss 2.303\n",
      "fedspa\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   3, Average loss 2.303\n",
      "fedspa\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   4, Average loss 2.303\n",
      "fedspa\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   5, Average loss 2.303\n",
      "fedspa\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   6, Average loss 2.303\n",
      "fedspa\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   7, Average loss 2.303\n",
      "fedspa\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   8, Average loss 2.303\n",
      "fedspa\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   9, Average loss 2.303\n",
      "Training accuracy: 12.60\n",
      "Testing accuracy: 12.31\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "721483.5\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   0, Average loss 2.301\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "729074.56\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   1, Average loss 2.297\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "749577.8\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   2, Average loss 2.209\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "920724.1\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   3, Average loss 1.584\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "1497675.0\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   4, Average loss 0.837\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "2274376.0\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   5, Average loss 0.476\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "2982949.8\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   6, Average loss 0.250\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "3574220.0\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   7, Average loss 0.009\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "3759428.5\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   8, Average loss 0.003\n",
      "mag\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "3859301.5\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   9, Average loss 0.002\n",
      "Training accuracy: 28.70\n",
      "Testing accuracy: 28.37\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "819641.2\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   0, Average loss 2.300\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "830634.5\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   1, Average loss 2.292\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "875043.4\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   2, Average loss 2.123\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "1123561.6\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   3, Average loss 1.405\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "1921928.5\n",
      "338049.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   4, Average loss 0.608\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "2828135.0\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   5, Average loss 0.349\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "3536435.0\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   6, Average loss 0.017\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "3807513.0\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   7, Average loss 0.197\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "4307452.5\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   8, Average loss 0.003\n",
      "synflow\n",
      "3.9810717055349722\n",
      "Layer Collapse if = 0\n",
      "4421082.5\n",
      "338050.0 1345800 1007750.3240474407 0.748811356849042\n",
      "Round   9, Average loss 0.001\n",
      "Training accuracy: 29.92\n",
      "Testing accuracy: 29.34\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "fedspa\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   0, Average loss 2.303\n",
      "fedspa\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   1, Average loss 2.303\n",
      "fedspa\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   2, Average loss 2.303\n",
      "fedspa\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   3, Average loss 2.303\n",
      "fedspa\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   4, Average loss 2.303\n",
      "fedspa\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   5, Average loss 2.303\n",
      "fedspa\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   6, Average loss 2.303\n",
      "fedspa\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   7, Average loss 2.303\n",
      "fedspa\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   8, Average loss 2.303\n",
      "fedspa\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   9, Average loss 2.303\n",
      "Training accuracy: 9.77\n",
      "Testing accuracy: 9.98\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "371311.38\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   0, Average loss 2.301\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "374981.22\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   1, Average loss 2.299\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "382644.06\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   2, Average loss 2.258\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "433231.4\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   3, Average loss 1.776\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "656981.1\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   4, Average loss 1.305\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "948678.1\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   5, Average loss 0.840\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "1359565.1\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round   6, Average loss 0.522\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "1878103.0\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   7, Average loss 0.328\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "2429295.0\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   8, Average loss 0.217\n",
      "mag\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "2873093.5\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   9, Average loss 0.086\n",
      "Training accuracy: 29.59\n",
      "Testing accuracy: 29.24\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "472993.62\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   0, Average loss 2.301\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "477417.5\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   1, Average loss 2.299\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "488193.75\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   2, Average loss 2.269\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "545841.6\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   3, Average loss 1.808\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "843044.2\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   4, Average loss 1.133\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "1290228.0\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   5, Average loss 0.705\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "1832969.2\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   6, Average loss 0.456\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "2447075.5\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   7, Average loss 0.281\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "3054248.0\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   8, Average loss 0.044\n",
      "synflow\n",
      "6.309573444801933\n",
      "Layer Collapse if = 0\n",
      "3261790.5\n",
      "213295.0 1345800 1132505.0741585833 0.8415106807538887\n",
      "Round   9, Average loss 0.062\n",
      "Training accuracy: 28.09\n",
      "Testing accuracy: 27.91\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "fedspa\n",
      "134580.0 1345800 1211220.0 0.9\n",
      "Round   0, Average loss 2.303\n",
      "fedspa\n",
      "134580.0 1345800 1211220.0 0.9\n",
      "Round   1, Average loss 2.303\n",
      "fedspa\n",
      "134580.0 1345800 1211220.0 0.9\n",
      "Round   2, Average loss 2.303\n",
      "fedspa\n",
      "134580.0 1345800 1211220.0 0.9\n",
      "Round   3, Average loss 2.303\n",
      "fedspa\n",
      "134580.0 1345800 1211220.0 0.9\n",
      "Round   4, Average loss 2.303\n",
      "fedspa\n",
      "134580.0 1345800 1211220.0 0.9\n",
      "Round   5, Average loss 2.303\n",
      "fedspa\n",
      "134580.0 1345800 1211220.0 0.9\n",
      "Round   6, Average loss 2.303\n",
      "fedspa\n",
      "134580.0 1345800 1211220.0 0.9\n",
      "Round   7, Average loss 2.303\n",
      "fedspa\n",
      "134580.0 1345800 1211220.0 0.9\n",
      "Round   8, Average loss 2.303\n",
      "fedspa\n",
      "134580.0 1345800 1211220.0 0.9\n",
      "Round   9, Average loss 2.303\n",
      "Training accuracy: 10.08\n",
      "Testing accuracy: 10.18\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "mag\n",
      "10.0\n",
      "Layer Collapse if = 0\n",
      "150454.3\n",
      "134580.0 1345800 1211220.0 0.9\n",
      "Round   0, Average loss 2.301\n",
      "mag\n",
      "10.0\n",
      "Layer Collapse if = 0\n",
      "151912.47\n",
      "134580.0 1345800 1211220.0 0.9\n",
      "Round   1, Average loss 2.299\n",
      "mag\n",
      "10.0\n",
      "Layer Collapse if = 0\n",
      "154835.31\n",
      "134580.0 1345800 1211220.0 0.9\n",
      "Round   2, Average loss 2.250\n",
      "mag\n",
      "10.0\n",
      "Layer Collapse if = 0\n",
      "170715.52\n",
      "134580.0 1345800 1211220.0 0.9\n",
      "Round   3, Average loss 2.056\n",
      "mag\n",
      "10.0\n",
      "Layer Collapse if = 0\n",
      "206146.94\n",
      "134580.0 1345800 1211220.0 0.9\n",
      "Round   4, Average loss 1.782\n",
      "mag\n",
      "10.0\n",
      "Layer Collapse if = 0\n",
      "283933.25\n",
      "134580.0 1345800 1211220.0 0.9\n",
      "Round   5, Average loss 1.263\n",
      "mag\n",
      "10.0\n",
      "Layer Collapse if = 0\n",
      "418451.25\n",
      "134580.0 1345800 1211220.0 0.9\n",
      "Round   6, Average loss 0.913\n",
      "mag\n",
      "10.0\n",
      "Layer Collapse if = 0\n",
      "607391.1\n",
      "134580.0 1345800 1211220.0 0.9\n",
      "Round   7, Average loss 0.579\n",
      "mag\n",
      "10.0\n",
      "Layer Collapse if = 0\n",
      "891065.9\n",
      "134580.0 1345800 1211220.0 0.9\n",
      "Round   8, Average loss 0.380\n",
      "mag\n",
      "10.0\n",
      "Layer Collapse if = 0\n",
      "1219582.8\n",
      "134580.0 1345800 1211220.0 0.9\n",
      "Round   9, Average loss 0.287\n",
      "Training accuracy: 25.90\n",
      "Testing accuracy: 26.73\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "synflow\n",
      "10.0\n",
      "Layer Collapse if = 0\n",
      "264690.6\n",
      "134580.0 1345800 1211220.0 0.9\n",
      "Round   0, Average loss 2.302\n",
      "synflow\n",
      "10.0\n",
      "Layer Collapse if = 0\n",
      "266169.03\n",
      "134580.0 1345800 1211220.0 0.9\n",
      "Round   1, Average loss 2.301\n",
      "synflow\n",
      "10.0\n",
      "Layer Collapse if = 0\n",
      "269125.78\n",
      "134580.0 1345800 1211220.0 0.9\n",
      "Round   2, Average loss 2.297\n",
      "synflow\n",
      "10.0\n",
      "Layer Collapse if = 0\n",
      "277477.9\n",
      "134580.0 1345800 1211220.0 0.9\n",
      "Round   3, Average loss 2.190\n",
      "synflow\n",
      "10.0\n",
      "Layer Collapse if = 0\n",
      "325684.5\n",
      "134580.0 1345800 1211220.0 0.9\n",
      "Round   4, Average loss 1.747\n",
      "synflow\n",
      "10.0\n",
      "Layer Collapse if = 0\n",
      "489594.88\n",
      "134580.0 1345800 1211220.0 0.9\n",
      "Round   5, Average loss 1.210\n",
      "synflow\n",
      "10.0\n",
      "Layer Collapse if = 0\n",
      "769415.3\n",
      "134580.0 1345800 1211220.0 0.9\n",
      "Round   6, Average loss 0.750\n",
      "synflow\n",
      "10.0\n",
      "Layer Collapse if = 0\n",
      "1215912.8\n",
      "134579.0 1345800 1211220.0 0.9\n",
      "Round   7, Average loss 0.444\n",
      "synflow\n",
      "10.0\n",
      "Layer Collapse if = 0\n",
      "1750995.9\n",
      "134580.0 1345800 1211220.0 0.9\n",
      "Round   8, Average loss 0.221\n",
      "synflow\n",
      "10.0\n",
      "Layer Collapse if = 0\n",
      "2221665.5\n",
      "134580.0 1345800 1211220.0 0.9\n",
      "Round   9, Average loss 0.018\n",
      "Training accuracy: 27.06\n",
      "Testing accuracy: 26.80\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "fedspa\n",
      "84915.0 1345800 1260885.7605798556 0.9369042655519807\n",
      "Round   0, Average loss 2.303\n",
      "fedspa\n",
      "84915.0 1345800 1260885.7605798556 0.9369042655519807\n",
      "Round   1, Average loss 2.303\n",
      "fedspa\n",
      "84915.0 1345800 1260885.7605798556 0.9369042655519807\n",
      "Round   2, Average loss 2.303\n",
      "fedspa\n",
      "84915.0 1345800 1260885.7605798556 0.9369042655519807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round   3, Average loss 2.303\n",
      "fedspa\n",
      "84915.0 1345800 1260885.7605798556 0.9369042655519807\n",
      "Round   4, Average loss 2.303\n",
      "fedspa\n",
      "84915.0 1345800 1260885.7605798556 0.9369042655519807\n",
      "Round   5, Average loss 2.303\n",
      "fedspa\n",
      "84915.0 1345800 1260885.7605798556 0.9369042655519807\n",
      "Round   6, Average loss 2.303\n",
      "fedspa\n",
      "84915.0 1345800 1260885.7605798556 0.9369042655519807\n",
      "Round   7, Average loss 2.303\n",
      "fedspa\n",
      "84915.0 1345800 1260885.7605798556 0.9369042655519807\n",
      "Round   8, Average loss 2.303\n",
      "fedspa\n",
      "84915.0 1345800 1260885.7605798556 0.9369042655519807\n",
      "Round   9, Average loss 2.303\n",
      "Training accuracy: 9.82\n",
      "Testing accuracy: 9.90\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "mag\n",
      "15.848931924611133\n",
      "Layer Collapse if = 0\n",
      "11808.525\n",
      "84915.0 1345800 1260885.7605798556 0.9369042655519807\n",
      "Round   0, Average loss 2.301\n",
      "mag\n",
      "15.848931924611133\n",
      "Layer Collapse if = 0\n",
      "11957.374\n",
      "84915.0 1345800 1260885.7605798556 0.9369042655519807\n",
      "Round   1, Average loss 2.295\n",
      "mag\n",
      "15.848931924611133\n",
      "Layer Collapse if = 0\n",
      "12398.58\n",
      "84915.0 1345800 1260885.7605798556 0.9369042655519807\n",
      "Round   2, Average loss 2.160\n",
      "mag\n",
      "15.848931924611133\n",
      "Layer Collapse if = 0\n",
      "14435.443\n",
      "84915.0 1345800 1260885.7605798556 0.9369042655519807\n",
      "Round   3, Average loss 1.953\n",
      "mag\n",
      "15.848931924611133\n",
      "Layer Collapse if = 0\n",
      "18640.527\n",
      "84915.0 1345800 1260885.7605798556 0.9369042655519807\n",
      "Round   4, Average loss 1.747\n",
      "mag\n",
      "15.848931924611133\n",
      "Layer Collapse if = 0\n",
      "24766.434\n",
      "84915.0 1345800 1260885.7605798556 0.9369042655519807\n",
      "Round   5, Average loss 1.656\n",
      "mag\n",
      "15.848931924611133\n",
      "Layer Collapse if = 0\n",
      "36914.61\n",
      "84915.0 1345800 1260885.7605798556 0.9369042655519807\n",
      "Round   6, Average loss 1.415\n",
      "mag\n",
      "15.848931924611133\n",
      "Layer Collapse if = 0\n",
      "66089.516\n",
      "84915.0 1345800 1260885.7605798556 0.9369042655519807\n",
      "Round   7, Average loss 1.164\n",
      "mag\n",
      "15.848931924611133\n",
      "Layer Collapse if = 0\n",
      "143578.25\n",
      "84915.0 1345800 1260885.7605798556 0.9369042655519807\n",
      "Round   8, Average loss 0.881\n",
      "mag\n",
      "15.848931924611133\n",
      "Layer Collapse if = 0\n",
      "289481.78\n",
      "84915.0 1345800 1260885.7605798556 0.9369042655519807\n",
      "Round   9, Average loss 0.691\n",
      "Training accuracy: 28.06\n",
      "Testing accuracy: 27.95\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "synflow\n",
      "15.848931924611133\n",
      "Layer Collapse if = 0\n",
      "132194.27\n",
      "84915.0 1345800 1260885.7605798556 0.9369042655519807\n",
      "Round   0, Average loss 2.302\n",
      "synflow\n",
      "15.848931924611133\n",
      "Layer Collapse if = 0\n",
      "132643.39\n",
      "84915.0 1345800 1260885.7605798556 0.9369042655519807\n",
      "Round   1, Average loss 2.302\n",
      "synflow\n",
      "15.848931924611133\n",
      "Layer Collapse if = 0\n",
      "133409.02\n",
      "84915.0 1345800 1260885.7605798556 0.9369042655519807\n",
      "Round   2, Average loss 2.301\n",
      "synflow\n",
      "15.848931924611133\n",
      "Layer Collapse if = 0\n",
      "134693.47\n",
      "84915.0 1345800 1260885.7605798556 0.9369042655519807\n",
      "Round   3, Average loss 2.299\n",
      "synflow\n",
      "15.848931924611133\n",
      "Layer Collapse if = 0\n",
      "137388.2\n",
      "84915.0 1345800 1260885.7605798556 0.9369042655519807\n",
      "Round   4, Average loss 2.253\n",
      "synflow\n",
      "15.848931924611133\n",
      "Layer Collapse if = 0\n",
      "154923.27\n",
      "84915.0 1345800 1260885.7605798556 0.9369042655519807\n",
      "Round   5, Average loss 1.850\n",
      "synflow\n",
      "15.848931924611133\n",
      "Layer Collapse if = 0\n",
      "237362.64\n",
      "84915.0 1345800 1260885.7605798556 0.9369042655519807\n",
      "Round   6, Average loss 1.405\n",
      "synflow\n",
      "15.848931924611133\n",
      "Layer Collapse if = 0\n",
      "388202.06\n",
      "84915.0 1345800 1260885.7605798556 0.9369042655519807\n",
      "Round   7, Average loss 0.997\n",
      "synflow\n",
      "15.848931924611133\n",
      "Layer Collapse if = 0\n",
      "660389.56\n",
      "84915.0 1345800 1260885.7605798556 0.9369042655519807\n",
      "Round   8, Average loss 0.760\n",
      "synflow\n",
      "15.848931924611133\n",
      "Layer Collapse if = 0\n",
      "997076.5\n",
      "84915.0 1345800 1260885.7605798556 0.9369042655519807\n",
      "Round   9, Average loss 0.472\n",
      "Training accuracy: 25.60\n",
      "Testing accuracy: 25.18\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "fedspa\n",
      "53578.0 1345800 1292222.7369869102 0.9601892829446502\n",
      "Round   0, Average loss 2.303\n",
      "fedspa\n",
      "53578.0 1345800 1292222.7369869102 0.9601892829446502\n",
      "Round   1, Average loss 2.303\n",
      "fedspa\n",
      "53578.0 1345800 1292222.7369869102 0.9601892829446502\n",
      "Round   2, Average loss 2.303\n",
      "fedspa\n",
      "53578.0 1345800 1292222.7369869102 0.9601892829446502\n",
      "Round   3, Average loss 2.303\n",
      "fedspa\n",
      "53578.0 1345800 1292222.7369869102 0.9601892829446502\n",
      "Round   4, Average loss 2.303\n",
      "fedspa\n",
      "53578.0 1345800 1292222.7369869102 0.9601892829446502\n",
      "Round   5, Average loss 2.303\n",
      "fedspa\n",
      "53578.0 1345800 1292222.7369869102 0.9601892829446502\n",
      "Round   6, Average loss 2.303\n",
      "fedspa\n",
      "53578.0 1345800 1292222.7369869102 0.9601892829446502\n",
      "Round   7, Average loss 2.303\n",
      "fedspa\n",
      "53578.0 1345800 1292222.7369869102 0.9601892829446502\n",
      "Round   8, Average loss 2.303\n",
      "fedspa\n",
      "53578.0 1345800 1292222.7369869102 0.9601892829446502\n",
      "Round   9, Average loss 2.303\n",
      "Training accuracy: 8.96\n",
      "Testing accuracy: 8.44\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "mag\n",
      "25.118864315095795\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "53578.0 1345800 1292222.7369869102 0.9601892829446502\n",
      "Round   0, Average loss 2.303\n",
      "mag\n",
      "25.118864315095795\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "53578.0 1345800 1292222.7369869102 0.9601892829446502\n",
      "Round   1, Average loss 2.303\n",
      "mag\n",
      "25.118864315095795\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "53578.0 1345800 1292222.7369869102 0.9601892829446502\n",
      "Round   2, Average loss 2.303\n",
      "mag\n",
      "25.118864315095795\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "53578.0 1345800 1292222.7369869102 0.9601892829446502\n",
      "Round   3, Average loss 2.303\n",
      "mag\n",
      "25.118864315095795\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "53578.0 1345800 1292222.7369869102 0.9601892829446502\n",
      "Round   4, Average loss 2.303\n",
      "mag\n",
      "25.118864315095795\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "53578.0 1345800 1292222.7369869102 0.9601892829446502\n",
      "Round   5, Average loss 2.303\n",
      "mag\n",
      "25.118864315095795\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "53578.0 1345800 1292222.7369869102 0.9601892829446502\n",
      "Round   6, Average loss 2.303\n",
      "mag\n",
      "25.118864315095795\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "53578.0 1345800 1292222.7369869102 0.9601892829446502\n",
      "Round   7, Average loss 2.303\n",
      "mag\n",
      "25.118864315095795\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "53578.0 1345800 1292222.7369869102 0.9601892829446502\n",
      "Round   8, Average loss 2.303\n",
      "mag\n",
      "25.118864315095795\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "53578.0 1345800 1292222.7369869102 0.9601892829446502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round   9, Average loss 2.303\n",
      "Training accuracy: 10.00\n",
      "Testing accuracy: 10.00\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "synflow\n",
      "25.118864315095795\n",
      "Layer Collapse if = 0\n",
      "57043.367\n",
      "53578.0 1345800 1292222.7369869102 0.9601892829446502\n",
      "Round   0, Average loss 2.302\n",
      "synflow\n",
      "25.118864315095795\n",
      "Layer Collapse if = 0\n",
      "57198.406\n",
      "53578.0 1345800 1292222.7369869102 0.9601892829446502\n",
      "Round   1, Average loss 2.302\n",
      "synflow\n",
      "25.118864315095795\n",
      "Layer Collapse if = 0\n",
      "57471.383\n",
      "53578.0 1345800 1292222.7369869102 0.9601892829446502\n",
      "Round   2, Average loss 2.302\n",
      "synflow\n",
      "25.118864315095795\n",
      "Layer Collapse if = 0\n",
      "57989.105\n",
      "53578.0 1345800 1292222.7369869102 0.9601892829446502\n",
      "Round   3, Average loss 2.294\n",
      "synflow\n",
      "25.118864315095795\n",
      "Layer Collapse if = 0\n",
      "60830.277\n",
      "53578.0 1345800 1292222.7369869102 0.9601892829446502\n",
      "Round   4, Average loss 2.146\n",
      "synflow\n",
      "25.118864315095795\n",
      "Layer Collapse if = 0\n",
      "73197.47\n",
      "53578.0 1345800 1292222.7369869102 0.9601892829446502\n",
      "Round   5, Average loss 1.990\n",
      "synflow\n",
      "25.118864315095795\n",
      "Layer Collapse if = 0\n",
      "93018.05\n",
      "53578.0 1345800 1292222.7369869102 0.9601892829446502\n",
      "Round   6, Average loss 1.889\n",
      "synflow\n",
      "25.118864315095795\n",
      "Layer Collapse if = 0\n",
      "129092.3\n",
      "53578.0 1345800 1292222.7369869102 0.9601892829446502\n",
      "Round   7, Average loss 1.551\n",
      "synflow\n",
      "25.118864315095795\n",
      "Layer Collapse if = 0\n",
      "221736.34\n",
      "53578.0 1345800 1292222.7369869102 0.9601892829446502\n",
      "Round   8, Average loss 1.202\n",
      "synflow\n",
      "25.118864315095795\n",
      "Layer Collapse if = 0\n",
      "354728.4\n",
      "53578.0 1345800 1292222.7369869102 0.9601892829446502\n",
      "Round   9, Average loss 1.007\n",
      "Training accuracy: 23.66\n",
      "Testing accuracy: 23.56\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "fedspa\n",
      "33805.0 1345800 1311995.032404744 0.9748811356849042\n",
      "Round   0, Average loss 2.303\n",
      "fedspa\n",
      "33805.0 1345800 1311995.032404744 0.9748811356849042\n",
      "Round   1, Average loss 2.303\n",
      "fedspa\n",
      "33805.0 1345800 1311995.032404744 0.9748811356849042\n",
      "Round   2, Average loss 2.303\n",
      "fedspa\n",
      "33805.0 1345800 1311995.032404744 0.9748811356849042\n",
      "Round   3, Average loss 2.303\n",
      "fedspa\n",
      "33805.0 1345800 1311995.032404744 0.9748811356849042\n",
      "Round   4, Average loss 2.303\n",
      "fedspa\n",
      "33805.0 1345800 1311995.032404744 0.9748811356849042\n",
      "Round   5, Average loss 2.303\n",
      "fedspa\n",
      "33805.0 1345800 1311995.032404744 0.9748811356849042\n",
      "Round   6, Average loss 2.303\n",
      "fedspa\n",
      "33805.0 1345800 1311995.032404744 0.9748811356849042\n",
      "Round   7, Average loss 2.303\n",
      "fedspa\n",
      "33805.0 1345800 1311995.032404744 0.9748811356849042\n",
      "Round   8, Average loss 2.303\n",
      "fedspa\n",
      "33805.0 1345800 1311995.032404744 0.9748811356849042\n",
      "Round   9, Average loss 2.303\n",
      "Training accuracy: 9.46\n",
      "Testing accuracy: 9.57\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "mag\n",
      "39.810717055349734\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "33805.0 1345800 1311995.032404744 0.9748811356849042\n",
      "Round   0, Average loss 2.303\n",
      "mag\n",
      "39.810717055349734\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "33805.0 1345800 1311995.032404744 0.9748811356849042\n",
      "Round   1, Average loss 2.303\n",
      "mag\n",
      "39.810717055349734\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "33805.0 1345800 1311995.032404744 0.9748811356849042\n",
      "Round   2, Average loss 2.303\n",
      "mag\n",
      "39.810717055349734\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "33805.0 1345800 1311995.032404744 0.9748811356849042\n",
      "Round   3, Average loss 2.303\n",
      "mag\n",
      "39.810717055349734\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "33805.0 1345800 1311995.032404744 0.9748811356849042\n",
      "Round   4, Average loss 2.303\n",
      "mag\n",
      "39.810717055349734\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "33805.0 1345800 1311995.032404744 0.9748811356849042\n",
      "Round   5, Average loss 2.303\n",
      "mag\n",
      "39.810717055349734\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "33805.0 1345800 1311995.032404744 0.9748811356849042\n",
      "Round   6, Average loss 2.303\n",
      "mag\n",
      "39.810717055349734\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "33805.0 1345800 1311995.032404744 0.9748811356849042\n",
      "Round   7, Average loss 2.303\n",
      "mag\n",
      "39.810717055349734\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "33805.0 1345800 1311995.032404744 0.9748811356849042\n",
      "Round   8, Average loss 2.303\n",
      "mag\n",
      "39.810717055349734\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "33805.0 1345800 1311995.032404744 0.9748811356849042\n",
      "Round   9, Average loss 2.303\n",
      "Training accuracy: 10.00\n",
      "Testing accuracy: 10.00\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "synflow\n",
      "39.810717055349734\n",
      "Layer Collapse if = 0\n",
      "19297.598\n",
      "33805.0 1345800 1311995.032404744 0.9748811356849042\n",
      "Round   0, Average loss 2.302\n",
      "synflow\n",
      "39.810717055349734\n",
      "Layer Collapse if = 0\n",
      "19328.604\n",
      "33805.0 1345800 1311995.032404744 0.9748811356849042\n",
      "Round   1, Average loss 2.302\n",
      "synflow\n",
      "39.810717055349734\n",
      "Layer Collapse if = 0\n",
      "19378.559\n",
      "33805.0 1345800 1311995.032404744 0.9748811356849042\n",
      "Round   2, Average loss 2.302\n",
      "synflow\n",
      "39.810717055349734\n",
      "Layer Collapse if = 0\n",
      "19453.625\n",
      "33805.0 1345800 1311995.032404744 0.9748811356849042\n",
      "Round   3, Average loss 2.302\n",
      "synflow\n",
      "39.810717055349734\n",
      "Layer Collapse if = 0\n",
      "19568.248\n",
      "33805.0 1345800 1311995.032404744 0.9748811356849042\n",
      "Round   4, Average loss 2.301\n",
      "synflow\n",
      "39.810717055349734\n",
      "Layer Collapse if = 0\n",
      "19795.438\n",
      "33805.0 1345800 1311995.032404744 0.9748811356849042\n",
      "Round   5, Average loss 2.281\n",
      "synflow\n",
      "39.810717055349734\n",
      "Layer Collapse if = 0\n",
      "21473.342\n",
      "33805.0 1345800 1311995.032404744 0.9748811356849042\n",
      "Round   6, Average loss 2.129\n",
      "synflow\n",
      "39.810717055349734\n",
      "Layer Collapse if = 0\n",
      "28247.975\n",
      "33805.0 1345800 1311995.032404744 0.9748811356849042\n",
      "Round   7, Average loss 1.992\n",
      "synflow\n",
      "39.810717055349734\n",
      "Layer Collapse if = 0\n",
      "39351.484\n",
      "33805.0 1345800 1311995.032404744 0.9748811356849042\n",
      "Round   8, Average loss 1.950\n",
      "synflow\n",
      "39.810717055349734\n",
      "Layer Collapse if = 0\n",
      "50073.17\n",
      "33805.0 1345800 1311995.032404744 0.9748811356849042\n",
      "Round   9, Average loss 1.924\n",
      "Training accuracy: 13.21\n",
      "Testing accuracy: 13.24\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fedspa\n",
      "21329.0 1345800 1324470.5074158583 0.9841510680753889\n",
      "Round   0, Average loss 2.303\n",
      "fedspa\n",
      "21329.0 1345800 1324470.5074158583 0.9841510680753889\n",
      "Round   1, Average loss 2.303\n",
      "fedspa\n",
      "21329.0 1345800 1324470.5074158583 0.9841510680753889\n",
      "Round   2, Average loss 2.303\n",
      "fedspa\n",
      "21329.0 1345800 1324470.5074158583 0.9841510680753889\n",
      "Round   3, Average loss 2.303\n",
      "fedspa\n",
      "21329.0 1345800 1324470.5074158583 0.9841510680753889\n",
      "Round   4, Average loss 2.303\n",
      "fedspa\n",
      "21329.0 1345800 1324470.5074158583 0.9841510680753889\n",
      "Round   5, Average loss 2.303\n",
      "fedspa\n",
      "21329.0 1345800 1324470.5074158583 0.9841510680753889\n",
      "Round   6, Average loss 2.303\n",
      "fedspa\n",
      "21329.0 1345800 1324470.5074158583 0.9841510680753889\n",
      "Round   7, Average loss 2.303\n",
      "fedspa\n",
      "21329.0 1345800 1324470.5074158583 0.9841510680753889\n",
      "Round   8, Average loss 2.303\n",
      "fedspa\n",
      "21329.0 1345800 1324470.5074158583 0.9841510680753889\n",
      "Round   9, Average loss 2.303\n",
      "Training accuracy: 10.35\n",
      "Testing accuracy: 10.17\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "mag\n",
      "63.09573444801933\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "21330.0 1345800 1324470.5074158583 0.9841510680753889\n",
      "Round   0, Average loss 2.303\n",
      "mag\n",
      "63.09573444801933\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "21330.0 1345800 1324470.5074158583 0.9841510680753889\n",
      "Round   1, Average loss 2.303\n",
      "mag\n",
      "63.09573444801933\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "21330.0 1345800 1324470.5074158583 0.9841510680753889\n",
      "Round   2, Average loss 2.303\n",
      "mag\n",
      "63.09573444801933\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "21330.0 1345800 1324470.5074158583 0.9841510680753889\n",
      "Round   3, Average loss 2.303\n",
      "mag\n",
      "63.09573444801933\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "21330.0 1345800 1324470.5074158583 0.9841510680753889\n",
      "Round   4, Average loss 2.303\n",
      "mag\n",
      "63.09573444801933\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "21330.0 1345800 1324470.5074158583 0.9841510680753889\n",
      "Round   5, Average loss 2.303\n",
      "mag\n",
      "63.09573444801933\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "21330.0 1345800 1324470.5074158583 0.9841510680753889\n",
      "Round   6, Average loss 2.303\n",
      "mag\n",
      "63.09573444801933\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "21330.0 1345800 1324470.5074158583 0.9841510680753889\n",
      "Round   7, Average loss 2.303\n",
      "mag\n",
      "63.09573444801933\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "21330.0 1345800 1324470.5074158583 0.9841510680753889\n",
      "Round   8, Average loss 2.303\n",
      "mag\n",
      "63.09573444801933\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "21330.0 1345800 1324470.5074158583 0.9841510680753889\n",
      "Round   9, Average loss 2.303\n",
      "Training accuracy: 10.00\n",
      "Testing accuracy: 10.00\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "synflow\n",
      "63.09573444801933\n",
      "Layer Collapse if = 0\n",
      "5462.5493\n",
      "21330.0 1345800 1324470.5074158583 0.9841510680753889\n",
      "Round   0, Average loss 2.302\n",
      "synflow\n",
      "63.09573444801933\n",
      "Layer Collapse if = 0\n",
      "5474.4316\n",
      "21330.0 1345800 1324470.5074158583 0.9841510680753889\n",
      "Round   1, Average loss 2.302\n",
      "synflow\n",
      "63.09573444801933\n",
      "Layer Collapse if = 0\n",
      "5491.9546\n",
      "21330.0 1345800 1324470.5074158583 0.9841510680753889\n",
      "Round   2, Average loss 2.302\n",
      "synflow\n",
      "63.09573444801933\n",
      "Layer Collapse if = 0\n",
      "5517.5654\n",
      "21330.0 1345800 1324470.5074158583 0.9841510680753889\n",
      "Round   3, Average loss 2.302\n",
      "synflow\n",
      "63.09573444801933\n",
      "Layer Collapse if = 0\n",
      "5559.1284\n",
      "21330.0 1345800 1324470.5074158583 0.9841510680753889\n",
      "Round   4, Average loss 2.301\n",
      "synflow\n",
      "63.09573444801933\n",
      "Layer Collapse if = 0\n",
      "5665.4595\n",
      "21330.0 1345800 1324470.5074158583 0.9841510680753889\n",
      "Round   5, Average loss 2.271\n",
      "synflow\n",
      "63.09573444801933\n",
      "Layer Collapse if = 0\n",
      "6999.6523\n",
      "21330.0 1345800 1324470.5074158583 0.9841510680753889\n",
      "Round   6, Average loss 2.119\n",
      "synflow\n",
      "63.09573444801933\n",
      "Layer Collapse if = 0\n",
      "12007.918\n",
      "21330.0 1345800 1324470.5074158583 0.9841510680753889\n",
      "Round   7, Average loss 2.004\n",
      "synflow\n",
      "63.09573444801933\n",
      "Layer Collapse if = 0\n",
      "18958.19\n",
      "21330.0 1345800 1324470.5074158583 0.9841510680753889\n",
      "Round   8, Average loss 1.959\n",
      "synflow\n",
      "63.09573444801933\n",
      "Layer Collapse if = 0\n",
      "25539.98\n",
      "21330.0 1345800 1324470.5074158583 0.9841510680753889\n",
      "Round   9, Average loss 1.934\n",
      "Training accuracy: 13.69\n",
      "Testing accuracy: 13.84\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "fedspa\n",
      "13457.0 1345800 1332342.0 0.99\n",
      "Round   0, Average loss 2.303\n",
      "fedspa\n",
      "13457.0 1345800 1332342.0 0.99\n",
      "Round   1, Average loss 2.303\n",
      "fedspa\n",
      "13457.0 1345800 1332342.0 0.99\n",
      "Round   2, Average loss 2.303\n",
      "fedspa\n",
      "13457.0 1345800 1332342.0 0.99\n",
      "Round   3, Average loss 2.303\n",
      "fedspa\n",
      "13457.0 1345800 1332342.0 0.99\n",
      "Round   4, Average loss 2.303\n",
      "fedspa\n",
      "13457.0 1345800 1332342.0 0.99\n",
      "Round   5, Average loss 2.303\n",
      "fedspa\n",
      "13457.0 1345800 1332342.0 0.99\n",
      "Round   6, Average loss 2.303\n",
      "fedspa\n",
      "13457.0 1345800 1332342.0 0.99\n",
      "Round   7, Average loss 2.303\n",
      "fedspa\n",
      "13457.0 1345800 1332342.0 0.99\n",
      "Round   8, Average loss 2.303\n",
      "fedspa\n",
      "13457.0 1345800 1332342.0 0.99\n",
      "Round   9, Average loss 2.303\n",
      "Training accuracy: 9.93\n",
      "Testing accuracy: 9.96\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "mag\n",
      "100.0\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "13458.0 1345800 1332342.0 0.99\n",
      "Round   0, Average loss 2.303\n",
      "mag\n",
      "100.0\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "13458.0 1345800 1332342.0 0.99\n",
      "Round   1, Average loss 2.303\n",
      "mag\n",
      "100.0\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "13458.0 1345800 1332342.0 0.99\n",
      "Round   2, Average loss 2.303\n",
      "mag\n",
      "100.0\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "13458.0 1345800 1332342.0 0.99\n",
      "Round   3, Average loss 2.303\n",
      "mag\n",
      "100.0\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "13458.0 1345800 1332342.0 0.99\n",
      "Round   4, Average loss 2.303\n",
      "mag\n",
      "100.0\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "13458.0 1345800 1332342.0 0.99\n",
      "Round   5, Average loss 2.303\n",
      "mag\n",
      "100.0\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "13458.0 1345800 1332342.0 0.99\n",
      "Round   6, Average loss 2.303\n",
      "mag\n",
      "100.0\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "13458.0 1345800 1332342.0 0.99\n",
      "Round   7, Average loss 2.303\n",
      "mag\n",
      "100.0\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "13458.0 1345800 1332342.0 0.99\n",
      "Round   8, Average loss 2.303\n",
      "mag\n",
      "100.0\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "13458.0 1345800 1332342.0 0.99\n",
      "Round   9, Average loss 2.303\n",
      "Training accuracy: 10.00\n",
      "Testing accuracy: 10.00\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synflow\n",
      "100.0\n",
      "Layer Collapse if = 0\n",
      "1591.451\n",
      "13458.0 1345800 1332342.0 0.99\n",
      "Round   0, Average loss 2.303\n",
      "synflow\n",
      "100.0\n",
      "Layer Collapse if = 0\n",
      "1595.508\n",
      "13458.0 1345800 1332342.0 0.99\n",
      "Round   1, Average loss 2.302\n",
      "synflow\n",
      "100.0\n",
      "Layer Collapse if = 0\n",
      "1600.9598\n",
      "13458.0 1345800 1332342.0 0.99\n",
      "Round   2, Average loss 2.302\n",
      "synflow\n",
      "100.0\n",
      "Layer Collapse if = 0\n",
      "1608.4794\n",
      "13458.0 1345800 1332342.0 0.99\n",
      "Round   3, Average loss 2.302\n",
      "synflow\n",
      "100.0\n",
      "Layer Collapse if = 0\n",
      "1619.936\n",
      "13458.0 1345800 1332342.0 0.99\n",
      "Round   4, Average loss 2.302\n",
      "synflow\n",
      "100.0\n",
      "Layer Collapse if = 0\n",
      "1639.7871\n",
      "13458.0 1345800 1332342.0 0.99\n",
      "Round   5, Average loss 2.301\n",
      "synflow\n",
      "100.0\n",
      "Layer Collapse if = 0\n",
      "1695.595\n",
      "13458.0 1345800 1332342.0 0.99\n",
      "Round   6, Average loss 2.262\n",
      "synflow\n",
      "100.0\n",
      "Layer Collapse if = 0\n",
      "2365.9202\n",
      "13458.0 1345800 1332342.0 0.99\n",
      "Round   7, Average loss 2.110\n",
      "synflow\n",
      "100.0\n",
      "Layer Collapse if = 0\n",
      "5279.591\n",
      "13458.0 1345800 1332342.0 0.99\n",
      "Round   8, Average loss 1.997\n",
      "synflow\n",
      "100.0\n",
      "Layer Collapse if = 0\n",
      "9304.584\n",
      "13458.0 1345800 1332342.0 0.99\n",
      "Round   9, Average loss 1.971\n",
      "Training accuracy: 9.95\n",
      "Testing accuracy: 9.95\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "fedspa\n",
      "8492.0 1345800 1337308.5760579857 0.9936904265551981\n",
      "Round   0, Average loss 2.303\n",
      "fedspa\n",
      "8492.0 1345800 1337308.5760579857 0.9936904265551981\n",
      "Round   1, Average loss 2.303\n",
      "fedspa\n",
      "8492.0 1345800 1337308.5760579857 0.9936904265551981\n",
      "Round   2, Average loss 2.303\n",
      "fedspa\n",
      "8492.0 1345800 1337308.5760579857 0.9936904265551981\n",
      "Round   3, Average loss 2.303\n",
      "fedspa\n",
      "8492.0 1345800 1337308.5760579857 0.9936904265551981\n",
      "Round   4, Average loss 2.303\n",
      "fedspa\n",
      "8492.0 1345800 1337308.5760579857 0.9936904265551981\n",
      "Round   5, Average loss 2.303\n",
      "fedspa\n",
      "8492.0 1345800 1337308.5760579857 0.9936904265551981\n",
      "Round   6, Average loss 2.303\n",
      "fedspa\n",
      "8492.0 1345800 1337308.5760579857 0.9936904265551981\n",
      "Round   7, Average loss 2.303\n",
      "fedspa\n",
      "8492.0 1345800 1337308.5760579857 0.9936904265551981\n",
      "Round   8, Average loss 2.303\n",
      "fedspa\n",
      "8492.0 1345800 1337308.5760579857 0.9936904265551981\n",
      "Round   9, Average loss 2.303\n",
      "Training accuracy: 11.66\n",
      "Testing accuracy: 11.89\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "mag\n",
      "158.48931924611142\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "8492.0 1345800 1337308.5760579857 0.9936904265551981\n",
      "Round   0, Average loss 2.303\n",
      "mag\n",
      "158.48931924611142\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "8492.0 1345800 1337308.5760579857 0.9936904265551981\n",
      "Round   1, Average loss 2.303\n",
      "mag\n",
      "158.48931924611142\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "8492.0 1345800 1337308.5760579857 0.9936904265551981\n",
      "Round   2, Average loss 2.303\n",
      "mag\n",
      "158.48931924611142\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "8492.0 1345800 1337308.5760579857 0.9936904265551981\n",
      "Round   3, Average loss 2.303\n",
      "mag\n",
      "158.48931924611142\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "8492.0 1345800 1337308.5760579857 0.9936904265551981\n",
      "Round   4, Average loss 2.303\n",
      "mag\n",
      "158.48931924611142\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "8492.0 1345800 1337308.5760579857 0.9936904265551981\n",
      "Round   5, Average loss 2.303\n",
      "mag\n",
      "158.48931924611142\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "8492.0 1345800 1337308.5760579857 0.9936904265551981\n",
      "Round   6, Average loss 2.303\n",
      "mag\n",
      "158.48931924611142\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "8492.0 1345800 1337308.5760579857 0.9936904265551981\n",
      "Round   7, Average loss 2.303\n",
      "mag\n",
      "158.48931924611142\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "8492.0 1345800 1337308.5760579857 0.9936904265551981\n",
      "Round   8, Average loss 2.303\n",
      "mag\n",
      "158.48931924611142\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "8492.0 1345800 1337308.5760579857 0.9936904265551981\n",
      "Round   9, Average loss 2.303\n",
      "Training accuracy: 10.00\n",
      "Testing accuracy: 10.00\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "synflow\n",
      "158.48931924611142\n",
      "Layer Collapse if = 0\n",
      "464.53488\n",
      "8492.0 1345800 1337308.5760579857 0.9936904265551981\n",
      "Round   0, Average loss 2.303\n",
      "synflow\n",
      "158.48931924611142\n",
      "Layer Collapse if = 0\n",
      "465.24997\n",
      "8492.0 1345800 1337308.5760579857 0.9936904265551981\n",
      "Round   1, Average loss 2.303\n",
      "synflow\n",
      "158.48931924611142\n",
      "Layer Collapse if = 0\n",
      "466.09705\n",
      "8492.0 1345800 1337308.5760579857 0.9936904265551981\n",
      "Round   2, Average loss 2.303\n",
      "synflow\n",
      "158.48931924611142\n",
      "Layer Collapse if = 0\n",
      "467.09833\n",
      "8492.0 1345800 1337308.5760579857 0.9936904265551981\n",
      "Round   3, Average loss 2.303\n",
      "synflow\n",
      "158.48931924611142\n",
      "Layer Collapse if = 0\n",
      "468.26694\n",
      "8492.0 1345800 1337308.5760579857 0.9936904265551981\n",
      "Round   4, Average loss 2.303\n",
      "synflow\n",
      "158.48931924611142\n",
      "Layer Collapse if = 0\n",
      "469.62994\n",
      "8492.0 1345800 1337308.5760579857 0.9936904265551981\n",
      "Round   5, Average loss 2.303\n",
      "synflow\n",
      "158.48931924611142\n",
      "Layer Collapse if = 0\n",
      "471.25598\n",
      "8492.0 1345800 1337308.5760579857 0.9936904265551981\n",
      "Round   6, Average loss 2.302\n",
      "synflow\n",
      "158.48931924611142\n",
      "Layer Collapse if = 0\n",
      "473.22272\n",
      "8492.0 1345800 1337308.5760579857 0.9936904265551981\n",
      "Round   7, Average loss 2.302\n",
      "synflow\n",
      "158.48931924611142\n",
      "Layer Collapse if = 0\n",
      "475.65244\n",
      "8492.0 1345800 1337308.5760579857 0.9936904265551981\n",
      "Round   8, Average loss 2.302\n",
      "synflow\n",
      "158.48931924611142\n",
      "Layer Collapse if = 0\n",
      "478.79517\n",
      "8492.0 1345800 1337308.5760579857 0.9936904265551981\n",
      "Round   9, Average loss 2.302\n",
      "Training accuracy: 14.03\n",
      "Testing accuracy: 13.79\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "fedspa\n",
      "5358.0 1345800 1340442.273698691 0.996018928294465\n",
      "Round   0, Average loss 2.303\n",
      "fedspa\n",
      "5358.0 1345800 1340442.273698691 0.996018928294465\n",
      "Round   1, Average loss 2.303\n",
      "fedspa\n",
      "5358.0 1345800 1340442.273698691 0.996018928294465\n",
      "Round   2, Average loss 2.303\n",
      "fedspa\n",
      "5358.0 1345800 1340442.273698691 0.996018928294465\n",
      "Round   3, Average loss 2.303\n",
      "fedspa\n",
      "5358.0 1345800 1340442.273698691 0.996018928294465\n",
      "Round   4, Average loss 2.303\n",
      "fedspa\n",
      "5358.0 1345800 1340442.273698691 0.996018928294465\n",
      "Round   5, Average loss 2.303\n",
      "fedspa\n",
      "5358.0 1345800 1340442.273698691 0.996018928294465\n",
      "Round   6, Average loss 2.303\n",
      "fedspa\n",
      "5358.0 1345800 1340442.273698691 0.996018928294465\n",
      "Round   7, Average loss 2.303\n",
      "fedspa\n",
      "5358.0 1345800 1340442.273698691 0.996018928294465\n",
      "Round   8, Average loss 2.303\n",
      "fedspa\n",
      "5358.0 1345800 1340442.273698691 0.996018928294465\n",
      "Round   9, Average loss 2.303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 10.00\n",
      "Testing accuracy: 10.00\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "mag\n",
      "251.18864315095797\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "5358.0 1345800 1340442.273698691 0.996018928294465\n",
      "Round   0, Average loss 2.303\n",
      "mag\n",
      "251.18864315095797\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "5358.0 1345800 1340442.273698691 0.996018928294465\n",
      "Round   1, Average loss 2.303\n",
      "mag\n",
      "251.18864315095797\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "5358.0 1345800 1340442.273698691 0.996018928294465\n",
      "Round   2, Average loss 2.303\n",
      "mag\n",
      "251.18864315095797\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "5358.0 1345800 1340442.273698691 0.996018928294465\n",
      "Round   3, Average loss 2.303\n",
      "mag\n",
      "251.18864315095797\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "5358.0 1345800 1340442.273698691 0.996018928294465\n",
      "Round   4, Average loss 2.303\n",
      "mag\n",
      "251.18864315095797\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "5358.0 1345800 1340442.273698691 0.996018928294465\n",
      "Round   5, Average loss 2.303\n",
      "mag\n",
      "251.18864315095797\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "5358.0 1345800 1340442.273698691 0.996018928294465\n",
      "Round   6, Average loss 2.303\n",
      "mag\n",
      "251.18864315095797\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "5358.0 1345800 1340442.273698691 0.996018928294465\n",
      "Round   7, Average loss 2.303\n",
      "mag\n",
      "251.18864315095797\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "5358.0 1345800 1340442.273698691 0.996018928294465\n",
      "Round   8, Average loss 2.303\n",
      "mag\n",
      "251.18864315095797\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "5358.0 1345800 1340442.273698691 0.996018928294465\n",
      "Round   9, Average loss 2.303\n",
      "Training accuracy: 10.00\n",
      "Testing accuracy: 10.00\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "synflow\n",
      "251.18864315095797\n",
      "Layer Collapse if = 0\n",
      "121.87741\n",
      "5358.0 1345800 1340442.273698691 0.996018928294465\n",
      "Round   0, Average loss 2.303\n",
      "synflow\n",
      "251.18864315095797\n",
      "Layer Collapse if = 0\n",
      "121.937485\n",
      "5358.0 1345800 1340442.273698691 0.996018928294465\n",
      "Round   1, Average loss 2.303\n",
      "synflow\n",
      "251.18864315095797\n",
      "Layer Collapse if = 0\n",
      "122.00252\n",
      "5358.0 1345800 1340442.273698691 0.996018928294465\n",
      "Round   2, Average loss 2.303\n",
      "synflow\n",
      "251.18864315095797\n",
      "Layer Collapse if = 0\n",
      "122.07276\n",
      "5358.0 1345800 1340442.273698691 0.996018928294465\n",
      "Round   3, Average loss 2.303\n",
      "synflow\n",
      "251.18864315095797\n",
      "Layer Collapse if = 0\n",
      "122.148346\n",
      "5358.0 1345800 1340442.273698691 0.996018928294465\n",
      "Round   4, Average loss 2.303\n",
      "synflow\n",
      "251.18864315095797\n",
      "Layer Collapse if = 0\n",
      "122.22952\n",
      "5358.0 1345800 1340442.273698691 0.996018928294465\n",
      "Round   5, Average loss 2.303\n",
      "synflow\n",
      "251.18864315095797\n",
      "Layer Collapse if = 0\n",
      "122.31694\n",
      "5358.0 1345800 1340442.273698691 0.996018928294465\n",
      "Round   6, Average loss 2.303\n",
      "synflow\n",
      "251.18864315095797\n",
      "Layer Collapse if = 0\n",
      "122.41176\n",
      "5358.0 1345800 1340442.273698691 0.996018928294465\n",
      "Round   7, Average loss 2.303\n",
      "synflow\n",
      "251.18864315095797\n",
      "Layer Collapse if = 0\n",
      "122.51325\n",
      "5358.0 1345800 1340442.273698691 0.996018928294465\n",
      "Round   8, Average loss 2.303\n",
      "synflow\n",
      "251.18864315095797\n",
      "Layer Collapse if = 0\n",
      "122.62134\n",
      "5358.0 1345800 1340442.273698691 0.996018928294465\n",
      "Round   9, Average loss 2.303\n",
      "Training accuracy: 9.09\n",
      "Testing accuracy: 9.52\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "fedspa\n",
      "3381.0 1345800 1342419.5032404745 0.9974881135684904\n",
      "Round   0, Average loss 2.303\n",
      "fedspa\n",
      "3381.0 1345800 1342419.5032404745 0.9974881135684904\n",
      "Round   1, Average loss 2.303\n",
      "fedspa\n",
      "3381.0 1345800 1342419.5032404745 0.9974881135684904\n",
      "Round   2, Average loss 2.303\n",
      "fedspa\n",
      "3381.0 1345800 1342419.5032404745 0.9974881135684904\n",
      "Round   3, Average loss 2.303\n",
      "fedspa\n",
      "3381.0 1345800 1342419.5032404745 0.9974881135684904\n",
      "Round   4, Average loss 2.303\n",
      "fedspa\n",
      "3381.0 1345800 1342419.5032404745 0.9974881135684904\n",
      "Round   5, Average loss 2.303\n",
      "fedspa\n",
      "3381.0 1345800 1342419.5032404745 0.9974881135684904\n",
      "Round   6, Average loss 2.303\n",
      "fedspa\n",
      "3381.0 1345800 1342419.5032404745 0.9974881135684904\n",
      "Round   7, Average loss 2.303\n",
      "fedspa\n",
      "3381.0 1345800 1342419.5032404745 0.9974881135684904\n",
      "Round   8, Average loss 2.303\n",
      "fedspa\n",
      "3381.0 1345800 1342419.5032404745 0.9974881135684904\n",
      "Round   9, Average loss 2.303\n",
      "Training accuracy: 10.00\n",
      "Testing accuracy: 10.00\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "mag\n",
      "398.1071705534973\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "3381.0 1345800 1342419.5032404745 0.9974881135684904\n",
      "Round   0, Average loss 2.303\n",
      "mag\n",
      "398.1071705534973\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "3381.0 1345800 1342419.5032404745 0.9974881135684904\n",
      "Round   1, Average loss 2.303\n",
      "mag\n",
      "398.1071705534973\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "3381.0 1345800 1342419.5032404745 0.9974881135684904\n",
      "Round   2, Average loss 2.303\n",
      "mag\n",
      "398.1071705534973\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "3381.0 1345800 1342419.5032404745 0.9974881135684904\n",
      "Round   3, Average loss 2.303\n",
      "mag\n",
      "398.1071705534973\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "3381.0 1345800 1342419.5032404745 0.9974881135684904\n",
      "Round   4, Average loss 2.303\n",
      "mag\n",
      "398.1071705534973\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "3381.0 1345800 1342419.5032404745 0.9974881135684904\n",
      "Round   5, Average loss 2.303\n",
      "mag\n",
      "398.1071705534973\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "3381.0 1345800 1342419.5032404745 0.9974881135684904\n",
      "Round   6, Average loss 2.303\n",
      "mag\n",
      "398.1071705534973\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "3381.0 1345800 1342419.5032404745 0.9974881135684904\n",
      "Round   7, Average loss 2.303\n",
      "mag\n",
      "398.1071705534973\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "3381.0 1345800 1342419.5032404745 0.9974881135684904\n",
      "Round   8, Average loss 2.303\n",
      "mag\n",
      "398.1071705534973\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "3381.0 1345800 1342419.5032404745 0.9974881135684904\n",
      "Round   9, Average loss 2.303\n",
      "Training accuracy: 10.00\n",
      "Testing accuracy: 10.00\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synflow\n",
      "398.1071705534973\n",
      "Layer Collapse if = 0\n",
      "35.456177\n",
      "3381.0 1345800 1342419.5032404745 0.9974881135684904\n",
      "Round   0, Average loss 2.303\n",
      "synflow\n",
      "398.1071705534973\n",
      "Layer Collapse if = 0\n",
      "35.491013\n",
      "3381.0 1345800 1342419.5032404745 0.9974881135684904\n",
      "Round   1, Average loss 2.303\n",
      "synflow\n",
      "398.1071705534973\n",
      "Layer Collapse if = 0\n",
      "35.526688\n",
      "3381.0 1345800 1342419.5032404745 0.9974881135684904\n",
      "Round   2, Average loss 2.303\n",
      "synflow\n",
      "398.1071705534973\n",
      "Layer Collapse if = 0\n",
      "35.563126\n",
      "3381.0 1345800 1342419.5032404745 0.9974881135684904\n",
      "Round   3, Average loss 2.303\n",
      "synflow\n",
      "398.1071705534973\n",
      "Layer Collapse if = 0\n",
      "35.600365\n",
      "3381.0 1345800 1342419.5032404745 0.9974881135684904\n",
      "Round   4, Average loss 2.303\n",
      "synflow\n",
      "398.1071705534973\n",
      "Layer Collapse if = 0\n",
      "35.638382\n",
      "3381.0 1345800 1342419.5032404745 0.9974881135684904\n",
      "Round   5, Average loss 2.303\n",
      "synflow\n",
      "398.1071705534973\n",
      "Layer Collapse if = 0\n",
      "35.676975\n",
      "3381.0 1345800 1342419.5032404745 0.9974881135684904\n",
      "Round   6, Average loss 2.303\n",
      "synflow\n",
      "398.1071705534973\n",
      "Layer Collapse if = 0\n",
      "35.71673\n",
      "3381.0 1345800 1342419.5032404745 0.9974881135684904\n",
      "Round   7, Average loss 2.303\n",
      "synflow\n",
      "398.1071705534973\n",
      "Layer Collapse if = 0\n",
      "35.757507\n",
      "3381.0 1345800 1342419.5032404745 0.9974881135684904\n",
      "Round   8, Average loss 2.303\n",
      "synflow\n",
      "398.1071705534973\n",
      "Layer Collapse if = 0\n",
      "35.79911\n",
      "3381.0 1345800 1342419.5032404745 0.9974881135684904\n",
      "Round   9, Average loss 2.303\n",
      "Training accuracy: 8.76\n",
      "Testing accuracy: 8.78\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "fedspa\n",
      "2133.0 1345800 1343667.050741586 0.9984151068075389\n",
      "Round   0, Average loss 2.303\n",
      "fedspa\n",
      "2133.0 1345800 1343667.050741586 0.9984151068075389\n",
      "Round   1, Average loss 2.303\n",
      "fedspa\n",
      "2133.0 1345800 1343667.050741586 0.9984151068075389\n",
      "Round   2, Average loss 2.303\n",
      "fedspa\n",
      "2133.0 1345800 1343667.050741586 0.9984151068075389\n",
      "Round   3, Average loss 2.303\n",
      "fedspa\n",
      "2133.0 1345800 1343667.050741586 0.9984151068075389\n",
      "Round   4, Average loss 2.303\n",
      "fedspa\n",
      "2133.0 1345800 1343667.050741586 0.9984151068075389\n",
      "Round   5, Average loss 2.303\n",
      "fedspa\n",
      "2133.0 1345800 1343667.050741586 0.9984151068075389\n",
      "Round   6, Average loss 2.303\n",
      "fedspa\n",
      "2133.0 1345800 1343667.050741586 0.9984151068075389\n",
      "Round   7, Average loss 2.303\n",
      "fedspa\n",
      "2133.0 1345800 1343667.050741586 0.9984151068075389\n",
      "Round   8, Average loss 2.303\n",
      "fedspa\n",
      "2133.0 1345800 1343667.050741586 0.9984151068075389\n",
      "Round   9, Average loss 2.303\n",
      "Training accuracy: 10.00\n",
      "Testing accuracy: 10.00\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "mag\n",
      "630.957344480193\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "2133.0 1345800 1343667.050741586 0.9984151068075389\n",
      "Round   0, Average loss 2.303\n",
      "mag\n",
      "630.957344480193\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "2133.0 1345800 1343667.050741586 0.9984151068075389\n",
      "Round   1, Average loss 2.303\n",
      "mag\n",
      "630.957344480193\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "2133.0 1345800 1343667.050741586 0.9984151068075389\n",
      "Round   2, Average loss 2.303\n",
      "mag\n",
      "630.957344480193\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "2133.0 1345800 1343667.050741586 0.9984151068075389\n",
      "Round   3, Average loss 2.303\n",
      "mag\n",
      "630.957344480193\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "2133.0 1345800 1343667.050741586 0.9984151068075389\n",
      "Round   4, Average loss 2.303\n",
      "mag\n",
      "630.957344480193\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "2133.0 1345800 1343667.050741586 0.9984151068075389\n",
      "Round   5, Average loss 2.303\n",
      "mag\n",
      "630.957344480193\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "2133.0 1345800 1343667.050741586 0.9984151068075389\n",
      "Round   6, Average loss 2.303\n",
      "mag\n",
      "630.957344480193\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "2133.0 1345800 1343667.050741586 0.9984151068075389\n",
      "Round   7, Average loss 2.303\n",
      "mag\n",
      "630.957344480193\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "2133.0 1345800 1343667.050741586 0.9984151068075389\n",
      "Round   8, Average loss 2.303\n",
      "mag\n",
      "630.957344480193\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "2133.0 1345800 1343667.050741586 0.9984151068075389\n",
      "Round   9, Average loss 2.303\n",
      "Training accuracy: 10.00\n",
      "Testing accuracy: 10.00\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "synflow\n",
      "630.957344480193\n",
      "Layer Collapse if = 0\n",
      "10.036935\n",
      "2133.0 1345800 1343667.050741586 0.9984151068075389\n",
      "Round   0, Average loss 2.303\n",
      "synflow\n",
      "630.957344480193\n",
      "Layer Collapse if = 0\n",
      "10.04341\n",
      "2133.0 1345800 1343667.050741586 0.9984151068075389\n",
      "Round   1, Average loss 2.303\n",
      "synflow\n",
      "630.957344480193\n",
      "Layer Collapse if = 0\n",
      "10.050042\n",
      "2133.0 1345800 1343667.050741586 0.9984151068075389\n",
      "Round   2, Average loss 2.303\n",
      "synflow\n",
      "630.957344480193\n",
      "Layer Collapse if = 0\n",
      "10.056843\n",
      "2133.0 1345800 1343667.050741586 0.9984151068075389\n",
      "Round   3, Average loss 2.303\n",
      "synflow\n",
      "630.957344480193\n",
      "Layer Collapse if = 0\n",
      "10.063803\n",
      "2133.0 1345800 1343667.050741586 0.9984151068075389\n",
      "Round   4, Average loss 2.303\n",
      "synflow\n",
      "630.957344480193\n",
      "Layer Collapse if = 0\n",
      "10.070923\n",
      "2133.0 1345800 1343667.050741586 0.9984151068075389\n",
      "Round   5, Average loss 2.303\n",
      "synflow\n",
      "630.957344480193\n",
      "Layer Collapse if = 0\n",
      "10.078223\n",
      "2133.0 1345800 1343667.050741586 0.9984151068075389\n",
      "Round   6, Average loss 2.303\n",
      "synflow\n",
      "630.957344480193\n",
      "Layer Collapse if = 0\n",
      "10.085738\n",
      "2133.0 1345800 1343667.050741586 0.9984151068075389\n",
      "Round   7, Average loss 2.303\n",
      "synflow\n",
      "630.957344480193\n",
      "Layer Collapse if = 0\n",
      "10.0934925\n",
      "2133.0 1345800 1343667.050741586 0.9984151068075389\n",
      "Round   8, Average loss 2.303\n",
      "synflow\n",
      "630.957344480193\n",
      "Layer Collapse if = 0\n",
      "10.101497\n",
      "2133.0 1345800 1343667.050741586 0.9984151068075389\n",
      "Round   9, Average loss 2.303\n",
      "Training accuracy: 12.06\n",
      "Testing accuracy: 12.07\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "fedspa\n",
      "1346.0 1345800 1344454.2 0.999\n",
      "Round   0, Average loss 2.303\n",
      "fedspa\n",
      "1346.0 1345800 1344454.2 0.999\n",
      "Round   1, Average loss 2.303\n",
      "fedspa\n",
      "1346.0 1345800 1344454.2 0.999\n",
      "Round   2, Average loss 2.303\n",
      "fedspa\n",
      "1346.0 1345800 1344454.2 0.999\n",
      "Round   3, Average loss 2.303\n",
      "fedspa\n",
      "1346.0 1345800 1344454.2 0.999\n",
      "Round   4, Average loss 2.303\n",
      "fedspa\n",
      "1346.0 1345800 1344454.2 0.999\n",
      "Round   5, Average loss 2.303\n",
      "fedspa\n",
      "1346.0 1345800 1344454.2 0.999\n",
      "Round   6, Average loss 2.303\n",
      "fedspa\n",
      "1346.0 1345800 1344454.2 0.999\n",
      "Round   7, Average loss 2.303\n",
      "fedspa\n",
      "1346.0 1345800 1344454.2 0.999\n",
      "Round   8, Average loss 2.303\n",
      "fedspa\n",
      "1346.0 1345800 1344454.2 0.999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round   9, Average loss 2.303\n",
      "Training accuracy: 10.00\n",
      "Testing accuracy: 10.00\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "mag\n",
      "1000.0\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "1346.0 1345800 1344454.2 0.999\n",
      "Round   0, Average loss 2.303\n",
      "mag\n",
      "1000.0\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "1346.0 1345800 1344454.2 0.999\n",
      "Round   1, Average loss 2.303\n",
      "mag\n",
      "1000.0\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "1346.0 1345800 1344454.2 0.999\n",
      "Round   2, Average loss 2.303\n",
      "mag\n",
      "1000.0\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "1346.0 1345800 1344454.2 0.999\n",
      "Round   3, Average loss 2.303\n",
      "mag\n",
      "1000.0\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "1346.0 1345800 1344454.2 0.999\n",
      "Round   4, Average loss 2.303\n",
      "mag\n",
      "1000.0\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "1346.0 1345800 1344454.2 0.999\n",
      "Round   5, Average loss 2.303\n",
      "mag\n",
      "1000.0\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "1346.0 1345800 1344454.2 0.999\n",
      "Round   6, Average loss 2.303\n",
      "mag\n",
      "1000.0\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "1346.0 1345800 1344454.2 0.999\n",
      "Round   7, Average loss 2.303\n",
      "mag\n",
      "1000.0\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "1346.0 1345800 1344454.2 0.999\n",
      "Round   8, Average loss 2.303\n",
      "mag\n",
      "1000.0\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "1346.0 1345800 1344454.2 0.999\n",
      "Round   9, Average loss 2.303\n",
      "Training accuracy: 10.00\n",
      "Testing accuracy: 10.00\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "synflow\n",
      "1000.0\n",
      "Layer Collapse if = 0\n",
      "2.8712418\n",
      "1346.0 1345800 1344454.2 0.999\n",
      "Round   0, Average loss 2.303\n",
      "synflow\n",
      "1000.0\n",
      "Layer Collapse if = 0\n",
      "2.8714437\n",
      "1346.0 1345800 1344454.2 0.999\n",
      "Round   1, Average loss 2.303\n",
      "synflow\n",
      "1000.0\n",
      "Layer Collapse if = 0\n",
      "2.8716536\n",
      "1346.0 1345800 1344454.2 0.999\n",
      "Round   2, Average loss 2.303\n",
      "synflow\n",
      "1000.0\n",
      "Layer Collapse if = 0\n",
      "2.87187\n",
      "1346.0 1345800 1344454.2 0.999\n",
      "Round   3, Average loss 2.303\n",
      "synflow\n",
      "1000.0\n",
      "Layer Collapse if = 0\n",
      "2.8721018\n",
      "1346.0 1345800 1344454.2 0.999\n",
      "Round   4, Average loss 2.303\n",
      "synflow\n",
      "1000.0\n",
      "Layer Collapse if = 0\n",
      "2.872346\n",
      "1346.0 1345800 1344454.2 0.999\n",
      "Round   5, Average loss 2.303\n",
      "synflow\n",
      "1000.0\n",
      "Layer Collapse if = 0\n",
      "2.8725977\n",
      "1346.0 1345800 1344454.2 0.999\n",
      "Round   6, Average loss 2.303\n",
      "synflow\n",
      "1000.0\n",
      "Layer Collapse if = 0\n",
      "2.8728564\n",
      "1346.0 1345800 1344454.2 0.999\n",
      "Round   7, Average loss 2.303\n",
      "synflow\n",
      "1000.0\n",
      "Layer Collapse if = 0\n",
      "2.8731203\n",
      "1346.0 1345800 1344454.2 0.999\n",
      "Round   8, Average loss 2.303\n",
      "synflow\n",
      "1000.0\n",
      "Layer Collapse if = 0\n",
      "2.8733912\n",
      "1346.0 1345800 1344454.2 0.999\n",
      "Round   9, Average loss 2.303\n",
      "Training accuracy: 11.85\n",
      "Testing accuracy: 11.72\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "fedspa\n",
      "850.0 1345800 1344950.8576057986 0.9993690426555198\n",
      "Round   0, Average loss 2.303\n",
      "fedspa\n",
      "850.0 1345800 1344950.8576057986 0.9993690426555198\n",
      "Round   1, Average loss 2.303\n",
      "fedspa\n",
      "850.0 1345800 1344950.8576057986 0.9993690426555198\n",
      "Round   2, Average loss 2.303\n",
      "fedspa\n",
      "850.0 1345800 1344950.8576057986 0.9993690426555198\n",
      "Round   3, Average loss 2.303\n",
      "fedspa\n",
      "850.0 1345800 1344950.8576057986 0.9993690426555198\n",
      "Round   4, Average loss 2.303\n",
      "fedspa\n",
      "850.0 1345800 1344950.8576057986 0.9993690426555198\n",
      "Round   5, Average loss 2.303\n",
      "fedspa\n",
      "850.0 1345800 1344950.8576057986 0.9993690426555198\n",
      "Round   6, Average loss 2.303\n",
      "fedspa\n",
      "850.0 1345800 1344950.8576057986 0.9993690426555198\n",
      "Round   7, Average loss 2.303\n",
      "fedspa\n",
      "850.0 1345800 1344950.8576057986 0.9993690426555198\n",
      "Round   8, Average loss 2.303\n",
      "fedspa\n",
      "850.0 1345800 1344950.8576057986 0.9993690426555198\n",
      "Round   9, Average loss 2.303\n",
      "Training accuracy: 10.00\n",
      "Testing accuracy: 10.00\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "mag\n",
      "1584.893192461114\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "850.0 1345800 1344950.8576057986 0.9993690426555198\n",
      "Round   0, Average loss 2.303\n",
      "mag\n",
      "1584.893192461114\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "850.0 1345800 1344950.8576057986 0.9993690426555198\n",
      "Round   1, Average loss 2.303\n",
      "mag\n",
      "1584.893192461114\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "850.0 1345800 1344950.8576057986 0.9993690426555198\n",
      "Round   2, Average loss 2.303\n",
      "mag\n",
      "1584.893192461114\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "850.0 1345800 1344950.8576057986 0.9993690426555198\n",
      "Round   3, Average loss 2.303\n",
      "mag\n",
      "1584.893192461114\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "850.0 1345800 1344950.8576057986 0.9993690426555198\n",
      "Round   4, Average loss 2.303\n",
      "mag\n",
      "1584.893192461114\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "850.0 1345800 1344950.8576057986 0.9993690426555198\n",
      "Round   5, Average loss 2.303\n",
      "mag\n",
      "1584.893192461114\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "850.0 1345800 1344950.8576057986 0.9993690426555198\n",
      "Round   6, Average loss 2.303\n",
      "mag\n",
      "1584.893192461114\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "850.0 1345800 1344950.8576057986 0.9993690426555198\n",
      "Round   7, Average loss 2.303\n",
      "mag\n",
      "1584.893192461114\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "850.0 1345800 1344950.8576057986 0.9993690426555198\n",
      "Round   8, Average loss 2.303\n",
      "mag\n",
      "1584.893192461114\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "850.0 1345800 1344950.8576057986 0.9993690426555198\n",
      "Round   9, Average loss 2.303\n",
      "Training accuracy: 10.00\n",
      "Testing accuracy: 10.00\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "synflow\n",
      "1584.893192461114\n",
      "Layer Collapse if = 0\n",
      "0.74633723\n",
      "850.0 1345800 1344950.8576057986 0.9993690426555198\n",
      "Round   0, Average loss 2.303\n",
      "synflow\n",
      "1584.893192461114\n",
      "Layer Collapse if = 0\n",
      "0.7464272\n",
      "850.0 1345800 1344950.8576057986 0.9993690426555198\n",
      "Round   1, Average loss 2.303\n",
      "synflow\n",
      "1584.893192461114\n",
      "Layer Collapse if = 0\n",
      "0.74651855\n",
      "850.0 1345800 1344950.8576057986 0.9993690426555198\n",
      "Round   2, Average loss 2.303\n",
      "synflow\n",
      "1584.893192461114\n",
      "Layer Collapse if = 0\n",
      "0.7466111\n",
      "850.0 1345800 1344950.8576057986 0.9993690426555198\n",
      "Round   3, Average loss 2.303\n",
      "synflow\n",
      "1584.893192461114\n",
      "Layer Collapse if = 0\n",
      "0.7467052\n",
      "850.0 1345800 1344950.8576057986 0.9993690426555198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round   4, Average loss 2.303\n",
      "synflow\n",
      "1584.893192461114\n",
      "Layer Collapse if = 0\n",
      "0.74680066\n",
      "850.0 1345800 1344950.8576057986 0.9993690426555198\n",
      "Round   5, Average loss 2.303\n",
      "synflow\n",
      "1584.893192461114\n",
      "Layer Collapse if = 0\n",
      "0.74689764\n",
      "850.0 1345800 1344950.8576057986 0.9993690426555198\n",
      "Round   6, Average loss 2.303\n",
      "synflow\n",
      "1584.893192461114\n",
      "Layer Collapse if = 0\n",
      "0.74699605\n",
      "850.0 1345800 1344950.8576057986 0.9993690426555198\n",
      "Round   7, Average loss 2.303\n",
      "synflow\n",
      "1584.893192461114\n",
      "Layer Collapse if = 0\n",
      "0.74709594\n",
      "850.0 1345800 1344950.8576057986 0.9993690426555198\n",
      "Round   8, Average loss 2.303\n",
      "synflow\n",
      "1584.893192461114\n",
      "Layer Collapse if = 0\n",
      "0.7471974\n",
      "850.0 1345800 1344950.8576057986 0.9993690426555198\n",
      "Round   9, Average loss 2.303\n",
      "Training accuracy: 12.89\n",
      "Testing accuracy: 12.77\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "fedspa\n",
      "536.0 1345800 1345264.2273698691 0.9996018928294464\n",
      "Round   0, Average loss 2.303\n",
      "fedspa\n",
      "536.0 1345800 1345264.2273698691 0.9996018928294464\n",
      "Round   1, Average loss 2.303\n",
      "fedspa\n",
      "536.0 1345800 1345264.2273698691 0.9996018928294464\n",
      "Round   2, Average loss 2.303\n",
      "fedspa\n",
      "536.0 1345800 1345264.2273698691 0.9996018928294464\n",
      "Round   3, Average loss 2.303\n",
      "fedspa\n",
      "536.0 1345800 1345264.2273698691 0.9996018928294464\n",
      "Round   4, Average loss 2.303\n",
      "fedspa\n",
      "536.0 1345800 1345264.2273698691 0.9996018928294464\n",
      "Round   5, Average loss 2.303\n",
      "fedspa\n",
      "536.0 1345800 1345264.2273698691 0.9996018928294464\n",
      "Round   6, Average loss 2.303\n",
      "fedspa\n",
      "536.0 1345800 1345264.2273698691 0.9996018928294464\n",
      "Round   7, Average loss 2.303\n",
      "fedspa\n",
      "536.0 1345800 1345264.2273698691 0.9996018928294464\n",
      "Round   8, Average loss 2.303\n",
      "fedspa\n",
      "536.0 1345800 1345264.2273698691 0.9996018928294464\n",
      "Round   9, Average loss 2.303\n",
      "Training accuracy: 10.00\n",
      "Testing accuracy: 10.00\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "mag\n",
      "2511.88643150958\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "536.0 1345800 1345264.2273698691 0.9996018928294464\n",
      "Round   0, Average loss 2.303\n",
      "mag\n",
      "2511.88643150958\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "536.0 1345800 1345264.2273698691 0.9996018928294464\n",
      "Round   1, Average loss 2.303\n",
      "mag\n",
      "2511.88643150958\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "536.0 1345800 1345264.2273698691 0.9996018928294464\n",
      "Round   2, Average loss 2.303\n",
      "mag\n",
      "2511.88643150958\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "536.0 1345800 1345264.2273698691 0.9996018928294464\n",
      "Round   3, Average loss 2.303\n",
      "mag\n",
      "2511.88643150958\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "536.0 1345800 1345264.2273698691 0.9996018928294464\n",
      "Round   4, Average loss 2.303\n",
      "mag\n",
      "2511.88643150958\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "536.0 1345800 1345264.2273698691 0.9996018928294464\n",
      "Round   5, Average loss 2.303\n",
      "mag\n",
      "2511.88643150958\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "536.0 1345800 1345264.2273698691 0.9996018928294464\n",
      "Round   6, Average loss 2.303\n",
      "mag\n",
      "2511.88643150958\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "536.0 1345800 1345264.2273698691 0.9996018928294464\n",
      "Round   7, Average loss 2.303\n",
      "mag\n",
      "2511.88643150958\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "536.0 1345800 1345264.2273698691 0.9996018928294464\n",
      "Round   8, Average loss 2.303\n",
      "mag\n",
      "2511.88643150958\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "536.0 1345800 1345264.2273698691 0.9996018928294464\n",
      "Round   9, Average loss 2.303\n",
      "Training accuracy: 10.00\n",
      "Testing accuracy: 10.00\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "synflow\n",
      "2511.88643150958\n",
      "Layer Collapse if = 0\n",
      "0.18991335\n",
      "536.0 1345800 1345264.2273698691 0.9996018928294464\n",
      "Round   0, Average loss 2.303\n",
      "synflow\n",
      "2511.88643150958\n",
      "Layer Collapse if = 0\n",
      "0.18992634\n",
      "536.0 1345800 1345264.2273698691 0.9996018928294464\n",
      "Round   1, Average loss 2.303\n",
      "synflow\n",
      "2511.88643150958\n",
      "Layer Collapse if = 0\n",
      "0.18993944\n",
      "536.0 1345800 1345264.2273698691 0.9996018928294464\n",
      "Round   2, Average loss 2.303\n",
      "synflow\n",
      "2511.88643150958\n",
      "Layer Collapse if = 0\n",
      "0.18995267\n",
      "536.0 1345800 1345264.2273698691 0.9996018928294464\n",
      "Round   3, Average loss 2.303\n",
      "synflow\n",
      "2511.88643150958\n",
      "Layer Collapse if = 0\n",
      "0.18996596\n",
      "536.0 1345800 1345264.2273698691 0.9996018928294464\n",
      "Round   4, Average loss 2.303\n",
      "synflow\n",
      "2511.88643150958\n",
      "Layer Collapse if = 0\n",
      "0.18997937\n",
      "536.0 1345800 1345264.2273698691 0.9996018928294464\n",
      "Round   5, Average loss 2.303\n",
      "synflow\n",
      "2511.88643150958\n",
      "Layer Collapse if = 0\n",
      "0.18999292\n",
      "536.0 1345800 1345264.2273698691 0.9996018928294464\n",
      "Round   6, Average loss 2.303\n",
      "synflow\n",
      "2511.88643150958\n",
      "Layer Collapse if = 0\n",
      "0.19000666\n",
      "536.0 1345800 1345264.2273698691 0.9996018928294464\n",
      "Round   7, Average loss 2.303\n",
      "synflow\n",
      "2511.88643150958\n",
      "Layer Collapse if = 0\n",
      "0.19002043\n",
      "536.0 1345800 1345264.2273698691 0.9996018928294464\n",
      "Round   8, Average loss 2.303\n",
      "synflow\n",
      "2511.88643150958\n",
      "Layer Collapse if = 0\n",
      "0.19003437\n",
      "536.0 1345800 1345264.2273698691 0.9996018928294464\n",
      "Round   9, Average loss 2.303\n",
      "Training accuracy: 14.14\n",
      "Testing accuracy: 13.99\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "fedspa\n",
      "339.0 1345800 1345461.9503240474 0.999748811356849\n",
      "Round   0, Average loss 2.303\n",
      "fedspa\n",
      "339.0 1345800 1345461.9503240474 0.999748811356849\n",
      "Round   1, Average loss 2.303\n",
      "fedspa\n",
      "339.0 1345800 1345461.9503240474 0.999748811356849\n",
      "Round   2, Average loss 2.303\n",
      "fedspa\n",
      "339.0 1345800 1345461.9503240474 0.999748811356849\n",
      "Round   3, Average loss 2.303\n",
      "fedspa\n",
      "339.0 1345800 1345461.9503240474 0.999748811356849\n",
      "Round   4, Average loss 2.303\n",
      "fedspa\n",
      "339.0 1345800 1345461.9503240474 0.999748811356849\n",
      "Round   5, Average loss 2.303\n",
      "fedspa\n",
      "339.0 1345800 1345461.9503240474 0.999748811356849\n",
      "Round   6, Average loss 2.303\n",
      "fedspa\n",
      "339.0 1345800 1345461.9503240474 0.999748811356849\n",
      "Round   7, Average loss 2.303\n",
      "fedspa\n",
      "339.0 1345800 1345461.9503240474 0.999748811356849\n",
      "Round   8, Average loss 2.303\n",
      "fedspa\n",
      "339.0 1345800 1345461.9503240474 0.999748811356849\n",
      "Round   9, Average loss 2.303\n",
      "Training accuracy: 10.00\n",
      "Testing accuracy: 10.00\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mag\n",
      "3981.0717055349733\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "339.0 1345800 1345461.9503240474 0.999748811356849\n",
      "Round   0, Average loss 2.303\n",
      "mag\n",
      "3981.0717055349733\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "339.0 1345800 1345461.9503240474 0.999748811356849\n",
      "Round   1, Average loss 2.303\n",
      "mag\n",
      "3981.0717055349733\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "339.0 1345800 1345461.9503240474 0.999748811356849\n",
      "Round   2, Average loss 2.303\n",
      "mag\n",
      "3981.0717055349733\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "339.0 1345800 1345461.9503240474 0.999748811356849\n",
      "Round   3, Average loss 2.303\n",
      "mag\n",
      "3981.0717055349733\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "339.0 1345800 1345461.9503240474 0.999748811356849\n",
      "Round   4, Average loss 2.303\n",
      "mag\n",
      "3981.0717055349733\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "339.0 1345800 1345461.9503240474 0.999748811356849\n",
      "Round   5, Average loss 2.303\n",
      "mag\n",
      "3981.0717055349733\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "339.0 1345800 1345461.9503240474 0.999748811356849\n",
      "Round   6, Average loss 2.303\n",
      "mag\n",
      "3981.0717055349733\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "339.0 1345800 1345461.9503240474 0.999748811356849\n",
      "Round   7, Average loss 2.303\n",
      "mag\n",
      "3981.0717055349733\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "339.0 1345800 1345461.9503240474 0.999748811356849\n",
      "Round   8, Average loss 2.303\n",
      "mag\n",
      "3981.0717055349733\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "339.0 1345800 1345461.9503240474 0.999748811356849\n",
      "Round   9, Average loss 2.303\n",
      "Training accuracy: 10.00\n",
      "Testing accuracy: 10.00\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "synflow\n",
      "3981.0717055349733\n",
      "Layer Collapse if = 0\n",
      "0.043803003\n",
      "339.0 1345800 1345461.9503240474 0.999748811356849\n",
      "Round   0, Average loss 2.303\n",
      "synflow\n",
      "3981.0717055349733\n",
      "Layer Collapse if = 0\n",
      "0.04380586\n",
      "339.0 1345800 1345461.9503240474 0.999748811356849\n",
      "Round   1, Average loss 2.303\n",
      "synflow\n",
      "3981.0717055349733\n",
      "Layer Collapse if = 0\n",
      "0.04380874\n",
      "339.0 1345800 1345461.9503240474 0.999748811356849\n",
      "Round   2, Average loss 2.303\n",
      "synflow\n",
      "3981.0717055349733\n",
      "Layer Collapse if = 0\n",
      "0.043811645\n",
      "339.0 1345800 1345461.9503240474 0.999748811356849\n",
      "Round   3, Average loss 2.303\n",
      "synflow\n",
      "3981.0717055349733\n",
      "Layer Collapse if = 0\n",
      "0.043814592\n",
      "339.0 1345800 1345461.9503240474 0.999748811356849\n",
      "Round   4, Average loss 2.303\n",
      "synflow\n",
      "3981.0717055349733\n",
      "Layer Collapse if = 0\n",
      "0.04381755\n",
      "339.0 1345800 1345461.9503240474 0.999748811356849\n",
      "Round   5, Average loss 2.303\n",
      "synflow\n",
      "3981.0717055349733\n",
      "Layer Collapse if = 0\n",
      "0.043820545\n",
      "339.0 1345800 1345461.9503240474 0.999748811356849\n",
      "Round   6, Average loss 2.303\n",
      "synflow\n",
      "3981.0717055349733\n",
      "Layer Collapse if = 0\n",
      "0.04382355\n",
      "339.0 1345800 1345461.9503240474 0.999748811356849\n",
      "Round   7, Average loss 2.303\n",
      "synflow\n",
      "3981.0717055349733\n",
      "Layer Collapse if = 0\n",
      "0.043826547\n",
      "339.0 1345800 1345461.9503240474 0.999748811356849\n",
      "Round   8, Average loss 2.303\n",
      "synflow\n",
      "3981.0717055349733\n",
      "Layer Collapse if = 0\n",
      "0.04382957\n",
      "339.0 1345800 1345461.9503240474 0.999748811356849\n",
      "Round   9, Average loss 2.303\n",
      "Training accuracy: 15.08\n",
      "Testing accuracy: 15.31\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "fedspa\n",
      "214.0 1345800 1345586.7050741585 0.9998415106807539\n",
      "Round   0, Average loss 2.303\n",
      "fedspa\n",
      "214.0 1345800 1345586.7050741585 0.9998415106807539\n",
      "Round   1, Average loss 2.303\n",
      "fedspa\n",
      "214.0 1345800 1345586.7050741585 0.9998415106807539\n",
      "Round   2, Average loss 2.303\n",
      "fedspa\n",
      "214.0 1345800 1345586.7050741585 0.9998415106807539\n",
      "Round   3, Average loss 2.303\n",
      "fedspa\n",
      "214.0 1345800 1345586.7050741585 0.9998415106807539\n",
      "Round   4, Average loss 2.303\n",
      "fedspa\n",
      "214.0 1345800 1345586.7050741585 0.9998415106807539\n",
      "Round   5, Average loss 2.303\n",
      "fedspa\n",
      "214.0 1345800 1345586.7050741585 0.9998415106807539\n",
      "Round   6, Average loss 2.303\n",
      "fedspa\n",
      "214.0 1345800 1345586.7050741585 0.9998415106807539\n",
      "Round   7, Average loss 2.303\n",
      "fedspa\n",
      "214.0 1345800 1345586.7050741585 0.9998415106807539\n",
      "Round   8, Average loss 2.303\n",
      "fedspa\n",
      "214.0 1345800 1345586.7050741585 0.9998415106807539\n",
      "Round   9, Average loss 2.303\n",
      "Training accuracy: 10.00\n",
      "Testing accuracy: 10.00\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "mag\n",
      "6309.57344480193\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "214.0 1345800 1345586.7050741585 0.9998415106807539\n",
      "Round   0, Average loss 2.303\n",
      "mag\n",
      "6309.57344480193\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "214.0 1345800 1345586.7050741585 0.9998415106807539\n",
      "Round   1, Average loss 2.303\n",
      "mag\n",
      "6309.57344480193\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "214.0 1345800 1345586.7050741585 0.9998415106807539\n",
      "Round   2, Average loss 2.303\n",
      "mag\n",
      "6309.57344480193\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "214.0 1345800 1345586.7050741585 0.9998415106807539\n",
      "Round   3, Average loss 2.303\n",
      "mag\n",
      "6309.57344480193\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "214.0 1345800 1345586.7050741585 0.9998415106807539\n",
      "Round   4, Average loss 2.303\n",
      "mag\n",
      "6309.57344480193\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "214.0 1345800 1345586.7050741585 0.9998415106807539\n",
      "Round   5, Average loss 2.303\n",
      "mag\n",
      "6309.57344480193\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "214.0 1345800 1345586.7050741585 0.9998415106807539\n",
      "Round   6, Average loss 2.303\n",
      "mag\n",
      "6309.57344480193\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "214.0 1345800 1345586.7050741585 0.9998415106807539\n",
      "Round   7, Average loss 2.303\n",
      "mag\n",
      "6309.57344480193\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "214.0 1345800 1345586.7050741585 0.9998415106807539\n",
      "Round   8, Average loss 2.303\n",
      "mag\n",
      "6309.57344480193\n",
      "Layer Collapse if = 0\n",
      "0.0\n",
      "214.0 1345800 1345586.7050741585 0.9998415106807539\n",
      "Round   9, Average loss 2.303\n",
      "Training accuracy: 10.00\n",
      "Testing accuracy: 10.00\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=3072, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n",
      "synflow\n",
      "6309.57344480193\n",
      "Layer Collapse if = 0\n",
      "0.011714172\n",
      "214.0 1345800 1345586.7050741585 0.9998415106807539\n",
      "Round   0, Average loss 2.303\n",
      "synflow\n",
      "6309.57344480193\n",
      "Layer Collapse if = 0\n",
      "0.011714215\n",
      "214.0 1345800 1345586.7050741585 0.9998415106807539\n",
      "Round   1, Average loss 2.303\n",
      "synflow\n",
      "6309.57344480193\n",
      "Layer Collapse if = 0\n",
      "0.011714261\n",
      "214.0 1345800 1345586.7050741585 0.9998415106807539\n",
      "Round   2, Average loss 2.303\n",
      "synflow\n",
      "6309.57344480193\n",
      "Layer Collapse if = 0\n",
      "0.011714305\n",
      "214.0 1345800 1345586.7050741585 0.9998415106807539\n",
      "Round   3, Average loss 2.303\n",
      "synflow\n",
      "6309.57344480193\n",
      "Layer Collapse if = 0\n",
      "0.011714352\n",
      "214.0 1345800 1345586.7050741585 0.9998415106807539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round   4, Average loss 2.303\n",
      "synflow\n",
      "6309.57344480193\n",
      "Layer Collapse if = 0\n",
      "0.011714395\n",
      "214.0 1345800 1345586.7050741585 0.9998415106807539\n",
      "Round   5, Average loss 2.303\n",
      "synflow\n",
      "6309.57344480193\n",
      "Layer Collapse if = 0\n",
      "0.011714442\n",
      "214.0 1345800 1345586.7050741585 0.9998415106807539\n",
      "Round   6, Average loss 2.303\n",
      "synflow\n",
      "6309.57344480193\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "%run ../layer-collapse.py --iid --model mlp --dataset cifar --epochs 10 --local_ep 15 --gpu -0 --num_channels 1 --num_users 100 --frac 0.1 --compression 10 --prune_epochs 100 --pruner mag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Testing plots\n",
    "\n",
    "- The code below is for testing plots from the results printed by manually copying them.\n",
    "- To plot the results directly, uncomment the `plt.show()` line\n",
    "- To save the results, uncomment the `plt.savefig()` line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "y = {}\n",
    "iters = 30\n",
    "alphas = [i/5 for i in range(iters)]\n",
    "y['synflow'] = [torch.tensor(97.7400), torch.tensor(97.6300), torch.tensor(97.5300), torch.tensor(97.5300), torch.tensor(97.6400), torch.tensor(97.2400), torch.tensor(96.3500), torch.tensor(95.5000), torch.tensor(94.8100), torch.tensor(93.3100), torch.tensor(89.5500), torch.tensor(71.1400), torch.tensor(42.9200), torch.tensor(10.1600), torch.tensor(11.9300), torch.tensor(9.1900), torch.tensor(14.0700), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000)]\n",
    "y['mag'] = [torch.tensor(97.4500), torch.tensor(97.0300), torch.tensor(97.2700), torch.tensor(97.6600), torch.tensor(97.6800), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000), torch.tensor(9.8000)]\n",
    "x_vals = [10**alpha for alpha in alphas]\n",
    "plt.figure()\n",
    "plt.xscale('log')\n",
    "plt.plot(x_vals, y['synflow'], label='Synflow', linestyle='-', marker='o', color='r')\n",
    "plt.plot(x_vals, y['mag'], label='Mag', linestyle='-', marker='o', color='b')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Y-axis')\n",
    "plt.title('Synflow vs Mag')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Save plot\n",
    "plt.savefig('../save/tesasdt-plot.png'.format())\n",
    "\n",
    "# Show plot\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

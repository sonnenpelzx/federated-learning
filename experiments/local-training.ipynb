{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer Collapse experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add the parent directory to path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Import modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/adamborgula/dev/bachelor_thesis/federated-learning\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "print(nb_dir)\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "    \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "\n",
    "# import os\n",
    "# os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "\n",
    "from utils.sampling import mnist_iid, mnist_noniid, cifar_iid\n",
    "from models.Update import LocalUpdate\n",
    "from models.Nets import MLP, CNNMnist, CNNCifar\n",
    "from models.Fed import FedAvg\n",
    "from models.test import test_img\n",
    "from models import imagenet_vgg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Set Default Args** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args():\n",
    "    # federated arguments\n",
    "    epochs = 1\n",
    "    num_users = 1\n",
    "    frac = 1\n",
    "    local_ep = 5\n",
    "    local_bs = 10\n",
    "    bs = 16\n",
    "    lr = 0.01\n",
    "    momentum = 0.5\n",
    "    split = 'user'\n",
    "\n",
    "    # model arguments\n",
    "    model = 'mlp'\n",
    "    kernel_num = 9\n",
    "    kernel_sizes = [3,4]\n",
    "    norm = 'batch_norm'\n",
    "    num_filters = 32\n",
    "    max_pool = True\n",
    "\n",
    "    # other arguments\n",
    "    dataset = 'mnist'\n",
    "    iid = True # action: store_true\n",
    "    num_classes = 10\n",
    "    num_channels = 3\n",
    "    gpu = 0\n",
    "    stopping_rounds = 10\n",
    "    verbose = False # action: store_true\n",
    "    seed = 1\n",
    "    all_clients = False # action: store_true\n",
    "    compression = 0.0\n",
    "    prune_epochs = 100\n",
    "    pruner = 'mag'\n",
    "    iters = 15\n",
    "\n",
    "    # test customization\n",
    "    save = False\n",
    "    show = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **The Experiment Without Bias** \n",
    "- bias was causing weird pruning behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment_no_bias():\n",
    "    args=Args()\n",
    "    args.local_ep = 2\n",
    "    args.dataset = 'mnist'\n",
    "    args.iters = 10\n",
    "    x_vals, y_vals = [],[]\n",
    "\n",
    "    args.device = torch.device('cuda:{}'.format(args.gpu) if torch.cuda.is_available() and args.gpu != -1 else 'cpu')\n",
    "\n",
    "    alphas = [i/5 for i in range(10, 10+args.iters)]\n",
    "    seeds = [0]\n",
    "    x_vals = [10**alpha for alpha in alphas]\n",
    "    y_vals = {'mag': [], 'synflow': []}\n",
    "\n",
    "    for c in x_vals:\n",
    "        for seed in seeds:\n",
    "            np.random.seed(args.seed)\n",
    "            torch.manual_seed(args.seed)\n",
    "            torch.cuda.manual_seed(args.seed)\n",
    "            torch.backends.cudnn.deterministic = True\n",
    "            for pruner in ('synflow', 'mag'):\n",
    "                args.pruner = pruner\n",
    "                args.compression = c\n",
    "\n",
    "                # load dataset and split users\n",
    "                if args.dataset == 'mnist':\n",
    "                    trans_mnist = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "                    dataset_train = datasets.MNIST('../data/mnist/', train=True, download=True, transform=trans_mnist)\n",
    "                    dataset_test = datasets.MNIST('../data/mnist/', train=False, download=True, transform=trans_mnist)\n",
    "                    # sample users\n",
    "                    if args.iid:\n",
    "                        dict_users = mnist_iid(dataset_train, args.num_users)\n",
    "                    else:\n",
    "                        dict_users = mnist_noniid(dataset_train, args.num_users)\n",
    "                elif args.dataset == 'cifar':\n",
    "                    trans_cifar = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "                    dataset_train = datasets.CIFAR10('../data/cifar', train=True, download=True, transform=trans_cifar)\n",
    "                    dataset_test = datasets.CIFAR10('../data/cifar', train=False, download=True, transform=trans_cifar)\n",
    "                    if args.iid:\n",
    "                        dict_users = cifar_iid(dataset_train, args.num_users)\n",
    "                    else:\n",
    "                        exit('Error: only consider IID setting in CIFAR10')\n",
    "                else:\n",
    "                    exit('Error: unrecognized dataset')\n",
    "                img_size = dataset_train[0][0].shape\n",
    "\n",
    "                # build model\n",
    "                if args.model == 'cnn' and args.dataset == 'cifar':\n",
    "                    net_glob = CNNCifar(args=args).to(args.device)\n",
    "                    #model = models.vgg16(weights = None)\n",
    "\n",
    "                    # Step 4: Modify last layer\n",
    "                    #num_classes = 10  # CIFAR-10 has 10 classes\n",
    "                    #model.classifier[-1] = nn.Linear(in_features=4096, out_features=num_classes)\n",
    "                    #net_glob = model.to(args.device)\n",
    "                elif args.model == 'cnn' and args.dataset == 'mnist':\n",
    "                    net_glob = CNNMnist(args=args).to(args.device)\n",
    "                elif args.model == 'mlp':\n",
    "                    len_in = 1\n",
    "                    for x in img_size:\n",
    "                        len_in *= x\n",
    "                    net_glob = MLP(dim_in=len_in, dim_hidden=200, dim_out=args.num_classes).to(args.device)\n",
    "                else:\n",
    "                    exit('Error: unrecognized model')\n",
    "                print(net_glob)\n",
    "                net_glob.train()\n",
    "\n",
    "                # copy weights\n",
    "                w_glob = net_glob.state_dict()\n",
    "\n",
    "                # training\n",
    "                loss_train = []\n",
    "                cv_loss, cv_acc = [], []\n",
    "                val_loss_pre, counter = 0, 0\n",
    "                net_best = None\n",
    "                best_loss = None\n",
    "                val_acc_list, net_list = [], []\n",
    "\n",
    "                if args.all_clients: \n",
    "                    print(\"Aggregation over all clients\")\n",
    "                    w_locals = [w_glob for i in range(args.num_users)]\n",
    "                for iter in range(args.epochs):\n",
    "                    loss_locals = []\n",
    "                    if not args.all_clients:\n",
    "                        w_locals = []\n",
    "                    m = max(int(args.frac * args.num_users), 1)\n",
    "                    idxs_users = [0]\n",
    "                    for idx in idxs_users:\n",
    "                        local = LocalUpdate(args=args, dataset=dataset_train, idxs=dict_users[idx])\n",
    "                        w, loss = local.train(net=copy.deepcopy(net_glob).to(args.device))\n",
    "                        if args.all_clients:\n",
    "                            w_locals[idx] = copy.deepcopy(w)\n",
    "                        else:\n",
    "                            w_locals.append(copy.deepcopy(w))\n",
    "                        loss_locals.append(copy.deepcopy(loss))\n",
    "                    # update global weights\n",
    "                    w_glob = FedAvg(w_locals)\n",
    "\n",
    "                    # copy weight to net_glob\n",
    "                    net_glob.load_state_dict(w_glob)\n",
    "\n",
    "                    # print loss\n",
    "                    loss_avg = sum(loss_locals) / len(loss_locals)\n",
    "                    print('Round {:3d}, Average loss {:.3f}'.format(iter, loss_avg))\n",
    "                    loss_train.append(loss_avg)\n",
    "\n",
    "                # plot loss curve\n",
    "                # plt.figure()\n",
    "                # plt.plot(range(len(loss_train)), loss_train)\n",
    "                # plt.ylabel('train_loss')\n",
    "                #   plt.savefig('./save/fed_{}_{}_{}_C{}_iid{}.png'.format(args.dataset, args.model, args.epochs, args.frac, args.iid))\n",
    "\n",
    "                # testing\n",
    "                net_glob.eval()\n",
    "                acc_train, loss_train = test_img(net_glob, dataset_train, args)\n",
    "                acc_test, loss_test = test_img(net_glob, dataset_test, args)\n",
    "                print(\"Training accuracy: {:.2f}\".format(acc_train))\n",
    "                print(\"Testing accuracy: {:.2f}\".format(acc_test))\n",
    "\n",
    "                y_vals[args.pruner].append(acc_test)\n",
    "                #y_vals[args.pruner].append(0)\n",
    "\n",
    "    print('synflow test accuracy: ', y_vals['synflow'])\n",
    "    print('mag test accuracy: ', y_vals['mag'])\n",
    "    # Plot both charts on the same axis\n",
    "    plt.figure()\n",
    "    plt.xscale('log')\n",
    "    plt.plot(x_vals, y_vals['synflow'], label='Synflow', linestyle='-', marker='o', color='r')\n",
    "    plt.plot(x_vals, y_vals['mag'], label='Mag', linestyle='-', marker='o', color='b')\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('X-axis')\n",
    "    plt.ylabel('Y-axis')\n",
    "    plt.title('Synflow vs Mag')\n",
    "\n",
    "    # Add legend\n",
    "    plt.legend()\n",
    "\n",
    "   # Show plot\n",
    "    if args.show:\n",
    "        plt.show()\n",
    "\n",
    "    # Save plot\n",
    "    if args.save:\n",
    "        plt.savefig('../save/synflow_test_{}_{}_{}.png'.format(args.prune_epochs, args.dataset, args.model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=400, bias=False)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=400, out_features=200, bias=False)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=200, out_features=50, bias=False)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=50, out_features=100, bias=False)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=100, out_features=200, bias=False)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "LocalUpdate.train() missing 1 required positional argument: 'mask'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m run_experiment_no_bias()\n",
      "Cell \u001b[0;32mIn[7], line 90\u001b[0m, in \u001b[0;36mrun_experiment_no_bias\u001b[0;34m()\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m idxs_users:\n\u001b[1;32m     89\u001b[0m     local \u001b[38;5;241m=\u001b[39m LocalUpdate(args\u001b[38;5;241m=\u001b[39margs, dataset\u001b[38;5;241m=\u001b[39mdataset_train, idxs\u001b[38;5;241m=\u001b[39mdict_users[idx])\n\u001b[0;32m---> 90\u001b[0m     w, loss \u001b[38;5;241m=\u001b[39m local\u001b[38;5;241m.\u001b[39mtrain(net\u001b[38;5;241m=\u001b[39mcopy\u001b[38;5;241m.\u001b[39mdeepcopy(net_glob)\u001b[38;5;241m.\u001b[39mto(args\u001b[38;5;241m.\u001b[39mdevice))\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mall_clients:\n\u001b[1;32m     92\u001b[0m         w_locals[idx] \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(w)\n",
      "\u001b[0;31mTypeError\u001b[0m: LocalUpdate.train() missing 1 required positional argument: 'mask'"
     ]
    }
   ],
   "source": [
    "run_experiment_no_bias()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **The Original Experiment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment():\n",
    "    args=Args()\n",
    "    x_vals, y_vals = [],[]\n",
    "\n",
    "    args.device = torch.device('cuda:{}'.format(args.gpu) if torch.cuda.is_available() and args.gpu != -1 else 'cpu')\n",
    "\n",
    "    # matplotlib.use('qtagg')\n",
    "\n",
    "    compression = 1\n",
    "    alphas = [i/4 for i in range(args.iters)]\n",
    "    # seeds = [0,99,345]\n",
    "    seeds = [0]\n",
    "    x_vals = [10**alpha for alpha in alphas]\n",
    "    y_vals = {'mag': [], 'synflow': []}\n",
    "\n",
    "    for i in range(args.iters):\n",
    "        for seed in seeds:\n",
    "            np.random.seed(args.seed)\n",
    "            torch.manual_seed(args.seed)\n",
    "            torch.cuda.manual_seed(args.seed)\n",
    "            torch.backends.cudnn.deterministic = True\n",
    "            for pruner in ('synflow', 'mag'):\n",
    "                args.pruner = pruner\n",
    "                args.compression = 10**alphas[i]\n",
    "\n",
    "                # load dataset and split users\n",
    "                if args.dataset == 'mnist':\n",
    "                    trans_mnist = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "                    dataset_train = datasets.MNIST('../data/mnist/', train=True, download=True, transform=trans_mnist)\n",
    "                    dataset_test = datasets.MNIST('../data/mnist/', train=False, download=True, transform=trans_mnist)\n",
    "                    # sample users\n",
    "                    if args.iid:\n",
    "                        dict_users = mnist_iid(dataset_train, args.num_users)\n",
    "                    else:\n",
    "                        dict_users = mnist_noniid(dataset_train, args.num_users)\n",
    "                elif args.dataset == 'cifar':\n",
    "                    trans_cifar = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "                    dataset_train = datasets.CIFAR10('../data/cifar', train=True, download=True, transform=trans_cifar)\n",
    "                    dataset_test = datasets.CIFAR10('../data/cifar', train=False, download=True, transform=trans_cifar)\n",
    "                    if args.iid:\n",
    "                        dict_users = cifar_iid(dataset_train, args.num_users)\n",
    "                    else:\n",
    "                        exit('Error: only consider IID setting in CIFAR10')\n",
    "                else:\n",
    "                    exit('Error: unrecognized dataset')\n",
    "                img_size = dataset_train[0][0].shape\n",
    "\n",
    "                # build model\n",
    "                if args.model == 'cnn' and args.dataset == 'cifar':\n",
    "                    net_glob = CNNCifar(args=args).to(args.device)\n",
    "                elif args.model == 'cnn' and args.dataset == 'mnist':\n",
    "                    net_glob = CNNMnist(args=args).to(args.device)\n",
    "                elif args.model == 'mlp':\n",
    "                    len_in = 1\n",
    "                    for x in img_size:\n",
    "                        len_in *= x\n",
    "                    net_glob = MLP(dim_in=len_in, dim_hidden=200, dim_out=args.num_classes).to(args.device)\n",
    "                elif args.model == 'vgg':\n",
    "                    net_glob = imagenet_vgg.vgg16(input_shape=img_size, num_classes=args.num_classes)\n",
    "                else:\n",
    "                    exit('Error: unrecognized model')\n",
    "                # print(net_glob)\n",
    "                net_glob.train()\n",
    "\n",
    "                # copy weights\n",
    "                w_glob = net_glob.state_dict()\n",
    "\n",
    "                # training\n",
    "                loss_train = []\n",
    "                cv_loss, cv_acc = [], []\n",
    "                val_loss_pre, counter = 0, 0\n",
    "                net_best = None\n",
    "                best_loss = None\n",
    "                val_acc_list, net_list = [], []\n",
    "\n",
    "                if args.all_clients: \n",
    "                    print(\"Aggregation over all clients\")\n",
    "                    w_locals = [w_glob for i in range(args.num_users)]\n",
    "                for iter in range(args.epochs):\n",
    "                    loss_locals = []\n",
    "                    if not args.all_clients:\n",
    "                        w_locals = []\n",
    "                    m = max(int(args.frac * args.num_users), 1)\n",
    "                    idxs_users = np.random.choice(range(args.num_users), m, replace=False)\n",
    "                    for idx in idxs_users:\n",
    "                        local = LocalUpdate(args=args, dataset=dataset_train, idxs=dict_users[idx])\n",
    "                        w, loss = local.train(net=copy.deepcopy(net_glob).to(args.device))\n",
    "                        if args.all_clients:\n",
    "                            w_locals[idx] = copy.deepcopy(w)\n",
    "                        else:\n",
    "                            w_locals.append(copy.deepcopy(w))\n",
    "                        loss_locals.append(copy.deepcopy(loss))\n",
    "                    # update global weights\n",
    "                    w_glob = FedAvg(w_locals)\n",
    "\n",
    "                    # copy weight to net_glob\n",
    "                    net_glob.load_state_dict(w_glob)\n",
    "\n",
    "                    # print loss\n",
    "                    loss_avg = sum(loss_locals) / len(loss_locals)\n",
    "                    print('Round {:3d}, Average loss {:.3f}'.format(iter, loss_avg))\n",
    "                    loss_train.append(loss_avg)\n",
    "\n",
    "                # plot loss curve\n",
    "                # plt.figure()\n",
    "                # plt.plot(range(len(loss_train)), loss_train)\n",
    "                # plt.ylabel('train_loss')\n",
    "                #   plt.savefig('./save/fed_{}_{}_{}_C{}_iid{}.png'.format(args.dataset, args.model, args.epochs, args.frac, args.iid))\n",
    "\n",
    "                # testing\n",
    "                net_glob.eval()\n",
    "                acc_train, loss_train = test_img(net_glob, dataset_train, args)\n",
    "                acc_test, loss_test = test_img(net_glob, dataset_test, args)\n",
    "                print(\"Training accuracy: {:.2f}\".format(acc_train))\n",
    "                print(\"Testing accuracy: {:.2f}\".format(acc_test))\n",
    "\n",
    "                y_vals[args.pruner].append(acc_test)\n",
    "\n",
    "    # set_results(x_vals, y_vals)\n",
    "    print('synflow test accuracy: ', y_vals['synflow'])\n",
    "    print('mag test accuracy: ', y_vals['mag'])\n",
    "    # Plot both charts on the same axis\n",
    "    plt.figure()\n",
    "    plt.xscale('log')\n",
    "    plt.plot(x_vals[:args.iters], y_vals['synflow'], label='Synflow', linestyle='-', marker='o', color='r')\n",
    "    plt.plot(x_vals[:args.iters], y_vals['mag'], label='Mag', linestyle='-', marker='o', color='b')\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('X-axis')\n",
    "    plt.ylabel('Y-axis')\n",
    "    plt.title('Synflow vs Mag')\n",
    "\n",
    "    # Add legend\n",
    "    plt.legend()\n",
    "\n",
    "    # Show plot\n",
    "    if args.show:\n",
    "        plt.show()\n",
    "\n",
    "    # Save plot\n",
    "    if args.save:\n",
    "        plt.savefig('../save/test.png'.format())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "example",
   "language": "python",
   "name": "example"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
